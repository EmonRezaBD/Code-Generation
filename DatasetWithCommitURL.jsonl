{"Commit title": "Allow/Fix special characters in json replies in WebUI", "Commit url": "https://github.com/qbittorrent/qBittorrent/commit/dc4d0a7078e042b12edca2a3d5cd7d70b2794dec", "Only_addition_codes": "", "Only_deletion_codes": "case'\\'':\ncase'&':", "Codes_without_addition_and_deletion": "result +=\"\\\\t\";\nbreak;\ncase'\\\"':\ncase'\\\\':\nresult +='\\\\';\ncase'\\0':\ndefault:", "Before_commit_codebase": "result +=\"\\\\t\";\nbreak;\ncase'\\\"':\ncase'\\'':\ncase'\\\\':\ncase'&':\nresult +='\\\\';\ncase'\\0':\ndefault:", "After_commit_codebase": "result +=\"\\\\t\";\nbreak;\ncase'\\\"':\ncase'\\\\':\nresult +='\\\\';\ncase'\\0':\ndefault:"}
{"Commit title": "Fix crash when delete RSS feed", "Commit url": "https://github.com/qbittorrent/qBittorrent/commit/dedd31ada528df02048ba66fead0a37f06dc1dbe", "Only_addition_codes": "rssItem->disconnect(this);", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "\nvoidFeedListWidget::handleItemAboutToBeRemoved(RSS::Item *rssItem)\n{\ndeletem_rssToTreeItemMapping.take(rssItem);\n\n//RSS Item is still valid in this slot so if it is the last", "Before_commit_codebase": "\nvoidFeedListWidget::handleItemAboutToBeRemoved(RSS::Item *rssItem)\n{\ndeletem_rssToTreeItemMapping.take(rssItem);\n\n//RSS Item is still valid in this slot so if it is the last", "After_commit_codebase": "\nvoidFeedListWidget::handleItemAboutToBeRemoved(RSS::Item *rssItem)\n{\nrssItem->disconnect(this);\ndeletem_rssToTreeItemMapping.take(rssItem);\n\n//RSS Item is still valid in this slot so if it is the last"}
{"Commit title": "Change MixedModeAlgorithm default to TCP.Closes#7779.", "Commit url": "https://github.com/qbittorrent/qBittorrent/commit/534ed91d043abfe8ad7ccd307e4c8b060bdaf214", "Only_addition_codes": ", m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::TCP", "Only_deletion_codes": ", m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::Proportional", "Codes_without_addition_and_deletion": ", m_btProtocol(BITTORRENT_SESSION_KEY(\"BTProtocol\"), BTProtocol::Both\n, clampValue(BTProtocol::Both, BTProtocol::UTP))\n, m_isUTPRateLimited(BITTORRENT_SESSION_KEY(\"uTPRateLimited\"),true)\n, clampValue(MixedModeAlgorithm::TCP, MixedModeAlgorithm::Proportional))\n, m_multiConnectionsPerIpEnabled(BITTORRENT_SESSION_KEY(\"MultiConnectionsPerIp\"),false)\n, m_isAddTrackersEnabled(BITTORRENT_SESSION_KEY(\"AddTrackersEnabled\"),false)", "Before_commit_codebase": ", m_btProtocol(BITTORRENT_SESSION_KEY(\"BTProtocol\"), BTProtocol::Both\n, clampValue(BTProtocol::Both, BTProtocol::UTP))\n, m_isUTPRateLimited(BITTORRENT_SESSION_KEY(\"uTPRateLimited\"),true)\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::Proportional\n, clampValue(MixedModeAlgorithm::TCP, MixedModeAlgorithm::Proportional))\n, m_multiConnectionsPerIpEnabled(BITTORRENT_SESSION_KEY(\"MultiConnectionsPerIp\"),false)\n, m_isAddTrackersEnabled(BITTORRENT_SESSION_KEY(\"AddTrackersEnabled\"),false)", "After_commit_codebase": ", m_btProtocol(BITTORRENT_SESSION_KEY(\"BTProtocol\"), BTProtocol::Both\n, clampValue(BTProtocol::Both, BTProtocol::UTP))\n, m_isUTPRateLimited(BITTORRENT_SESSION_KEY(\"uTPRateLimited\"),true)\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::TCP\n, clampValue(MixedModeAlgorithm::TCP, MixedModeAlgorithm::Proportional))\n, m_multiConnectionsPerIpEnabled(BITTORRENT_SESSION_KEY(\"MultiConnectionsPerIp\"),false)\n, m_isAddTrackersEnabled(BITTORRENT_SESSION_KEY(\"AddTrackersEnabled\"),false)"}
{"Commit title": "Use a more detailed alert mask where possible", "Commit url": "https://github.com/qbittorrent/qBittorrent/commit/2f1a0ffe5c3e01a1903809106df7156e86a22201", "Only_addition_codes": "#ifLIBTORRENT_VERSION_NUM < 10110\n#else\n| libt::alert::file_progress_notification\n#endif", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "| libt::alert::tracker_notification\n| libt::alert::status_notification\n| libt::alert::ip_block_notification\n| libt::alert::progress_notification\n| libt::alert::stats_notification;\n\n#ifLIBTORRENT_VERSION_NUM < 10100", "Before_commit_codebase": "| libt::alert::tracker_notification\n| libt::alert::status_notification\n| libt::alert::ip_block_notification\n| libt::alert::progress_notification\n| libt::alert::stats_notification;\n\n#ifLIBTORRENT_VERSION_NUM < 10100", "After_commit_codebase": "| libt::alert::tracker_notification\n| libt::alert::status_notification\n| libt::alert::ip_block_notification\n#ifLIBTORRENT_VERSION_NUM < 10110\n| libt::alert::progress_notification\n#else\n| libt::alert::file_progress_notification\n#endif\n| libt::alert::stats_notification;\n\n#ifLIBTORRENT_VERSION_NUM < 10100"}
{"Commit title": "Change number of time axis divisions from 5 to 6 for convenience", "Commit url": "https://github.com/qbittorrent/qBittorrent/commit/7de0f9abed1afe5153c03978a817aea349baeb26", "Only_addition_codes": "constintTIME_AXIS_DIVISIONS =6;\nfor(inti =0; i < TIME_AXIS_DIVISIONS; ++i) {\nconstintx =rect.left() +(i* rect.width()) / TIME_AXIS_DIVISIONS;\npainter.drawLine(x, fullRect.top(),x, fullRect.bottom());\n}", "Only_deletion_codes": "painter.drawLine(rect.left(), fullRect.top(), rect.left(), fullRect.bottom());\npainter.drawLine(rect.left() +0.2* rect.width(), fullRect.top(), rect.left() +0.2* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.4* rect.width(), fullRect.top(),rect.left() +0.4* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.6* rect.width(), fullRect.top(),rect.left() +0.6* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.8* rect.width(), fullRect.top(), rect.left() +0.8* rect.width(), fullRect.bottom());", "Codes_without_addition_and_deletion": "painter.drawLine(fullRect.left(), rect.top() +0.75* rect.height(), rect.right(), rect.top() +0.75* rect.height());\npainter.drawLine(fullRect.left(), rect.bottom(), rect.right(), rect.bottom());\n\n\n//Set antialiasing for graphs\npainter.setRenderHints(QPainter::Antialiasing | QPainter::HighQualityAntialiasing);", "Before_commit_codebase": "painter.drawLine(fullRect.left(), rect.top() +0.75* rect.height(), rect.right(), rect.top() +0.75* rect.height());\npainter.drawLine(fullRect.left(), rect.bottom(), rect.right(), rect.bottom());\n\npainter.drawLine(rect.left(), fullRect.top(), rect.left(), fullRect.bottom());\npainter.drawLine(rect.left() +0.2* rect.width(), fullRect.top(), rect.left() +0.2* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.4* rect.width(), fullRect.top(),rect.left() +0.4* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.6* rect.width(), fullRect.top(),rect.left() +0.6* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.8* rect.width(), fullRect.top(), rect.left() +0.8* rect.width(), fullRect.bottom());\n\n//Set antialiasing for graphs\npainter.setRenderHints(QPainter::Antialiasing | QPainter::HighQualityAntialiasing);", "After_commit_codebase": "painter.drawLine(fullRect.left(), rect.top() +0.75* rect.height(), rect.right(), rect.top() +0.75* rect.height());\npainter.drawLine(fullRect.left(), rect.bottom(), rect.right(), rect.bottom());\n\nconstintTIME_AXIS_DIVISIONS =6;\nfor(inti =0; i < TIME_AXIS_DIVISIONS; ++i) {\nconstintx =rect.left() +(i* rect.width()) / TIME_AXIS_DIVISIONS;\npainter.drawLine(x, fullRect.top(),x, fullRect.bottom());\n}\n\n//Set antialiasing for graphs\npainter.setRenderHints(QPainter::Antialiasing | QPainter::HighQualityAntialiasing);"}
{"Commit title": "Run all passing json against parse_many. Empty documents pass, too.", "Commit url": "https://github.com/simdjson/simdjson/commit/3e226795f062268c45f8deb4256a78795fa8147c", "Only_addition_codes": "}elseif(starts_with(\"pass\", name)orstarts_with(\"fail10.json\", name)orstarts_with(\"fail70.json\", name)) {\nif(error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}elseif(starts_with(\"fail\", name) ) {\nif(!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}", "Only_deletion_codes": "}elseif(starts_with(\"pass\", name)and(has_extension(extension1, name)orhas_extension(extension2, name))anderror) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"fail\", name)and(notstarts_with(\"fail10.json\", name))and!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;", "Codes_without_addition_and_deletion": "if(contains(\"EXCLUDE\", name)) {\n//skipping\nhow_many--;\n}\nfree(fullpath);\n}", "Before_commit_codebase": "if(contains(\"EXCLUDE\", name)) {\n//skipping\nhow_many--;\n}elseif(starts_with(\"pass\", name)and(has_extension(extension1, name)orhas_extension(extension2, name))anderror) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"fail\", name)and(notstarts_with(\"fail10.json\", name))and!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\nfree(fullpath);\n}", "After_commit_codebase": "if(contains(\"EXCLUDE\", name)) {\n//skipping\nhow_many--;\n}elseif(starts_with(\"pass\", name)orstarts_with(\"fail10.json\", name)orstarts_with(\"fail70.json\", name)) {\nif(error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}elseif(starts_with(\"fail\", name) ) {\nif(!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}\nfree(fullpath);\n}"}
{"Commit title": "Fix clang-format violation", "Commit url": "https://github.com/microsoft/AirSim/commit/8524e35b90a898658b1a67a261ee6d8ee90260b5", "Only_addition_codes": "", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "UWorld* world =GetWorld();\nUGameViewportClient* gameViewport = world->GetGameViewport();\ngameViewport->bDisableWorldRendering= nodisplay;\n}", "Before_commit_codebase": "UWorld* world =GetWorld();\nUGameViewportClient* gameViewport = world->GetGameViewport();\ngameViewport->bDisableWorldRendering= nodisplay;\n\n}", "After_commit_codebase": "UWorld* world =GetWorld();\nUGameViewportClient* gameViewport = world->GetGameViewport();\ngameViewport->bDisableWorldRendering= nodisplay;\n}"}
{"Commit title": "replace auto with concrete type", "Commit url": "https://github.com/Tencent/rapidjson/commit/3cdfde14d682466b2ad550f1c47825a686a3db23", "Only_addition_codes": "Value::ConstObjectsub = o.GetObject();\nValue::ConstObjectsub2 = o.GetObj();", "Only_deletion_codes": "autosub = o.GetObject();\nautosub2 = o.GetObj();", "Codes_without_addition_and_deletion": "EXPECT_TRUE(doc.HasMember(\"object\"));\nconstDocument::ValueType& o = doc[\"object\"];\nEXPECT_TRUE(o.IsObject());\nEXPECT_TRUE(sub.HasMember(\"pi\"));\nEXPECT_TRUE(sub2.HasMember(\"pi\"));\n}", "Before_commit_codebase": "EXPECT_TRUE(doc.HasMember(\"object\"));\nconstDocument::ValueType& o = doc[\"object\"];\nEXPECT_TRUE(o.IsObject());\nautosub = o.GetObject();\nEXPECT_TRUE(sub.HasMember(\"pi\"));\nautosub2 = o.GetObj();\nEXPECT_TRUE(sub2.HasMember(\"pi\"));\n}", "After_commit_codebase": "EXPECT_TRUE(doc.HasMember(\"object\"));\nconstDocument::ValueType& o = doc[\"object\"];\nEXPECT_TRUE(o.IsObject());\nValue::ConstObjectsub = o.GetObject();\nEXPECT_TRUE(sub.HasMember(\"pi\"));\nValue::ConstObjectsub2 = o.GetObj();\nEXPECT_TRUE(sub2.HasMember(\"pi\"));\n}"}
{"Commit title": "Move profiling option help message to devhelp", "Commit url": "https://github.com/apple/foundationdb/commit/ab834c4f7ebf3ee406b90d6d4dcb66402726022e", "Only_addition_codes": "#ifdef__linux__\nprintf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold. fdbserver needs to be compiled with\\n\"\n\"USE_GPERFTOOLS flag in order to use this feature.\\n\");\n#endif", "Only_deletion_codes": "printf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold.\\n\");", "Codes_without_addition_and_deletion": "\"mounted at the specified PATH. This checks that the device at PATH\\n\"\n\"is currently mounted and that any data files get written to the\\n\"\n\"same device.\\n\");\n#endif\nprintf(\"-d PATH, --datadir PATH\\n\"\n\"Store data files in the given folder (must be unique for each\\n\");\nprintf(\"--num_testers NUM\\n\");\nprintf(\"A multitester will wait for NUM testers before starting\\n\");\nprintf(\"(defaults to 1).\\n\");\nprintf(\"--testservers ADDRESSES\\n\");\nprintf(\"The addresses of networktestservers\\n\");\nprintf(\"specified as ADDRESS:PORT,ADDRESS:PORT...\\n\");", "Before_commit_codebase": "\"mounted at the specified PATH. This checks that the device at PATH\\n\"\n\"is currently mounted and that any data files get written to the\\n\"\n\"same device.\\n\");\nprintf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold.\\n\");\n#endif\nprintf(\"-d PATH, --datadir PATH\\n\"\n\"Store data files in the given folder (must be unique for each\\n\");\nprintf(\"--num_testers NUM\\n\");\nprintf(\"A multitester will wait for NUM testers before starting\\n\");\nprintf(\"(defaults to 1).\\n\");\nprintf(\"--testservers ADDRESSES\\n\");\nprintf(\"The addresses of networktestservers\\n\");\nprintf(\"specified as ADDRESS:PORT,ADDRESS:PORT...\\n\");", "After_commit_codebase": "\"mounted at the specified PATH. This checks that the device at PATH\\n\"\n\"is currently mounted and that any data files get written to the\\n\"\n\"same device.\\n\");\n#endif\nprintf(\"-d PATH, --datadir PATH\\n\"\n\"Store data files in the given folder (must be unique for each\\n\");\nprintf(\"--num_testers NUM\\n\");\nprintf(\"A multitester will wait for NUM testers before starting\\n\");\nprintf(\"(defaults to 1).\\n\");\n#ifdef__linux__\nprintf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold. fdbserver needs to be compiled with\\n\"\n\"USE_GPERFTOOLS flag in order to use this feature.\\n\");\n#endif\nprintf(\"--testservers ADDRESSES\\n\");\nprintf(\"The addresses of networktestservers\\n\");\nprintf(\"specified as ADDRESS:PORT,ADDRESS:PORT...\\n\");"}
{"Commit title": "optimization: increased the update interval for MidiDevicesListener", "Commit url": "https://github.com/musescore/MuseScore/commit/2e5363b288892dfcebfa8abf0c9b5ef47588d261", "Only_addition_codes": "std::this_thread::sleep_for(std::chrono::milliseconds(5000));", "Only_deletion_codes": "std::this_thread::sleep_for(std::chrono::milliseconds(500));", "Codes_without_addition_and_deletion": "\nth_setDevices(devices);\n\n}\n}\n", "Before_commit_codebase": "\nth_setDevices(devices);\n\nstd::this_thread::sleep_for(std::chrono::milliseconds(500));\n}\n}\n", "After_commit_codebase": "\nth_setDevices(devices);\n\nstd::this_thread::sleep_for(std::chrono::milliseconds(5000));\n}\n}\n"}
{"Commit title": "sceKernelFindModuleByName:Add delay for Fake module", "Commit url": "https://github.com/hrydgard/ppsspp/commit/354d263ccf4cf8f3913433b1b6f7f534e497de82", "Only_addition_codes": "if(strcmp(name, module->nm.name) ==0) {\nif(!module->isFake) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\nelse{\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Fake\", name);\nreturnhleDelayResult(0,\"Module Fake\",1000*1000);\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Found\", name);", "Only_deletion_codes": "if(!module->isFake&&strcmp(name, module->nm.name) ==0) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Foundor Fake\", name);", "Codes_without_addition_and_deletion": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\n}\n}\nreturn0;\n}\n", "Before_commit_codebase": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\nif(!module->isFake&&strcmp(name, module->nm.name) ==0) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Foundor Fake\", name);\nreturn0;\n}\n", "After_commit_codebase": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\nif(strcmp(name, module->nm.name) ==0) {\nif(!module->isFake) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\nelse{\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Fake\", name);\nreturnhleDelayResult(0,\"Module Fake\",1000*1000);\n}\n}\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Found\", name);\nreturn0;\n}\n"}
{"Commit title": "Add the slow comment to one more place", "Commit url": "https://github.com/hrydgard/ppsspp/commit/dffc1a9196fcbab89c4e5f6f336c33f0eb3abfc6", "Only_addition_codes": "//NOTE: Reading the decoded texture here may be very slow, if we just wrote it to write-combined memory.", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}", "Before_commit_codebase": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}", "After_commit_codebase": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//NOTE: Reading the decoded texture here may be very slow, if we just wrote it to write-combined memory.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}"}
{"Commit title": "UI: Prevent save textures if not replacing.", "Commit url": "https://github.com/hrydgard/ppsspp/commit/8f8436fd1a07ef02b39ff765a694f1d6456849fb", "Only_addition_codes": "list->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")))->SetEnabledPtr(&g_Config.bReplaceTextures);", "Only_deletion_codes": "list->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")));", "Codes_without_addition_and_deletion": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow", "Before_commit_codebase": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")));\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow", "After_commit_codebase": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")))->SetEnabledPtr(&g_Config.bReplaceTextures);\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow"}
{"Commit title": "Replacement: Be more consistent about base level.", "Commit url": "https://github.com/hrydgard/ppsspp/commit/73c06bb77605415648c9b92102e78bc4ad4d7b07", "Only_addition_codes": "actualFmt =ToVulkanFormat(plan.replaced->Format(plan.baseLevelSrc));\nplan.replaced->GetSize(plan.baseLevelSrc+i, mipWidth, mipHeight);\nplan.replaced->Load(plan.baseLevelSrc+i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride,plan.baseLevelSrc+i, w, h);", "Only_deletion_codes": "actualFmt =ToVulkanFormat(plan.replaced->Format(0));\nplan.replaced->GetSize(i, mipWidth, mipHeight);\nplan.replaced->Load(i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);", "Codes_without_addition_and_deletion": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\n}\n}\n}", "Before_commit_codebase": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\nactualFmt =ToVulkanFormat(plan.replaced->Format(0));\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\nplan.replaced->GetSize(i, mipWidth, mipHeight);\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nplan.replaced->Load(i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}\n}", "After_commit_codebase": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\nactualFmt =ToVulkanFormat(plan.replaced->Format(plan.baseLevelSrc));\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\nplan.replaced->GetSize(plan.baseLevelSrc+i, mipWidth, mipHeight);\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nplan.replaced->Load(plan.baseLevelSrc+i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride,plan.baseLevelSrc+i, w, h);\n}\n}\n}"}
{"Commit title": "+ fix: go to doc begin after global indentation change", "Commit url": "https://github.com/rizonesoft/Notepad3/commit/c4aaeeedac747eef1a3305782444e1572ce3a296", "Only_addition_codes": "\nSci_GotoPosChooseCaret(0);\n", "Only_deletion_codes": "DocPosconstiCurPos=SciCall_GetCurrentPos();\n\nSci_GotoPosChooseCaret(iCurPos);\n", "Codes_without_addition_and_deletion": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;", "Before_commit_codebase": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nDocPosconstiCurPos=SciCall_GetCurrentPos();\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSci_GotoPosChooseCaret(iCurPos);\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;", "After_commit_codebase": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n\nSci_GotoPosChooseCaret(0);\n\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;"}
{"Commit title": "fixes#621: better performance for iPhone 6 Plus through smaller rend…", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/49e76dba951aa232e24b988981e7bd8532b254c5", "Only_addition_codes": "if([UIScreeninstancesRespondToSelector:@selector(nativeScale)]) {\n_glView.contentScaleFactor= [[UIScreenmainScreen]nativeScale];\n}", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];", "Before_commit_codebase": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];", "After_commit_codebase": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\nif([UIScreeninstancesRespondToSelector:@selector(nativeScale)]) {\n_glView.contentScaleFactor= [[UIScreenmainScreen]nativeScale];\n}\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];"}
{"Commit title": "Disable all Sources when terminating", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/743619dee9056d902de6ea6890f4997b5b4cbe42", "Only_addition_codes": "\n//Since we don't have a stylesheet anymore, this will disable all Sources and cancel\n//their associated requests.\nupdateSources();\nassert(activeSources.empty());\n\n//It's now safe to destroy/join the workers since there won't be any more callbacks that\n//could dispatch to the worker pool.", "Only_deletion_codes": "activeSources.clear();", "Codes_without_addition_and_deletion": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\nworkers.reset();\n\nterminating =true;\n", "Before_commit_codebase": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\nworkers.reset();\nactiveSources.clear();\n\nterminating =true;\n", "After_commit_codebase": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\n\n//Since we don't have a stylesheet anymore, this will disable all Sources and cancel\n//their associated requests.\nupdateSources();\nassert(activeSources.empty());\n\n//It's now safe to destroy/join the workers since there won't be any more callbacks that\n//could dispatch to the worker pool.\nworkers.reset();\n\nterminating =true;\n"}
{"Commit title": "add worker cancellation test (failing)", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/e20faf7a8d531689642106164b5ee53b3353fe80", "Only_addition_codes": "\nTEST(Worker, WorkRequestCancelsImmediately) {\nRunLooploop(uv_default_loop());\n\nWorkerworker(1);\n\nloop.invoke([&] {\nstd::promise<void> started;\n//First worker item.\nWorkRequest request1 = worker.send([&] {\nusleep(10000);\nstarted.set_value();\n}, [&] {});\n\nWorkRequest request2 = worker.send([&] {\nADD_FAILURE() <<\"Second work item should not be invoked\";\n}, [&] {});\nrequest2.join();\n\nstarted.get_future().get();\nrequest1.join();\n\nloop.stop();\n});\n\nuv_run(uv_default_loop(), UV_RUN_DEFAULT);\n}", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}", "Before_commit_codebase": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}", "After_commit_codebase": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}\n\nTEST(Worker, WorkRequestCancelsImmediately) {\nRunLooploop(uv_default_loop());\n\nWorkerworker(1);\n\nloop.invoke([&] {\nstd::promise<void> started;\n//First worker item.\nWorkRequest request1 = worker.send([&] {\nusleep(10000);\nstarted.set_value();\n}, [&] {});\n\nWorkRequest request2 = worker.send([&] {\nADD_FAILURE() <<\"Second work item should not be invoked\";\n}, [&] {});\nrequest2.join();\n\nstarted.get_future().get();\nrequest1.join();\n\nloop.stop();\n});\n\nuv_run(uv_default_loop(), UV_RUN_DEFAULT);\n}"}
{"Commit title": "GLFW port now uses nudgeTransitions()", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/0b8cd02c195e58ae11037e3905f4987f7ce05bbb", "Only_addition_codes": "constboolneedsRerender = map->renderSync();\nmap->nudgeTransitions(needsRerender);", "Only_deletion_codes": "map->renderSync();", "Codes_without_addition_and_deletion": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\n}\n}\n}", "Before_commit_codebase": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\nmap->renderSync();\n}\n}\n}", "After_commit_codebase": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\nconstboolneedsRerender = map->renderSync();\nmap->nudgeTransitions(needsRerender);\n}\n}\n}"}
{"Commit title": "Ignore tile URL sharding", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/bea457697a550392971c143071296e0d26a09fb4", "Only_addition_codes": "std::string result = tiles.at(0);", "Only_deletion_codes": "std::string result = tiles.at((id.x+ id.y) % tiles.size());", "Codes_without_addition_and_deletion": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));", "Before_commit_codebase": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nstd::string result = tiles.at((id.x+ id.y) % tiles.size());\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));", "After_commit_codebase": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nstd::string result = tiles.at(0);\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));"}
{"Commit title": "Disable heading updates for .FollowWithCourse", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/2f30dfe97d851f2a2bb4141dc234013b01f8afd3", "Only_addition_codes": "caseMGLUserTrackingModeFollowWithCourse:", "Only_deletion_codes": "caseMGLUserTrackingModeFollowWithCourse:", "Codes_without_addition_and_deletion": "break;\n}\ncaseMGLUserTrackingModeFollow:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\n{\nself.showsUserLocation=YES;\n", "Before_commit_codebase": "break;\n}\ncaseMGLUserTrackingModeFollow:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\ncaseMGLUserTrackingModeFollowWithCourse:\n{\nself.showsUserLocation=YES;\n", "After_commit_codebase": "break;\n}\ncaseMGLUserTrackingModeFollow:\ncaseMGLUserTrackingModeFollowWithCourse:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\n{\nself.showsUserLocation=YES;\n"}
{"Commit title": "[ios][bench] Add total and avg FPS to final summary", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/253a007d99c2079b95d5c6d11715e16815067e16", "Only_addition_codes": "doubletotalFPS =0;\ntotalFPS += row.second;\nNSLog(@\"Total FPS:%4.1f\", totalFPS);\nNSLog(@\"Average FPS:%4.1f\", totalFPS / result.size());", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\n}\nexit(0);\n}\n}", "Before_commit_codebase": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\n}\nexit(0);\n}\n}", "After_commit_codebase": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\ndoubletotalFPS =0;\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\ntotalFPS += row.second;\n}\nNSLog(@\"Total FPS:%4.1f\", totalFPS);\nNSLog(@\"Average FPS:%4.1f\", totalFPS / result.size());\nexit(0);\n}\n}"}
{"Commit title": "[core] Fix deleter mismatch", "Commit url": "https://github.com/mapbox/mapbox-gl-native/commit/62bc6e29c822d823ca6bb54d056835ec95d3aa73", "Only_addition_codes": "intstride = width *4;\nsize_twebpSize = stride * height;\nautowebp = std::make_unique<uint8_t[]>(webpSize);\n\nif(!WebPDecodeRGBAInto(data, size, webp.get(), webpSize, stride)) {", "Only_deletion_codes": "std::unique_ptr<uint8_t[]>webp(WebPDecodeRGBA(data, size, &width, &height));\nif(!webp) {", "Codes_without_addition_and_deletion": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n", "Before_commit_codebase": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nstd::unique_ptr<uint8_t[]>webp(WebPDecodeRGBA(data, size, &width, &height));\nif(!webp) {\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n", "After_commit_codebase": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nintstride = width *4;\nsize_twebpSize = stride * height;\nautowebp = std::make_unique<uint8_t[]>(webpSize);\n\nif(!WebPDecodeRGBAInto(data, size, webp.get(), webpSize, stride)) {\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n"}
{"Commit title": "rwgame: remove undefined behavior in CharacterObjects", "Commit url": "https://github.com/rwengine/openrw/commit/46b94bd1ede5fd96f9472e64bb2fad2c19a05ec3", "Only_addition_codes": "if(isPlayer() &&static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;", "Only_deletion_codes": "if(controller) {\nif(static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}", "Codes_without_addition_and_deletion": "}\n}\n\n}\n\n//Check if we need to change the animation or change speed", "Before_commit_codebase": "}\n}\n\nif(controller) {\nif(static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}\n}\n\n//Check if we need to change the animation or change speed", "After_commit_codebase": "}\n}\n\nif(isPlayer() &&static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}\n\n//Check if we need to change the animation or change speed"}
{"Commit title": "setForcedUpdateAllAabbs to false; Reduces stepSimulation time by 35%.", "Commit url": "https://github.com/rwengine/openrw/commit/f7bd8701db2a98678e206ae78515b0a0e16b092b", "Only_addition_codes": "dynamicsWorld->setForceUpdateAllAabbs(false);", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\n}\n\nGameWorld::~GameWorld() {", "Before_commit_codebase": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\n}\n\nGameWorld::~GameWorld() {", "After_commit_codebase": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\ndynamicsWorld->setForceUpdateAllAabbs(false);\n}\n\nGameWorld::~GameWorld() {"}
{"Commit title": "Arm64: Implement support for SVE bitperm", "Commit url": "https://github.com/FEX-Emu/FEX/commit/e24b01b6cb4dd4a3d18caed2dccc486ad0d5acf7", "Only_addition_codes": "if(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PDEP but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), OrigInput.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), OrigMask.W());\nbdep(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), OrigInput.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), OrigMask.X());\nbdep(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PEXT but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), Input.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), Mask.W());\nbext(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), Input.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), Mask.X());\nbext(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}", "Only_deletion_codes": "//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);", "Codes_without_addition_and_deletion": "\nconstautoDest =GetReg(Node);\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\n}\n\nDEF_OP(LDiv) {", "Before_commit_codebase": "\nconstautoDest =GetReg(Node);\n\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}\n\nDEF_OP(LDiv) {", "After_commit_codebase": "\nconstautoDest =GetReg(Node);\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PDEP but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), OrigInput.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), OrigMask.W());\nbdep(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), OrigInput.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), OrigMask.X());\nbdep(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PEXT but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), Input.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), Mask.W());\nbext(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), Input.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), Mask.X());\nbext(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}\n}\n\nDEF_OP(LDiv) {"}
{"Commit title": "fixup formatting", "Commit url": "https://github.com/tfussell/xlnt/commit/e5d6a26e1738f9b43a4a4e8a12b9ac438a2a5550", "Only_addition_codes": "autorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\nexpect_end_element(row_el);", "Only_deletion_codes": "//auto row_index = parser().attribute<row_t>(\"r\");\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\nexpect_end_element(row_el);", "Codes_without_addition_and_deletion": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\n\nif(!in_element(sheetData_el))\n{", "Before_commit_codebase": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\n//auto row_index = parser().attribute<row_t>(\"r\");\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\nexpect_end_element(row_el);\n\nif(!in_element(sheetData_el))\n{", "After_commit_codebase": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\nexpect_end_element(row_el);\n\nif(!in_element(sheetData_el))\n{"}
{"Commit title": "[StructuralMechanicsApplication] Adding patch test for Quad9", "Commit url": "https://github.com/KratosMultiphysics/Kratos/commit/745cdb6c79e6e0a6713535842f941819e422f9c9", "Only_addition_codes": "deftest_SmallDisplacementElement_2D_quadratic_quadrilateral(self):\ndim=2\ncurrent_model=KratosMultiphysics.Model()\nmp=current_model.CreateModelPart(\"solid_part\")\nself._add_variables(mp)\nself._apply_material_properties(mp,dim)\n\n# Create nodes\nmp.CreateNewNode(1,2.0000000000,1.0000000000,0.0000000000)\nmp.CreateNewNode(2,1.8333333333,0.8333333333,0.0000000000)\nmp.CreateNewNode(3,1.7500000000,0.9166666667,0.0000000000)\nmp.CreateNewNode(4,1.6501412600,0.7903466431,0.0000000000)\nmp.CreateNewNode(5,1.6666666667,0.6666666667,0.0000000000)\nmp.CreateNewNode(6,1.5000000000,0.8333333333,0.0000000000)\nmp.CreateNewNode(7,1.5502825201,0.6640266196,0.0000000000)\nmp.CreateNewNode(8,1.4669491867,0.7473599529,0.0000000000)\nmp.CreateNewNode(9,1.4338983735,0.6613865725,0.0000000000)\nmp.CreateNewNode(10,1.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(11,1.3930628337,0.5373333663,0.0000000000)\nmp.CreateNewNode(12,1.2500000000,0.7500000000,0.0000000000)\nmp.CreateNewNode(13,1.2680628337,0.6623333663,0.0000000000)\nmp.CreateNewNode(14,1.2861256675,0.5746667326,0.0000000000)\nmp.CreateNewNode(15,1.3333333333,0.3333333333,0.0000000000)\nmp.CreateNewNode(16,1.2358431474,0.4106401130,0.0000000000)\nmp.CreateNewNode(17,1.1383529614,0.4879468926,0.0000000000)\nmp.CreateNewNode(18,1.0691764807,0.5773067797,0.0000000000)\nmp.CreateNewNode(19,1.0000000000,0.6666666667,0.0000000000)\nmp.CreateNewNode(20,1.1666666667,0.1666666667,0.0000000000)\nmp.CreateNewNode(21,1.0644666084,0.2779203060,0.0000000000)\nmp.CreateNewNode(22,0.9622665502,0.3891739453,0.0000000000)\nmp.CreateNewNode(23,0.8561332751,0.4862536393,0.0000000000)\nmp.CreateNewNode(24,0.7500000000,0.5833333333,0.0000000000)\nmp.CreateNewNode(25,0.8930900695,0.1452004990,0.0000000000)\nmp.CreateNewNode(26,0.7861801389,0.2904009980,0.0000000000)\nmp.CreateNewNode(27,1.0000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(28,0.6430900695,0.3952004990,0.0000000000)\nmp.CreateNewNode(29,0.6479361204,0.2339226363,0.0000000000)\nmp.CreateNewNode(30,0.6989680602,0.1169613182,0.0000000000)\nmp.CreateNewNode(31,0.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(32,0.7500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(33,0.5114680602,0.3044613182,0.0000000000)\nmp.CreateNewNode(34,0.5096921019,0.1774442747,0.0000000000)\nmp.CreateNewNode(35,0.3750000000,0.3750000000,0.0000000000)\nmp.CreateNewNode(36,0.5048460509,0.0887221373,0.0000000000)\nmp.CreateNewNode(37,0.3798460509,0.2137221373,0.0000000000)\nmp.CreateNewNode(38,0.5000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(39,0.2500000000,0.2500000000,0.0000000000)\nmp.CreateNewNode(40,0.3149230255,0.1068610687,0.0000000000)\nmp.CreateNewNode(41,0.2500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(42,0.1250000000,0.1250000000,0.0000000000)\nmp.CreateNewNode(43,0.0000000000,0.0000000000,0.0000000000)\n\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_X,KratosMultiphysics.REACTION_X,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Y,KratosMultiphysics.REACTION_Y,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Z,KratosMultiphysics.REACTION_Z,mp)\n\n#create a submodelpart for boundary conditions\nbcs=mp.CreateSubModelPart(\"BoundaryCondtions\")\nbcs.AddNodes([1,2,3,5,6,10,12,15,19,20,24,27,31,32,35,38,39,41,42,43])\n\n# Create Element\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",1, [39,43,38,34,42,41,36,37,40],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",2, [31,39,34,26,35,37,29,28,33],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",3, [34,38,27,26,36,32,25,29,30],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",4, [5,1,6,9,2,3,8,7,4],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",5, [27,15,17,26,20,16,22,25,21],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",6, [31,26,17,19,28,22,18,24,23],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",7, [15,5,9,17,10,7,14,16,11],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",8, [19,17,9,6,18,14,8,12,13],mp.GetProperties()[1])\n\nA,b=self._define_movement(dim)\n\nself._apply_BCs(bcs,A,b)\nself._solve(mp)\nself._check_results(mp,A,b)\nself._check_outputs(mp,A,dim)\n\n#self.__post_process(mp)\n", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()", "Before_commit_codebase": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()", "After_commit_codebase": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_2D_quadratic_quadrilateral(self):\ndim=2\ncurrent_model=KratosMultiphysics.Model()\nmp=current_model.CreateModelPart(\"solid_part\")\nself._add_variables(mp)\nself._apply_material_properties(mp,dim)\n\n# Create nodes\nmp.CreateNewNode(1,2.0000000000,1.0000000000,0.0000000000)\nmp.CreateNewNode(2,1.8333333333,0.8333333333,0.0000000000)\nmp.CreateNewNode(3,1.7500000000,0.9166666667,0.0000000000)\nmp.CreateNewNode(4,1.6501412600,0.7903466431,0.0000000000)\nmp.CreateNewNode(5,1.6666666667,0.6666666667,0.0000000000)\nmp.CreateNewNode(6,1.5000000000,0.8333333333,0.0000000000)\nmp.CreateNewNode(7,1.5502825201,0.6640266196,0.0000000000)\nmp.CreateNewNode(8,1.4669491867,0.7473599529,0.0000000000)\nmp.CreateNewNode(9,1.4338983735,0.6613865725,0.0000000000)\nmp.CreateNewNode(10,1.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(11,1.3930628337,0.5373333663,0.0000000000)\nmp.CreateNewNode(12,1.2500000000,0.7500000000,0.0000000000)\nmp.CreateNewNode(13,1.2680628337,0.6623333663,0.0000000000)\nmp.CreateNewNode(14,1.2861256675,0.5746667326,0.0000000000)\nmp.CreateNewNode(15,1.3333333333,0.3333333333,0.0000000000)\nmp.CreateNewNode(16,1.2358431474,0.4106401130,0.0000000000)\nmp.CreateNewNode(17,1.1383529614,0.4879468926,0.0000000000)\nmp.CreateNewNode(18,1.0691764807,0.5773067797,0.0000000000)\nmp.CreateNewNode(19,1.0000000000,0.6666666667,0.0000000000)\nmp.CreateNewNode(20,1.1666666667,0.1666666667,0.0000000000)\nmp.CreateNewNode(21,1.0644666084,0.2779203060,0.0000000000)\nmp.CreateNewNode(22,0.9622665502,0.3891739453,0.0000000000)\nmp.CreateNewNode(23,0.8561332751,0.4862536393,0.0000000000)\nmp.CreateNewNode(24,0.7500000000,0.5833333333,0.0000000000)\nmp.CreateNewNode(25,0.8930900695,0.1452004990,0.0000000000)\nmp.CreateNewNode(26,0.7861801389,0.2904009980,0.0000000000)\nmp.CreateNewNode(27,1.0000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(28,0.6430900695,0.3952004990,0.0000000000)\nmp.CreateNewNode(29,0.6479361204,0.2339226363,0.0000000000)\nmp.CreateNewNode(30,0.6989680602,0.1169613182,0.0000000000)\nmp.CreateNewNode(31,0.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(32,0.7500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(33,0.5114680602,0.3044613182,0.0000000000)\nmp.CreateNewNode(34,0.5096921019,0.1774442747,0.0000000000)\nmp.CreateNewNode(35,0.3750000000,0.3750000000,0.0000000000)\nmp.CreateNewNode(36,0.5048460509,0.0887221373,0.0000000000)\nmp.CreateNewNode(37,0.3798460509,0.2137221373,0.0000000000)\nmp.CreateNewNode(38,0.5000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(39,0.2500000000,0.2500000000,0.0000000000)\nmp.CreateNewNode(40,0.3149230255,0.1068610687,0.0000000000)\nmp.CreateNewNode(41,0.2500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(42,0.1250000000,0.1250000000,0.0000000000)\nmp.CreateNewNode(43,0.0000000000,0.0000000000,0.0000000000)\n\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_X,KratosMultiphysics.REACTION_X,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Y,KratosMultiphysics.REACTION_Y,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Z,KratosMultiphysics.REACTION_Z,mp)\n\n#create a submodelpart for boundary conditions\nbcs=mp.CreateSubModelPart(\"BoundaryCondtions\")\nbcs.AddNodes([1,2,3,5,6,10,12,15,19,20,24,27,31,32,35,38,39,41,42,43])\n\n# Create Element\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",1, [39,43,38,34,42,41,36,37,40],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",2, [31,39,34,26,35,37,29,28,33],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",3, [34,38,27,26,36,32,25,29,30],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",4, [5,1,6,9,2,3,8,7,4],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",5, [27,15,17,26,20,16,22,25,21],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",6, [31,26,17,19,28,22,18,24,23],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",7, [15,5,9,17,10,7,14,16,11],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",8, [19,17,9,6,18,14,8,12,13],mp.GetProperties()[1])\n\nA,b=self._define_movement(dim)\n\nself._apply_BCs(bcs,A,b)\nself._solve(mp)\nself._check_results(mp,A,b)\nself._check_outputs(mp,A,dim)\n\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()"}
{"Commit title": "Missing changes in CompressiblePotentialFlowApp", "Commit url": "https://github.com/KratosMultiphysics/Kratos/commit/826d1bd8d74623c8e08782d5081408b30eb388a4", "Only_addition_codes": "std::vector<array_1d<double,3>> cut_normal;", "Only_deletion_codes": "std::vector<Vector> cut_normal;", "Codes_without_addition_and_deletion": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;", "Before_commit_codebase": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\nstd::vector<Vector> cut_normal;\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;", "After_commit_codebase": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\nstd::vector<array_1d<double,3>> cut_normal;\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;"}
{"Commit title": "A test.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/30ba546917769bd6f6bef67ae96c052318978729", "Only_addition_codes": "deserialized_circle->WriteToMessage(\n&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\n//positions by less than the tolerance.  It also preserve the degrees of\n//freedom at the \"exact\" iterators.\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +1* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +1* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +2* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +2* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +3* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +3* Second)->degrees_of_freedom);\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +4* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +4* Second)->degrees_of_freedom);", "Only_deletion_codes": "deserialized_circle->WriteToMessage(&message,/*forks=*/{},/*exact=*/{});\n//positions by less than the tolerance.", "Codes_without_addition_and_deletion": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\n\n//Appending may result in different downsampling because the positions differ\n//a bit.", "Before_commit_codebase": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle->WriteToMessage(&message,/*forks=*/{},/*exact=*/{});\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\n//positions by less than the tolerance.\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\n\n//Appending may result in different downsampling because the positions differ\n//a bit.", "After_commit_codebase": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle->WriteToMessage(\n&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\n//positions by less than the tolerance.  It also preserve the degrees of\n//freedom at the \"exact\" iterators.\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +1* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +1* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +2* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +2* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +3* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +3* Second)->degrees_of_freedom);\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +4* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +4* Second)->degrees_of_freedom);\n\n//Appending may result in different downsampling because the positions differ\n//a bit."}
{"Commit title": "Fix compilation errors.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/2e162bedeab9b5f8d1bfcb7c661abf9a395120d8", "Only_addition_codes": "CHECK_EQ(0, message.checkpoint(0).non_collapsible_segment().children_size());\nCHECK_EQ(\n1,\nmessage.checkpoint(0).non_collapsible_segment().zfp().timeline_size());\nCHECK_EQ(0, message.checkpoint(1).non_collapsible_segment().children_size());\nCHECK_EQ(\n16,\nmessage.checkpoint(1).non_collapsible_segment().zfp().timeline_size());", "Only_deletion_codes": "CHECK_EQ(0, message.checkpoint(0).segment().children_size());\nCHECK_EQ(1, message.checkpoint(0).segment().zfp().timeline_size());\nCHECK_EQ(0, message.checkpoint(1).segment().children_size());\nCHECK_EQ(16, message.checkpoint(1).segment().zfp().timeline_size());", "Codes_without_addition_and_deletion": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {", "Before_commit_codebase": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(0).segment().children_size());\nCHECK_EQ(1, message.checkpoint(0).segment().zfp().timeline_size());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(1).segment().children_size());\nCHECK_EQ(16, message.checkpoint(1).segment().zfp().timeline_size());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {", "After_commit_codebase": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(0).non_collapsible_segment().children_size());\nCHECK_EQ(\n1,\nmessage.checkpoint(0).non_collapsible_segment().zfp().timeline_size());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(1).non_collapsible_segment().children_size());\nCHECK_EQ(\n16,\nmessage.checkpoint(1).non_collapsible_segment().zfp().timeline_size());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {"}
{"Commit title": "Compilation error.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/41e9229eb7f9a1c6dd1d544da697966fa55cdcc4", "Only_addition_codes": "/*excluded=*/{},\n/*tracked=*/{},", "Only_deletion_codes": "/*forks=*/{},", "Codes_without_addition_and_deletion": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle =", "Before_commit_codebase": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle =", "After_commit_codebase": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*excluded=*/{},\n/*tracked=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle ="}
{"Commit title": "Track the backstory.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/99ab63097a4a5272fe82f95ffbe462b13c0d8b71", "Only_addition_codes": "//or prediction (at the last time of the backstory).  To figure things out\n//when reading we must track the |backstory_|.\n/*tracked=*/{backstory_},", "Only_deletion_codes": "//or prediction (at the last time of the backstory).\n/*tracked=*/{},", "Codes_without_addition_and_deletion": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment.", "Before_commit_codebase": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\n//or prediction (at the last time of the backstory).\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*tracked=*/{},\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment.", "After_commit_codebase": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\n//or prediction (at the last time of the backstory).  To figure things out\n//when reading we must track the |backstory_|.\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*tracked=*/{backstory_},\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment."}
{"Commit title": "Bypass stock aerodynamics outside the atmosphere", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/1df150311c12d50009d681396dbc61ed9be6e034", "Only_addition_codes": "if(part.atmDensity <=0){\ncontinue;\n}", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){", "Before_commit_codebase": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){", "After_commit_codebase": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nif(part.atmDensity <=0){\ncontinue;\n}\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){"}
{"Commit title": "Fix a test that was broken by the removal of history().", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/ff745707096fb1be67aa3c1ddf9af57f01e37179", "Only_addition_codes": "EXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(trajectory,SizeIs(435'929));", "Only_deletion_codes": "EXPECT_THAT(trajectory,SizeIs(435'927));", "Codes_without_addition_and_deletion": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}", "Before_commit_codebase": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(trajectory,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}", "After_commit_codebase": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}"}
{"Commit title": "Lint.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/67a86591c42004b31b4e2ca2632bec3187f449b1", "Only_addition_codes": "//we cannot use FindPolynomialForInstantLocked because it calls\n//lower_boundand we don't want to change its behaviour.", "Only_deletion_codes": "//we cannot use FindPolynomialForInstantLocked because it callslower_bound\n//and we don't want to change its behaviour.", "Codes_without_addition_and_deletion": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial.", "Before_commit_codebase": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\n//we cannot use FindPolynomialForInstantLocked because it callslower_bound\n//and we don't want to change its behaviour.\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial.", "After_commit_codebase": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\n//we cannot use FindPolynomialForInstantLocked because it calls\n//lower_boundand we don't want to change its behaviour.\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial."}
{"Commit title": "No auto sync.", "Commit url": "https://github.com/mockingbirdnest/Principia/commit/98bd3a6f4c38c6b8071947182852d196a4625182", "Only_addition_codes": "// We aregoing to touch plenty of|Transform|s,sowewill prevent\n//Unity from syncing withthephysics system all the time.", "Only_deletion_codes": "// We arenot changing the|Transform|s,but ifwedon't disable auto-\n//synctheprofiles show |SyncColliderTransform|.\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n", "Codes_without_addition_and_deletion": "yieldbreak;\n}\n\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;", "Before_commit_codebase": "yieldbreak;\n}\n\n// We arenot changing the|Transform|s,but ifwedon't disable auto-\n//synctheprofiles show |SyncColliderTransform|.\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;", "After_commit_codebase": "yieldbreak;\n}\n\n// We aregoing to touch plenty of|Transform|s,sowewill prevent\n//Unity from syncing withthephysics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;"}
{"Commit title": "Fallback to GLX_MESA_swap_control if GLX_EXT_swap_control isn't suppo…", "Commit url": "https://github.com/DiligentGraphics/DiligentCore/commit/7836b2c504c4efb25a3bd6d85bcb2312fae3c58a", "Only_addition_codes": "#ifGLX_MESA_swap_control\nelseif(glXSwapIntervalMESA !=nullptr)\n{\nglXSwapIntervalMESA(SwapInterval);\n}\n#endif", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#endif\nglXSwapBuffers(display, wnd);\n}", "Before_commit_codebase": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#endif\nglXSwapBuffers(display, wnd);\n}", "After_commit_codebase": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#ifGLX_MESA_swap_control\nelseif(glXSwapIntervalMESA !=nullptr)\n{\nglXSwapIntervalMESA(SwapInterval);\n}\n#endif\n#endif\nglXSwapBuffers(display, wnd);\n}"}
{"Commit title": "Remove obsolete TODO comment", "Commit url": "https://github.com/TurningWheel/Barony/commit/8dc2ff3bc0d114e5c8119b0cb42d94e09dbee0e7", "Only_addition_codes": "//dead reckoning", "Only_deletion_codes": "//dead reckoning//TODO: I feel like this could be improved. Right now, it's effectively an O(N^2) loop when it concerns monsters and players, since for every monster and player, it loops through the entire entity list to find the limbs. Why? Just access them directly from this entity!", "Codes_without_addition_and_deletion": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;", "Before_commit_codebase": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\n//dead reckoning//TODO: I feel like this could be improved. Right now, it's effectively an O(N^2) loop when it concerns monsters and players, since for every monster and player, it loops through the entire entity list to find the limbs. Why? Just access them directly from this entity!\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;", "After_commit_codebase": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\n//dead reckoning\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;"}
{"Commit title": "Adding percentile statistics to pmemkv_bench output", "Commit url": "https://github.com/pmem/pmemkv/commit/646c53da3cb944a56be030b1579314adc61682c7", "Only_addition_codes": "snprintf(buf,sizeof(buf),\n\"Percentiles: P50: %.2f P75: %.2f P99: %.2f P99.9: %.2f P99.99: %.2f\\n\",\nPercentile(50),Percentile(75),Percentile(99),\nPercentile(99.9),Percentile(99.99)\n);\nr.append(buf);", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;", "Before_commit_codebase": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;", "After_commit_codebase": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nsnprintf(buf,sizeof(buf),\n\"Percentiles: P50: %.2f P75: %.2f P99: %.2f P99.9: %.2f P99.99: %.2f\\n\",\nPercentile(50),Percentile(75),Percentile(99),\nPercentile(99.9),Percentile(99.99)\n);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;"}
{"Commit title": "Changed default color preset to Plasma_17", "Commit url": "https://github.com/OpenChemistry/tomviz/commit/efa34d3bf0c8318418890ad80f5701d6e24232b0", "Only_addition_codes": "this->setDefaultColorMapFromPreset(\"Plasma_17\");", "Only_deletion_codes": "this->setDefaultColorMapFromPreset(\"Grayscale\");", "Codes_without_addition_and_deletion": "}\n\n//Set the default color map from a preset.\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");", "Before_commit_codebase": "}\n\n//Set the default color map from a preset.\nthis->setDefaultColorMapFromPreset(\"Grayscale\");\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");", "After_commit_codebase": "}\n\n//Set the default color map from a preset.\nthis->setDefaultColorMapFromPreset(\"Plasma_17\");\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");"}
{"Commit title": "fix a bug in disk.cpp related to#430", "Commit url": "https://github.com/PrincetonUniversity/athena/commit/36a24ba98c79313fdc8eb99a2b6328e13432b187", "Only_addition_codes": "phi=pco->x3v(k);", "Only_deletion_codes": "phi=pco->x3v(i);", "Codes_without_addition_and_deletion": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;", "Before_commit_codebase": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nphi=pco->x3v(i);\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;", "After_commit_codebase": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nphi=pco->x3v(k);\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;"}
{"Commit title": "Remove the unused test code: generate_pow_code is used to assist in g…", "Commit url": "https://github.com/bigbangcore/BigBang/commit/d76b5525b5e78b9e14fcf11b4feb3effce2f96a7", "Only_addition_codes": "", "Only_deletion_codes": "BOOST_AUTO_TEST_CASE(generate_pow_code)\n{\nstd::cout <<\"{\"<< std::endl;\nfor(inti =1; i <=51; i++)\n{\nstd::cout <<\"//\"<< i <<\"^1 ...\"<< i <<\"^26\"<< std::endl;\nstd::cout <<\"{\"<< std::endl;\nCSC25519base(1);\nuint256 ret;\nfor(intj =1; j <=26; j++)\n{\nbase *= i;\nbase.Pack(ret.begin());\nconstuint64* p = (constuint64*)ret.begin();\nstd::cout <<\"CSC25519({\";\nfor(intk =0; k <4; k++)\n{\nstd::cout <<\"0x\"<< std::hex << *p++ <<std::resetiosflags(std::ios_base::basefield);\nif(k <3)\n{\nstd::cout <<\",\";\n}\n}\nstd::cout <<\"}),\"<< std::endl;\n}\nstd::cout <<\"},\"<< std::endl;\n}\nstd::cout <<\"};\"<< std::endl;\n}\n", "Codes_without_addition_and_deletion": "}\n}\n\nBOOST_AUTO_TEST_SUITE_END()", "Before_commit_codebase": "}\n}\n\nBOOST_AUTO_TEST_CASE(generate_pow_code)\n{\nstd::cout <<\"{\"<< std::endl;\nfor(inti =1; i <=51; i++)\n{\nstd::cout <<\"//\"<< i <<\"^1 ...\"<< i <<\"^26\"<< std::endl;\nstd::cout <<\"{\"<< std::endl;\nCSC25519base(1);\nuint256 ret;\nfor(intj =1; j <=26; j++)\n{\nbase *= i;\nbase.Pack(ret.begin());\nconstuint64* p = (constuint64*)ret.begin();\nstd::cout <<\"CSC25519({\";\nfor(intk =0; k <4; k++)\n{\nstd::cout <<\"0x\"<< std::hex << *p++ <<std::resetiosflags(std::ios_base::basefield);\nif(k <3)\n{\nstd::cout <<\",\";\n}\n}\nstd::cout <<\"}),\"<< std::endl;\n}\nstd::cout <<\"},\"<< std::endl;\n}\nstd::cout <<\"};\"<< std::endl;\n}\n\nBOOST_AUTO_TEST_SUITE_END()", "After_commit_codebase": "}\n}\n\nBOOST_AUTO_TEST_SUITE_END()"}
{"Commit title": "Return early from fwdpy11.infinite_sites when possible.", "Commit url": "https://github.com/molpopgen/fwdpy11/commit/99c8e5abdbe62b605089277051bd6ac7ed29d061", "Only_addition_codes": "constdoublemu) ->unsigned{\nif(mu <=0.0)\n{\nreturn0u;\n}\nif(nmuts ==0)\n{\nreturnnmuts;\n}", "Only_deletion_codes": "constdoublemu) {\nstd::sort(pop.tables.mutation_table.begin(),\npop.tables.mutation_table.end(),\n[&pop](constfwdpp::ts::mutation_record& a,\nconstfwdpp::ts::mutation_record& b) {\nreturnpop.mutations[a.key].pos\n< pop.mutations[b.key].pos;\n});", "Codes_without_addition_and_deletion": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);", "Before_commit_codebase": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nconstdoublemu) {\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nstd::sort(pop.tables.mutation_table.begin(),\npop.tables.mutation_table.end(),\n[&pop](constfwdpp::ts::mutation_record& a,\nconstfwdpp::ts::mutation_record& b) {\nreturnpop.mutations[a.key].pos\n< pop.mutations[b.key].pos;\n});\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);", "After_commit_codebase": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nconstdoublemu) ->unsigned{\nif(mu <=0.0)\n{\nreturn0u;\n}\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nif(nmuts ==0)\n{\nreturnnmuts;\n}\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);"}
{"Commit title": "Update to use new namespaces", "Commit url": "https://github.com/project-asgard/asgard/commit/19a55124c19f1e99ad315e511a6f487a9036413d", "Only_addition_codes": "\n", "Only_deletion_codes": "", "Codes_without_addition_and_deletion": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold =", "Before_commit_codebase": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold =", "After_commit_codebase": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold ="}
{"Commit title": "update tim's tests to use the new op two scale interface", "Commit url": "https://github.com/project-asgard/asgard/commit/3881ccebe66a1bba0603b9e224ee0255be1f2f92", "Only_addition_codes": "fk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);", "Only_deletion_codes": "fk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);", "Codes_without_addition_and_deletion": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));", "Before_commit_codebase": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));", "After_commit_codebase": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));"}
{"Commit title": "clang-format", "Commit url": "https://github.com/project-asgard/asgard/commit/11a890019fb230ce1c8699ceb2f2dad2fe6609e5", "Only_addition_codes": "(*std::min_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n})).second.start;\n\nintconstmax_col =\n(*std::max_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n})).second.stop;", "Only_deletion_codes": "(*std::min_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n}))\n.second.start;\n\nintconstmax_col = (*std::max_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n}))\n.second.stop;", "Codes_without_addition_and_deletion": "{\nassert(g.size() >0);\nintconstmin_col =\nreturngrid_limits(min_col, max_col);\n}\n", "Before_commit_codebase": "{\nassert(g.size() >0);\nintconstmin_col =\n(*std::min_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n}))\n.second.start;\n\nintconstmax_col = (*std::max_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n}))\n.second.stop;\nreturngrid_limits(min_col, max_col);\n}\n", "After_commit_codebase": "{\nassert(g.size() >0);\nintconstmin_col =\n(*std::min_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n})).second.start;\n\nintconstmax_col =\n(*std::max_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n})).second.stop;\nreturngrid_limits(min_col, max_col);\n}\n"}
{"Commit title": "default token -> string output for symbols", "Commit url": "https://github.com/jaypipes/sqltoast/commit/9ab9674aa601e4cb99ed9b89a51755702c83936e", "Only_addition_codes": "}else{\nout <<symbol_map::to_string(token.symbol);\nreturnout;", "Only_deletion_codes": "if(token.is_punctuator()) {\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}", "Codes_without_addition_and_deletion": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}\nreturnout;\n}", "Before_commit_codebase": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_punctuator()) {\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}\nreturnout;\n}", "After_commit_codebase": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}else{\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}\nreturnout;\n}"}
