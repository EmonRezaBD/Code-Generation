{"Commit title": "LibUnicode: Optimize the canonical composition algorithm implementation", "Commit body": "@@ -208,42 +208,52 @@ static void canonical_ordering_algorithm(Span<u32> code_points)\n//See Section 3.11, D115 of Version 15.0.0 of the Unicode Standard.\nstaticboolis_blocked(Span<u32> code_points,size_ta,size_tc)\n{\nif(!is_starter(code_points[a]) ||a == c -1)\nif(a == c -1)\nreturnfalse;\nautoconstc_combining_class =Unicode::canonical_combining_class(code_points[c]);\nautoconstb_combining_class =Unicode::canonical_combining_class(code_points[c -1]);\nreturnb_combining_class==0|| b_combining_class>= c_combining_class;\nreturnb_combining_class >= c_combining_class;\n}\n\n//The Canonical Composition Algorithm, as specified in Version 15.0.0 of the Unicode Standard.\n//See Section 3.11, D117; and UAX #15 https://unicode.org/reports/tr15\n//https://www.unicode.org/versions/Unicode15.0.0/ch03.pdf#G50628\nstaticvoidcanonical_composition_algorithm(Vector<u32>& code_points)\n{\nif(code_points.size() <=1)\nreturn;\nssize_tlast_starter =is_starter(code_points[0]) ?0: -1;\nfor(size_ti =1; i < code_points.size(); ++i) {\nautoconstcurrent_character = code_points[i];\n//R1. Seek back (left) to find the last Starter L preceding C in the character sequence\nfor(ssize_tj = i -1; j >=0; --j) {\nif(!is_starter(code_points[j]))\ncontinue;\n//R2. If there is such an L, and C is not blocked from L,\n//and there exists a Primary Composite P which is canonically equivalent to <L, C>,\n//then replace L by P in the sequence and delete C from the sequence.\nif(is_blocked(code_points.span(), j, i))\ncontinue;\nif(last_starter == -1) {\nif(is_starter(current_character))\nlast_starter = i;\ncontinue;\n}\n//R2. If there is such an L, and C is not blocked from L,\n//and there exists a Primary Composite P which is canonically equivalent to <L, C>,\n//then replace L by P in the sequence and delete C from the sequence.\nif(is_blocked(code_points.span(), last_starter, i)) {\nif(is_starter(current_character))\nlast_starter = i;\ncontinue;\n}\n\nautocomposite =combine_hangul_code_points(code_points[j], current_character);\nautocomposite =combine_hangul_code_points(code_points[last_starter], current_character);\n\nif(composite ==0)\ncomposite =combine_code_points(code_points[j], current_character);\nif(composite ==0)\ncomposite =combine_code_points(code_points[last_starter], current_character);\n\nif(composite !=0) {\ncode_points[j] = composite;\ncode_points.remove(i);\n--i;\nbreak;\n}\nif(composite ==0) {\nif(is_starter(current_character))\nlast_starter = i;\ncontinue;\n}\n\ncode_points[last_starter] = composite;\ncode_points.remove(i);\n--i;\n}\n}\n\n"}
{"Commit title": "Bump org.mockito:mockito-core from 4.11.0 to 5.12.0", "Commit body": "@@ -16,7 +16,7 @@ ext {\nreactiveStreamsVersion=\"1.0.4\"\njunitVersion=\"4.13.2\"\ntestNgVersion=\"7.5\"\nmockitoVersion=\"4.11.0\"\nmockitoVersion=\"5.12.0\"\njmhLibVersion=\"1.21\"\nguavaVersion=\"33.2.0-jre\"\n}\n"}
{"Commit title": "#22244fix typo", "Commit body": "@@ -70,7 +70,7 @@ tree.sequences.node.tip = MariaDB Sequences\n\nmanager.catalog.name=Catalog manager\n\nparameters.all.caches= Cachemeta data\nparameters.all.caches= Cachemetadata\nparameters.all.caches.tip= Read tables constraints and columns at the stage of reading tables.\\nThis setting may reduce metadata loading performance for small databases and increase for large databases.\n\nmeta.org.jkiss.dbeaver.ext.mysql.model.MySQLCatalog.name.name=Schema Name\n"}
{"Commit title": "AK: Use correct wide integer type for qhat check in UFixedBigIntDivision", "Commit body": "@@ -95,7 +95,7 @@ constexpr void div_mod_internal(\nqhat =div_mod_words(dividend[i -1], dividend[i], divisor_approx, rhat);\n\nautois_qhat_too_large = [&] {\nreturnUFixedBigInt<native_word_size> { qhat }.wide_multiply(divisor[divisor_len -2]) >u128{ dividend[i -2], rhat };\nreturnUFixedBigInt<native_word_size> { qhat }.wide_multiply(divisor[divisor_len -2]) >UFixedBigInt<native_word_size *2>{ dividend[i -2], rhat };\n};\nif(is_qhat_too_large()) {\n--qhat;\n"}
{"Commit title": "#20060Revert JSQLParser to 4.5", "Commit body": "@@ -9,7 +9,7 @@\n<name>DBeaver - 3rd party dependencies</name>\n\n<properties>\n<tycho-version>3.0.0</tycho-version>\n<tycho-version>3.0.1</tycho-version>\n<reficio-p2-version>1.4.1</reficio-p2-version>\n<repo-name>DBeaver CE Update</repo-name>\n</properties>\n@@ -34,7 +34,7 @@\n<id>default-cli</id>\n<configuration>\n<artifacts>\n<artifact><id>com.github.jsqlparser:jsqlparser:4.6</id></artifact>\n<artifact><id>com.github.jsqlparser:jsqlparser:4.5</id></artifact>\n<!--<artifact><id>com.manticore-projects.jsqlformatter:jsqlformatter:0.1.7</id></artifact>-->\n\n<artifact><id>org.apache.commons:commons-jexl3:3.1</id></artifact>\n"}
{"Commit title": "LibPDF: Usedraw_rect()to show debug clipping rects", "Commit body": "@@ -305,12 +305,12 @@ RENDERER_HANDLER(path_append_rect)\n\nvoidRenderer::activate_clip()\n{\nautobounding_box =state().clipping_paths.current.bounding_box();\nautobounding_box =state().clipping_paths.current.bounding_box().to_type<int>();\nm_painter.clear_clip_rect();\nif(m_rendering_preferences.show_clipping_paths) {\nm_painter.stroke_path(rect_path(bounding_box), Color::Black,1);\nm_painter.draw_rect(bounding_box, Color::Black);\n}\nm_painter.add_clip_rect(bounding_box.to_type<int>());\nm_painter.add_clip_rect(bounding_box);\n}\n\nvoidRenderer::deactivate_clip()\n"}
{"Commit title": "#18798escape wild cards during primary and imported keys loading", "Commit body": "@@ -732,8 +732,9 @@ public JDBCStatement prepareUniqueConstraintsLoadStatement(@NotNull JDBCSession\nthrowsSQLException,DBException{\nreturnsession.getMetaData().getPrimaryKeys(\nowner.getCatalog() ==null?null:owner.getCatalog().getName(),\nowner.getSchema() ==null||DBUtils.isVirtualObject(owner.getSchema()) ?null:owner.getSchema().getName(),\nforParent==null?owner.getDataSource().getAllObjectsPattern() :forParent.getName())\nowner.getSchema() ==null||DBUtils.isVirtualObject(owner.getSchema()) ?\nnull:JDBCUtils.escapeWildCards(session,owner.getSchema().getName()),\nforParent==null?owner.getDataSource().getAllObjectsPattern() :JDBCUtils.escapeWildCards(session,forParent.getName()))\n.getSourceStatement();\n}\n\n@@ -749,10 +750,11 @@ public GenericTableForeignKey createTableForeignKeyImpl(GenericTableBase table,\npublicJDBCStatementprepareForeignKeysLoadStatement(@NotNullJDBCSessionsession,@NotNullGenericStructContainerowner,@NullableGenericTableBaseforParent)throwsSQLException{\nreturnsession.getMetaData().getImportedKeys(\nowner.getCatalog() ==null?null:owner.getCatalog().getName(),\nowner.getSchema() ==null||DBUtils.isVirtualObject(owner.getSchema()) ?null:owner.getSchema().getName(),\nowner.getSchema() ==null||DBUtils.isVirtualObject(owner.getSchema()) ?\nnull:JDBCUtils.escapeWildCards(session,owner.getSchema().getName()),\nforParent==null?\nowner.getDataSource().getAllObjectsPattern() :\nforParent.getName())\nJDBCUtils.escapeWildCards(session,forParent.getName()))\n.getSourceStatement();\n}\n\n"}
{"Commit title": "LibIPC: Use a simpler encoding for arithmetic values", "Commit body": "@@ -40,11 +40,6 @@ class Encoder {\nreturnm_buffer.data.try_ensure_capacity(m_buffer.data.size() + capacity);\n}\n\nvoidappend(u8 value)\n{\nm_buffer.data.unchecked_append(value);\n}\n\nErrorOr<void>append(u8const* values,size_tcount)\n{\nTRY(extend_capacity(count));\n@@ -67,31 +62,7 @@ class Encoder {\ntemplate<Arithmetic T>\nErrorOr<void>encode(Encoder& encoder, Tconst& value)\n{\nTRY(encoder.extend_capacity(sizeof(T)));\n\nifconstexpr(sizeof(T) ==1) {\nencoder.append(static_cast<u8>(value));\n}elseifconstexpr(sizeof(T) ==2) {\nencoder.append(static_cast<u8>(value));\nencoder.append(static_cast<u8>(value >>8));\n}elseifconstexpr(sizeof(T) ==4) {\nencoder.append(static_cast<u8>(value));\nencoder.append(static_cast<u8>(value >>8));\nencoder.append(static_cast<u8>(value >>16));\nencoder.append(static_cast<u8>(value >>24));\n}elseifconstexpr(sizeof(T) ==8) {\nencoder.append(static_cast<u8>(value));\nencoder.append(static_cast<u8>(value >>8));\nencoder.append(static_cast<u8>(value >>16));\nencoder.append(static_cast<u8>(value >>24));\nencoder.append(static_cast<u8>(value >>32));\nencoder.append(static_cast<u8>(value >>40));\nencoder.append(static_cast<u8>(value >>48));\nencoder.append(static_cast<u8>(value >>56));\n}else{\nstatic_assert(DependentFalse<T>);\n}\n\nTRY(encoder.append(reinterpret_cast<u8const*>(&value),sizeof(value)));\nreturn{};\n}\n\n"}
{"Commit title": "HackStudio: Remove adjustment of text range for documentation tooltip", "Commit body": "@@ -263,11 +263,8 @@ void Editor::mousemove_event(GUI::MouseEvent& event)\n}\n\nif(span.range.contains(text_position)) {\nautoadjusted_range = span.range;\nautoend_line_length =document().line(span.range.end().line()).length();\nadjusted_range.end().set_column(min(end_line_length, adjusted_range.end().column() +1));\nautohovered_span_text =document().text_in_range(adjusted_range);\ndbgln_if(EDITOR_DEBUG,\"Hovering: {}\\\"{}\\\"\", adjusted_range, hovered_span_text);\nautohovered_span_text =document().text_in_range(span.range);\ndbgln_if(EDITOR_DEBUG,\"Hovering: {}\\\"{}\\\"\", span.range, hovered_span_text);\n\nif(is_clickable) {\nis_over_clickable =true;\n"}
{"Commit title": "#17675read enum values specifically for new added types", "Commit body": "@@ -314,6 +314,27 @@ private void readEnumValues(@NotNull DBRProgressMonitor monitor) throws DBExcept\n.toArray();\n}\n\nprivatevoidreadNewEnumValues(DBRProgressMonitormonitor)throwsDBException{\ntry(JDBCSessionsession=DBUtils.openMetaSession(monitor,this,\"Refresh enum values\")) {\ntry(JDBCPreparedStatementdbStat=session.prepareStatement(\n\"SELECT e.enumlabel\\n\"+\n\"FROM pg_catalog.pg_enum e\\n\"+\n\"WHERE e.enumtypid=?\\n\"+\n\"ORDER BY e.enumsortorder\")) {\ndbStat.setLong(1,getObjectId());\ntry(JDBCResultSetrs=dbStat.executeQuery()) {\nList<String>values=newArrayList<>();\nwhile(rs.nextRow()) {\nvalues.add(JDBCUtils.safeGetString(rs,1));\n}\nenumValues=values.toArray();\n}\n}catch(SQLExceptione) {\nthrownewDBException(\"Error reading enum values\",e,getDataSource());\n}\n}\n}\n\npublicstaticString[]getOidTypes() {\nreturnOID_TYPES;\n}\n@@ -627,9 +648,13 @@ public DBSObject refreshObject(@NotNull DBRProgressMonitor monitor) throws DBExc\n\n@Property(viewable=true,order=16,visibleIf=EnumTypeValidator.class)\npublicObject[]getEnumValues(DBRProgressMonitormonitor) {\nif(typeCategory==PostgreTypeCategory.E&&enumValues==null) {\nif(typeCategory==PostgreTypeCategory.E&&ArrayUtils.isEmpty(enumValues)) {\ntry{\nreadEnumValues(monitor);\nif(ArrayUtils.isEmpty(enumValues)) {\n// Probably new objects not cached yet. Let's read them.\nreadNewEnumValues(monitor);\n}\n}catch(DBExceptione) {\nlog.error(\"Can't read enum values of type \"+getFullTypeName());\nenumValues=newObject[]{0};\n"}
{"Commit title": "LibUnicode: Make unicode data generation logic more relocatable", "Commit body": "@@ -30,31 +30,25 @@ if (ENABLE_UNICODE_DATABASE_DOWNLOAD)\nfile(DOWNLOAD${WORD_BREAK_URL}${WORD_BREAK_PATH}INACTIVITY_TIMEOUT 10)\nendif()\n\nset(UNICODE_GENERATOR CodeGenerators/GenerateUnicodeData)\nset(UNICODE_DATA_HEADER UnicodeData.h)\nset(UNICODE_DATA_IMPLEMENTATION UnicodeData.cpp)\nset(UNICODE_DATA_HEADER LibUnicode/UnicodeData.h)\nset(UNICODE_DATA_IMPLEMENTATION LibUnicode/UnicodeData.cpp)\n\nif(CMAKE_SOURCE_DIRMATCHES\".*/Lagom\")#Lagom-only build.\nset(UNICODE_GENERATOR LibUnicode/CodeGenerators/GenerateUnicodeData)\nset(UNICODE_DATA_HEADER LibUnicode/UnicodeData.h)\nset(UNICODE_DATA_IMPLEMENTATION LibUnicode/UnicodeData.cpp)\nelseif(CMAKE_CURRENT_BINARY_DIRMATCHES\".*/Lagom\")#Lagom build within the main SerenityOS build.\nset(UNICODE_GENERATOR ../../Userland/Libraries/LibUnicode/CodeGenerators/GenerateUnicodeData)\nset(UNICODE_DATA_HEADER LibUnicode/UnicodeData.h)\nset(UNICODE_DATA_IMPLEMENTATION LibUnicode/UnicodeData.cpp)\nif(CMAKE_CURRENT_BINARY_DIRMATCHES\".*/LibUnicode\")#Serenity build.\nset(UNICODE_DATA_HEADER UnicodeData.h)\nset(UNICODE_DATA_IMPLEMENTATION UnicodeData.cpp)\nendif()\n\nadd_custom_command(\nOUTPUT${UNICODE_DATA_HEADER}\nCOMMAND${write_if_different}${UNICODE_DATA_HEADER}${UNICODE_GENERATOR}-h -u${UNICODE_DATA_PATH}-s${SPECIAL_CASING_PATH}-p${PROP_LIST_PATH}-w${WORD_BREAK_PATH}\nCOMMAND${write_if_different}${UNICODE_DATA_HEADER}$<TARGET_FILE:GenerateUnicodeData>-h -u${UNICODE_DATA_PATH}-s${SPECIAL_CASING_PATH}-p${PROP_LIST_PATH}-w${WORD_BREAK_PATH}\nVERBATIM\nDEPENDSGenerateUnicodeData\nMAIN_DEPENDENCY${UNICODE_DATA_PATH}${SPECIAL_CASING_PATH}\n)\n\nadd_custom_command(\nOUTPUT${UNICODE_DATA_IMPLEMENTATION}\nCOMMAND${write_if_different}${UNICODE_DATA_IMPLEMENTATION}${UNICODE_GENERATOR}-c -u${UNICODE_DATA_PATH}-s${SPECIAL_CASING_PATH}-p${PROP_LIST_PATH}-w${WORD_BREAK_PATH}\nCOMMAND${write_if_different}${UNICODE_DATA_IMPLEMENTATION}$<TARGET_FILE:GenerateUnicodeData>-c -u${UNICODE_DATA_PATH}-s${SPECIAL_CASING_PATH}-p${PROP_LIST_PATH}-w${WORD_BREAK_PATH}\nVERBATIM\nDEPENDSGenerateUnicodeData\nMAIN_DEPENDENCY${UNICODE_DATA_PATH}${SPECIAL_CASING_PATH}\n"}
{"Commit title": "LibGfx: Remove unused headers from BitmapFont.{cpp,h}", "Commit body": "@@ -5,20 +5,11 @@\n*/\n\n#include\"BitmapFont.h\"\n#include\"Bitmap.h\"\n#include\"Emoji.h\"\n#include<AK/StdLibExtras.h>\n#include<AK/StringBuilder.h>\n#include<AK/Utf32View.h>\n#include<AK/Utf8View.h>\n#include<AK/Vector.h>\n#include<LibCore/FileStream.h>\n#include<LibGfx/FontDatabase.h>\n#include<stdio.h>\n#include<stdlib.h>\n#include<string.h>\n#include<sys/mman.h>\n#include<unistd.h>\n\nnamespaceGfx{\n\n"}
{"Commit title": "LibGUI: Account for the row and column headers when painting a TableView", "Commit body": "@@ -73,8 +73,8 @@ void TableView::paint_event(PaintEvent& event)\ninty_offset =column_header().is_visible() ?column_header().height() :0;\n\nbooldummy;\nintfirst_visible_row =index_at_event_position(frame_inner_rect().top_left(), dummy).row();\nintlast_visible_row =index_at_event_position(frame_inner_rect().bottom_right(), dummy).row();\nintfirst_visible_row =index_at_event_position(frame_inner_rect().top_left().translated(x_offset, y_offset), dummy).row();\nintlast_visible_row =index_at_event_position(frame_inner_rect().bottom_right().translated(x_offset, y_offset), dummy).row();\n\nif(first_visible_row == -1)\nfirst_visible_row =0;\n"}
{"Commit title": "Allow/Fix special characters in json replies in WebUI", "Code difference": "@@ -76,9 +76,7 @@ QString json::toJson(const QVariant& v) {\nresult +=\"\\\\t\";\nbreak;\ncase'\\\"':\ncase'\\'':\ncase'\\\\':\ncase'&':\nresult +='\\\\';\ncase'\\0':\ndefault:\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Add tooltip to episode filter text edit", "Code difference": "@@ -73,6 +73,16 @@ AutomatedRssDownloader::AutomatedRssDownloader(const QWeakPointer<RssManager>& m\nQt::CaseInsensitive),\nui->lineEFilter);\nui->lineEFilter->setValidator(m_episodeValidator);\nQString tip =\"<p>\"+tr(\"Matches articles based on episode filter.\") +\"</p><p><b>\"+tr(\"Example:\") +\n\"1x2;8-15;5;30-;</b>\"+tr(\"will match 2, 5, 8 through 15, 30 and onward episodes of season one\",\"example X will match\") +\"</p>\";\ntip +=\"<p>\"+tr(\"Episode filter rules:\") +\"</p><ul><li>\"+tr(\"Season number is a mandatory non-zero value\") +\"</li>\"+\n\"<li>\"+tr(\"Episode number is a mandatory non-zero value\") +\"</li>\"+\n\"<li>\"+tr(\"Filter must end with semicolon\") +\"</li>\"+\n\"<li>\"+tr(\"Three range types for episodes are supported:\") +\"</li>\"+\"<li><ul>\"\n\"<li>\"+tr(\"Single number: <b>1x25;</b> matches episode 25 of season one\") +\"</li>\"+\n\"<li>\"+tr(\"Normal range: <b>1x25-40;</b> matches episodes 25 through 40 of season one\") +\"</li>\"+\n\"<li>\"+tr(\"Infinite range: <b>1x25-;</b> matches 40 and onward episodes of season one\") +\"</li>\"+\"</ul></li></ul>\";\nui->lineEFilter->setToolTip(tip);\ninitLabelCombobox();\nloadFeedList();\nloadSettings();\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix crash when delete RSS feed", "Code difference": "@@ -137,6 +137,7 @@ void FeedListWidget::handleItemPathChanged(RSS::Item *rssItem)\n\nvoidFeedListWidget::handleItemAboutToBeRemoved(RSS::Item *rssItem)\n{\nrssItem->disconnect(this);\ndeletem_rssToTreeItemMapping.take(rssItem);\n\n//RSS Item is still valid in this slot so if it is the last\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Change MixedModeAlgorithm default to TCP.Closes#7779.", "Code difference": "@@ -304,7 +304,7 @@ Session::Session(QObject *parent)\n, m_btProtocol(BITTORRENT_SESSION_KEY(\"BTProtocol\"), BTProtocol::Both\n, clampValue(BTProtocol::Both, BTProtocol::UTP))\n, m_isUTPRateLimited(BITTORRENT_SESSION_KEY(\"uTPRateLimited\"),true)\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::Proportional\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::TCP\n, clampValue(MixedModeAlgorithm::TCP, MixedModeAlgorithm::Proportional))\n, m_multiConnectionsPerIpEnabled(BITTORRENT_SESSION_KEY(\"MultiConnectionsPerIp\"),false)\n, m_isAddTrackersEnabled(BITTORRENT_SESSION_KEY(\"AddTrackersEnabled\"),false)\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Use a more detailed alert mask where possible", "Code difference": "@@ -392,7 +392,11 @@ Session::Session(QObject *parent)\n| libt::alert::tracker_notification\n| libt::alert::status_notification\n| libt::alert::ip_block_notification\n#ifLIBTORRENT_VERSION_NUM < 10110\n| libt::alert::progress_notification\n#else\n| libt::alert::file_progress_notification\n#endif\n| libt::alert::stats_notification;\n\n#ifLIBTORRENT_VERSION_NUM < 10100\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Change number of time axis divisions from 5 to 6 for convenience", "Code difference": "@@ -327,11 +327,11 @@ void SpeedPlotView::paintEvent(QPaintEvent *)\npainter.drawLine(fullRect.left(), rect.top() +0.75* rect.height(), rect.right(), rect.top() +0.75* rect.height());\npainter.drawLine(fullRect.left(), rect.bottom(), rect.right(), rect.bottom());\n\npainter.drawLine(rect.left(), fullRect.top(), rect.left(), fullRect.bottom());\npainter.drawLine(rect.left() +0.2* rect.width(), fullRect.top(), rect.left() +0.2* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.4* rect.width(), fullRect.top(),rect.left() +0.4* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.6* rect.width(), fullRect.top(),rect.left() +0.6* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.8* rect.width(), fullRect.top(), rect.left() +0.8* rect.width(), fullRect.bottom());\nconstintTIME_AXIS_DIVISIONS =6;\nfor(inti =0; i < TIME_AXIS_DIVISIONS; ++i) {\nconstintx =rect.left() +(i* rect.width()) / TIME_AXIS_DIVISIONS;\npainter.drawLine(x, fullRect.top(),x, fullRect.bottom());\n}\n\n//Set antialiasing for graphs\npainter.setRenderHints(QPainter::Antialiasing | QPainter::HighQualityAntialiasing);\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Run all passing json against parse_many. Empty documents pass, too.", "Code difference": "@@ -83,17 +83,21 @@ bool validate(const char *dirname) {\nif(contains(\"EXCLUDE\", name)) {\n//skipping\nhow_many--;\n}elseif(starts_with(\"pass\", name)and(has_extension(extension1, name)orhas_extension(extension2, name))anderror) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"fail\", name)and(notstarts_with(\"fail10.json\", name))and!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"pass\", name)orstarts_with(\"fail10.json\", name)orstarts_with(\"fail70.json\", name)) {\nif(error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}elseif(starts_with(\"fail\", name) ) {\nif(!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}\nfree(fullpath);\n}\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix arm64 build", "Code difference": "@@ -140,7 +140,7 @@ WARN_UNUSED error_code dom_parser_implementation::stage1(const uint8_t *_buf, si\n}\n\nWARN_UNUSEDboolimplementation::validate_utf8(constchar*buf,size_tlen)constnoexcept{\nreturnsimdjson::arm64::stage1::generic_validate_utf8(buf,len);\nreturnarm64::stage1::generic_validate_utf8(buf,len);\n}\n\nWARN_UNUSED error_codedom_parser_implementation::stage2(dom::document &_doc)noexcept{\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "This makes the float errors explicit.", "Code difference": "@@ -2,6 +2,7 @@\n\n#include<vector>\n#include<sstream>\n#include<limits>\n\ntemplate<typenameT>\nstaticbooldiff_results(benchmark::State &state,constT &result,constT &reference);\n@@ -19,6 +20,24 @@ struct result_differ {\n}\n};\n\ntemplate<>\nboolresult_differ<double>::diff(benchmark::State &state,constdouble&result,constdouble&reference) {\nif(result != reference) {\nstd::stringstream str;\n//We print it out using full precision.\nautoprior_precision = str.precision(std::numeric_limits<double>::max_digits10);\nstr <<\"result incorrect:\"<< result <<\"... reference:\"<< reference;\nstr.precision(prior_precision);//reset to prior state\nstr << std::hexfloat;//If there are floats, we want to see them in hexadecimal form!\nstr <<\"result incorrect (hexadecimal notation):\"<< result <<\"... reference:\"<< reference;\nstr << std::defaultfloat;//reset to prior state\nstate.SkipWithError(str.str().data());\nreturnfalse;\n}\nreturntrue;\n}\n\n\ntemplate<typenameT>\nstructresult_differ<std::vector<T>> {\nstaticbooldiff(benchmark::State &state,conststd::vector<T> &result,conststd::vector<T> &reference) {\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix clang-format violation", "Code difference": "@@ -347,5 +347,4 @@ void ACameraDirector::notifyViewModeChanged()\nUWorld* world =GetWorld();\nUGameViewportClient* gameViewport = world->GetGameViewport();\ngameViewport->bDisableWorldRendering= nodisplay;\n\n}", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "GenericDocument: forward allocator to GenericReader", "Code difference": "@@ -719,7 +719,7 @@ class GenericDocument : public GenericValue<Encoding, Allocator> {\ntemplate<unsignedparseFlags,typenameSourceEncoding,typenameInputStream>\nGenericDocument&ParseStream(InputStream& is) {\nValueType::SetNull();//Remove existing root if exist\nGenericReader<SourceEncoding, Encoding, Allocator> reader;\nGenericReader<SourceEncoding, Encoding, Allocator>reader(&GetAllocator());\nif(reader.templateParse<parseFlags>(is, *this)) {\nRAPIDJSON_ASSERT(stack_.GetSize() ==sizeof(ValueType));//Got one and only one root object\nthis->RawAssign(*stack_.templatePop<ValueType>(1));//Add this-> to prevent issue 13.\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "DoublePrecision: add a unit test for the precision handling", "Code difference": "@@ -1,4 +1,5 @@\n#include\"unittest.h\"\n#include\"rapidjson/document.h\"\n#include\"rapidjson/reader.h\"\n#include\"rapidjson/writer.h\"\n#include\"rapidjson/stringbuffer.h\"\n@@ -56,6 +57,61 @@ TEST(Writer, String) {\nTEST_ROUNDTRIP(\"[\\\"\\\\\\\"\\\\\\\\/\\\\b\\\\f\\\\n\\\\r\\\\t\\\"]\");\n}\n\nTEST(Writer,DoublePrecision) {\nconstcharjson[] =\"[1.2345,1.2345678,0.123456789012,1234567.8]\";\n\nStringBuffer buffer;\nWriter<StringBuffer>writer(buffer);\n\nconstintkDefaultDoublePrecision=6;\n//handling the double precision\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nwriter.SetDoublePrecision(17);\nEXPECT_EQ(writer.GetDoublePrecision(),17);\nwriter.SetDoublePrecision(-1);//negative equivalent to reset\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nwriter.SetDoublePrecision(1);\nwriter.SetDoublePrecision();//reset again\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\n\n{//write with explicitly increased precision\nStringStreams(json);\nReader reader;\nreader.Parse<0>(s, writer.SetDoublePrecision(12));\nEXPECT_EQ(writer.GetDoublePrecision(),12);\nEXPECT_STREQ(json, buffer.GetString());\nbuffer.Clear();\n}\n{//explicit individual double precisions\nwriter.SetDoublePrecision(2)\n.StartArray()\n.Double(1.2345,5)\n.Double(1.2345678,9)\n.Double(0.123456789012,12)\n.Double(1234567.8,8)\n.EndArray();\n\nEXPECT_EQ(writer.GetDoublePrecision(),2);\nEXPECT_STREQ(json, buffer.GetString());\nbuffer.Clear();\n}\n{//write with default precision (output with precision loss)\nDocument d;\nd.Parse<0>(json);\nd.Accept(writer.SetDoublePrecision());\n\n//parsed again to avoid platform-dependent floating point outputs\n//(e.g. width of exponents)\nd.Parse<0>(buffer.GetString());\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nEXPECT_DOUBLE_EQ(d[0u].GetDouble(),1.2345);\nEXPECT_DOUBLE_EQ(d[1u].GetDouble(),1.23457);\nEXPECT_DOUBLE_EQ(d[2u].GetDouble(),0.123457);\nEXPECT_DOUBLE_EQ(d[3u].GetDouble(),1234570);\nbuffer.Clear();\n}\n}\n\nTEST(Writer, Transcode) {\n//UTF8 -> UTF16 -> UTF8\nStringStreams(\"{\\\"hello\\\":\\\"world\\\",\\\"t\\\": true ,\\\"f\\\": false,\\\"n\\\": null,\\\"i\\\":123,\\\"pi\\\": 3.1416,\\\"a\\\":[1, 2, 3],\\\"dollar\\\":\\\"\\x24\\\",\\\"cents\\\":\\\"\\xC2\\xA2\\\",\\\"euro\\\":\\\"\\xE2\\x82\\xAC\\\",\\\"gclef\\\":\\\"\\xF0\\x9D\\x84\\x9E\\\"}\");\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Allow/Fix special characters in json replies in WebUI", "Code difference": "@@ -76,9 +76,7 @@ QString json::toJson(const QVariant& v) {\nresult +=\"\\\\t\";\nbreak;\ncase'\\\"':\ncase'\\'':\ncase'\\\\':\ncase'&':\nresult +='\\\\';\ncase'\\0':\ndefault:\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Add tooltip to episode filter text edit", "Code difference": "@@ -73,6 +73,16 @@ AutomatedRssDownloader::AutomatedRssDownloader(const QWeakPointer<RssManager>& m\nQt::CaseInsensitive),\nui->lineEFilter);\nui->lineEFilter->setValidator(m_episodeValidator);\nQString tip =\"<p>\"+tr(\"Matches articles based on episode filter.\") +\"</p><p><b>\"+tr(\"Example:\") +\n\"1x2;8-15;5;30-;</b>\"+tr(\"will match 2, 5, 8 through 15, 30 and onward episodes of season one\",\"example X will match\") +\"</p>\";\ntip +=\"<p>\"+tr(\"Episode filter rules:\") +\"</p><ul><li>\"+tr(\"Season number is a mandatory non-zero value\") +\"</li>\"+\n\"<li>\"+tr(\"Episode number is a mandatory non-zero value\") +\"</li>\"+\n\"<li>\"+tr(\"Filter must end with semicolon\") +\"</li>\"+\n\"<li>\"+tr(\"Three range types for episodes are supported:\") +\"</li>\"+\"<li><ul>\"\n\"<li>\"+tr(\"Single number: <b>1x25;</b> matches episode 25 of season one\") +\"</li>\"+\n\"<li>\"+tr(\"Normal range: <b>1x25-40;</b> matches episodes 25 through 40 of season one\") +\"</li>\"+\n\"<li>\"+tr(\"Infinite range: <b>1x25-;</b> matches 40 and onward episodes of season one\") +\"</li>\"+\"</ul></li></ul>\";\nui->lineEFilter->setToolTip(tip);\ninitLabelCombobox();\nloadFeedList();\nloadSettings();\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix crash when delete RSS feed", "Code difference": "@@ -137,6 +137,7 @@ void FeedListWidget::handleItemPathChanged(RSS::Item *rssItem)\n\nvoidFeedListWidget::handleItemAboutToBeRemoved(RSS::Item *rssItem)\n{\nrssItem->disconnect(this);\ndeletem_rssToTreeItemMapping.take(rssItem);\n\n//RSS Item is still valid in this slot so if it is the last\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Change MixedModeAlgorithm default to TCP.Closes#7779.", "Code difference": "@@ -304,7 +304,7 @@ Session::Session(QObject *parent)\n, m_btProtocol(BITTORRENT_SESSION_KEY(\"BTProtocol\"), BTProtocol::Both\n, clampValue(BTProtocol::Both, BTProtocol::UTP))\n, m_isUTPRateLimited(BITTORRENT_SESSION_KEY(\"uTPRateLimited\"),true)\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::Proportional\n, m_utpMixedMode(BITTORRENT_SESSION_KEY(\"uTPMixedMode\"), MixedModeAlgorithm::TCP\n, clampValue(MixedModeAlgorithm::TCP, MixedModeAlgorithm::Proportional))\n, m_multiConnectionsPerIpEnabled(BITTORRENT_SESSION_KEY(\"MultiConnectionsPerIp\"),false)\n, m_isAddTrackersEnabled(BITTORRENT_SESSION_KEY(\"AddTrackersEnabled\"),false)\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Use a more detailed alert mask where possible", "Code difference": "@@ -392,7 +392,11 @@ Session::Session(QObject *parent)\n| libt::alert::tracker_notification\n| libt::alert::status_notification\n| libt::alert::ip_block_notification\n#ifLIBTORRENT_VERSION_NUM < 10110\n| libt::alert::progress_notification\n#else\n| libt::alert::file_progress_notification\n#endif\n| libt::alert::stats_notification;\n\n#ifLIBTORRENT_VERSION_NUM < 10100\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Change number of time axis divisions from 5 to 6 for convenience", "Code difference": "@@ -327,11 +327,11 @@ void SpeedPlotView::paintEvent(QPaintEvent *)\npainter.drawLine(fullRect.left(), rect.top() +0.75* rect.height(), rect.right(), rect.top() +0.75* rect.height());\npainter.drawLine(fullRect.left(), rect.bottom(), rect.right(), rect.bottom());\n\npainter.drawLine(rect.left(), fullRect.top(), rect.left(), fullRect.bottom());\npainter.drawLine(rect.left() +0.2* rect.width(), fullRect.top(), rect.left() +0.2* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.4* rect.width(), fullRect.top(),rect.left() +0.4* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.6* rect.width(), fullRect.top(),rect.left() +0.6* rect.width(), fullRect.bottom());\npainter.drawLine(rect.left() +0.8* rect.width(), fullRect.top(), rect.left() +0.8* rect.width(), fullRect.bottom());\nconstintTIME_AXIS_DIVISIONS =6;\nfor(inti =0; i < TIME_AXIS_DIVISIONS; ++i) {\nconstintx =rect.left() +(i* rect.width()) / TIME_AXIS_DIVISIONS;\npainter.drawLine(x, fullRect.top(),x, fullRect.bottom());\n}\n\n//Set antialiasing for graphs\npainter.setRenderHints(QPainter::Antialiasing | QPainter::HighQualityAntialiasing);\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Run all passing json against parse_many. Empty documents pass, too.", "Code difference": "@@ -83,17 +83,21 @@ bool validate(const char *dirname) {\nif(contains(\"EXCLUDE\", name)) {\n//skipping\nhow_many--;\n}elseif(starts_with(\"pass\", name)and(has_extension(extension1, name)orhas_extension(extension2, name))anderror) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"fail\", name)and(notstarts_with(\"fail10.json\", name))and!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}elseif(starts_with(\"pass\", name)orstarts_with(\"fail10.json\", name)orstarts_with(\"fail70.json\", name)) {\nif(error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should pass but it fails. Error is: %s\\n\",\nname,error_message(error));\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}elseif(starts_with(\"fail\", name) ) {\nif(!error) {\nis_file_as_expected[i] =false;\nprintf(\"warning: file %s should fail but it passes.\\n\", name);\nprintf(\"size of file in bytes: %zu\\n\", json.size());\neverything_fine =false;\n}\n}\nfree(fullpath);\n}\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix arm64 build", "Code difference": "@@ -140,7 +140,7 @@ WARN_UNUSED error_code dom_parser_implementation::stage1(const uint8_t *_buf, si\n}\n\nWARN_UNUSEDboolimplementation::validate_utf8(constchar*buf,size_tlen)constnoexcept{\nreturnsimdjson::arm64::stage1::generic_validate_utf8(buf,len);\nreturnarm64::stage1::generic_validate_utf8(buf,len);\n}\n\nWARN_UNUSED error_codedom_parser_implementation::stage2(dom::document &_doc)noexcept{\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "This makes the float errors explicit.", "Code difference": "@@ -2,6 +2,7 @@\n\n#include<vector>\n#include<sstream>\n#include<limits>\n\ntemplate<typenameT>\nstaticbooldiff_results(benchmark::State &state,constT &result,constT &reference);\n@@ -19,6 +20,24 @@ struct result_differ {\n}\n};\n\ntemplate<>\nboolresult_differ<double>::diff(benchmark::State &state,constdouble&result,constdouble&reference) {\nif(result != reference) {\nstd::stringstream str;\n//We print it out using full precision.\nautoprior_precision = str.precision(std::numeric_limits<double>::max_digits10);\nstr <<\"result incorrect:\"<< result <<\"... reference:\"<< reference;\nstr.precision(prior_precision);//reset to prior state\nstr << std::hexfloat;//If there are floats, we want to see them in hexadecimal form!\nstr <<\"result incorrect (hexadecimal notation):\"<< result <<\"... reference:\"<< reference;\nstr << std::defaultfloat;//reset to prior state\nstate.SkipWithError(str.str().data());\nreturnfalse;\n}\nreturntrue;\n}\n\n\ntemplate<typenameT>\nstructresult_differ<std::vector<T>> {\nstaticbooldiff(benchmark::State &state,conststd::vector<T> &result,conststd::vector<T> &reference) {\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Fix clang-format violation", "Code difference": "@@ -347,5 +347,4 @@ void ACameraDirector::notifyViewModeChanged()\nUWorld* world =GetWorld();\nUGameViewportClient* gameViewport = world->GetGameViewport();\ngameViewport->bDisableWorldRendering= nodisplay;\n\n}", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "GenericDocument: forward allocator to GenericReader", "Code difference": "@@ -719,7 +719,7 @@ class GenericDocument : public GenericValue<Encoding, Allocator> {\ntemplate<unsignedparseFlags,typenameSourceEncoding,typenameInputStream>\nGenericDocument&ParseStream(InputStream& is) {\nValueType::SetNull();//Remove existing root if exist\nGenericReader<SourceEncoding, Encoding, Allocator> reader;\nGenericReader<SourceEncoding, Encoding, Allocator>reader(&GetAllocator());\nif(reader.templateParse<parseFlags>(is, *this)) {\nRAPIDJSON_ASSERT(stack_.GetSize() ==sizeof(ValueType));//Got one and only one root object\nthis->RawAssign(*stack_.templatePop<ValueType>(1));//Add this-> to prevent issue 13.\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "DoublePrecision: add a unit test for the precision handling", "Code difference": "@@ -1,4 +1,5 @@\n#include\"unittest.h\"\n#include\"rapidjson/document.h\"\n#include\"rapidjson/reader.h\"\n#include\"rapidjson/writer.h\"\n#include\"rapidjson/stringbuffer.h\"\n@@ -56,6 +57,61 @@ TEST(Writer, String) {\nTEST_ROUNDTRIP(\"[\\\"\\\\\\\"\\\\\\\\/\\\\b\\\\f\\\\n\\\\r\\\\t\\\"]\");\n}\n\nTEST(Writer,DoublePrecision) {\nconstcharjson[] =\"[1.2345,1.2345678,0.123456789012,1234567.8]\";\n\nStringBuffer buffer;\nWriter<StringBuffer>writer(buffer);\n\nconstintkDefaultDoublePrecision=6;\n//handling the double precision\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nwriter.SetDoublePrecision(17);\nEXPECT_EQ(writer.GetDoublePrecision(),17);\nwriter.SetDoublePrecision(-1);//negative equivalent to reset\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nwriter.SetDoublePrecision(1);\nwriter.SetDoublePrecision();//reset again\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\n\n{//write with explicitly increased precision\nStringStreams(json);\nReader reader;\nreader.Parse<0>(s, writer.SetDoublePrecision(12));\nEXPECT_EQ(writer.GetDoublePrecision(),12);\nEXPECT_STREQ(json, buffer.GetString());\nbuffer.Clear();\n}\n{//explicit individual double precisions\nwriter.SetDoublePrecision(2)\n.StartArray()\n.Double(1.2345,5)\n.Double(1.2345678,9)\n.Double(0.123456789012,12)\n.Double(1234567.8,8)\n.EndArray();\n\nEXPECT_EQ(writer.GetDoublePrecision(),2);\nEXPECT_STREQ(json, buffer.GetString());\nbuffer.Clear();\n}\n{//write with default precision (output with precision loss)\nDocument d;\nd.Parse<0>(json);\nd.Accept(writer.SetDoublePrecision());\n\n//parsed again to avoid platform-dependent floating point outputs\n//(e.g. width of exponents)\nd.Parse<0>(buffer.GetString());\nEXPECT_EQ(writer.GetDoublePrecision(),kDefaultDoublePrecision);\nEXPECT_DOUBLE_EQ(d[0u].GetDouble(),1.2345);\nEXPECT_DOUBLE_EQ(d[1u].GetDouble(),1.23457);\nEXPECT_DOUBLE_EQ(d[2u].GetDouble(),0.123457);\nEXPECT_DOUBLE_EQ(d[3u].GetDouble(),1234570);\nbuffer.Clear();\n}\n}\n\nTEST(Writer, Transcode) {\n//UTF8 -> UTF16 -> UTF8\nStringStreams(\"{\\\"hello\\\":\\\"world\\\",\\\"t\\\": true ,\\\"f\\\": false,\\\"n\\\": null,\\\"i\\\":123,\\\"pi\\\": 3.1416,\\\"a\\\":[1, 2, 3],\\\"dollar\\\":\\\"\\x24\\\",\\\"cents\\\":\\\"\\xC2\\xA2\\\",\\\"euro\\\":\\\"\\xE2\\x82\\xAC\\\",\\\"gclef\\\":\\\"\\xF0\\x9D\\x84\\x9E\\\"}\");\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "- Fixed a build issue by initializing \"index\" in the header file", "Code difference": "@@ -899,7 +899,7 @@ class Schema {\n}\n}\n\nSizeTypeindex;\nSizeTypeindex=0;\nif(FindPropertyIndex(ValueType(str, len).Move(), &index)) {\nif(context.patternPropertiesSchemaCount>0) {\ncontext.patternPropertiesSchemas[context.patternPropertiesSchemaCount++] = properties_[index].schema;\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "replace auto with concrete type", "Code difference": "@@ -33,8 +33,8 @@ TEST(Platform, GetObject) {\nEXPECT_TRUE(doc.HasMember(\"object\"));\nconstDocument::ValueType& o = doc[\"object\"];\nEXPECT_TRUE(o.IsObject());\nautosub = o.GetObject();\nValue::ConstObjectsub = o.GetObject();\nEXPECT_TRUE(sub.HasMember(\"pi\"));\nautosub2 = o.GetObj();\nValue::ConstObjectsub2 = o.GetObj();\nEXPECT_TRUE(sub2.HasMember(\"pi\"));\n}", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "Move profiling option help message to devhelp", "Code difference": "@@ -543,9 +543,6 @@ static void printUsage( const char *name, bool devhelp ) {\n\"mounted at the specified PATH. This checks that the device at PATH\\n\"\n\"is currently mounted and that any data files get written to the\\n\"\n\"same device.\\n\");\nprintf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold.\\n\");\n#endif\nprintf(\"-d PATH, --datadir PATH\\n\"\n\"Store data files in the given folder (must be unique for each\\n\");\n@@ -619,6 +616,12 @@ static void printUsage( const char *name, bool devhelp ) {\nprintf(\"--num_testers NUM\\n\");\nprintf(\"A multitester will wait for NUM testers before starting\\n\");\nprintf(\"(defaults to 1).\\n\");\n#ifdef__linux__\nprintf(\"--rsssize SIZE\\n\"\n\"Turns on automatic heap profiling when RSS memory size exceeds\\n\"\n\"the given threshold. fdbserver needs to be compiled with\\n\"\n\"USE_GPERFTOOLS flag in order to use this feature.\\n\");\n#endif\nprintf(\"--testservers ADDRESSES\\n\");\nprintf(\"The addresses of networktestservers\\n\");\nprintf(\"specified as ADDRESS:PORT,ADDRESS:PORT...\\n\");\n", "Added lines (+)": "", "Removed lines (-)": ""}
{"Commit title": "view_update_generator: Dump throughput and duration for view update f…", "Code difference": "@@ -16,6 +16,7 @@\n#include\"sstables/progress_monitor.hh\"\n#include\"readers/evictable.hh\"\n#include\"dht/partition_filter.hh\"\n#include\"utils/pretty_printers.hh\"\n\nstaticlogging::loggervug_logger(\"view_update_generator\");\n\n@@ -127,9 +128,9 @@ future<> view_update_generator::start() {\nauto& [t, sstables] = *table_it;\nschema_ptr s = t->schema();\n\nvug_logger.trace(\"Processing {}.{}: {} sstables\", s->ks_name(), s->cf_name(), sstables.size());\n\nconstautonum_sstables = sstables.size();\nautostart_time =db_clock::now();\nuint64_tinput_size =0;\n\ntry{\n//Exploit the fact that sstables in the staging directory\n@@ -138,8 +139,12 @@ future<> view_update_generator::start() {\nautossts = make_lw_shared<sstables::sstable_set>(sstables::make_partitioned_sstable_set(s,false));\nfor(auto& sst : sstables) {\nssts->insert(sst);\ninput_size += sst->data_size();\n}\n\nvug_logger.info(\"Processing {}.{}: {} in {} sstables\",\ns->ks_name(), s->cf_name(),utils::pretty_printed_data_size(input_size), sstables.size());\n\nautopermit = _db.obtain_reader_permit(*t,\"view_update_generator\", db::no_timeout, {}).get0();\nautoms =mutation_source([this, ssts] (\nschema_ptr s,\n@@ -184,6 +189,12 @@ future<> view_update_generator::start() {\nvug_logger.warn(\"Moving {} from staging failed: {}:{}. Ignoring...\", s->ks_name(), s->cf_name(),std::current_exception());\n}\n_registration_sem.signal(num_sstables);\n\nautoend_time =db_clock::now();\nautoduration = std::chrono::duration<float>(end_time - start_time);\nvug_logger.info(\"Processed {}.{}: {} sstables in {}ms = {}\", s->ks_name(), s->cf_name(), sstables.size(),\nstd::chrono::duration_cast<std::chrono::milliseconds>(duration).count(),\nutils::pretty_printed_throughput(input_size, duration));\n}\n//For each table, move the processed staging sstables into the table's base dir.\nfor(autoit = _sstables_to_move.begin(); it != _sstables_to_move.end(); ) {\n", "Added lines (+)": "", "Removed lines (-)": ""}
