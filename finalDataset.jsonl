{"Commit title": "sceKernelFindModuleByName:Add delay for Fake module", "only_addition_codes": "if(strcmp(name, module->nm.name) ==0) {\nif(!module->isFake) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\nelse{\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Fake\", name);\nreturnhleDelayResult(0,\"Module Fake\",1000*1000);\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Found\", name);", "only_deletion_codes": "if(!module->isFake&&strcmp(name, module->nm.name) ==0) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Foundor Fake\", name);", "codes_without_addition_and_deletion": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\n}\n}\nreturn0;\n}\n", "before_commit_codebase": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\nif(!module->isFake&&strcmp(name, module->nm.name) ==0) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Foundor Fake\", name);\nreturn0;\n}\n", "after_commit_codebase": "PSPModule *module = kernelObjects.Get<PSPModule>(moduleId, error);\nif(!module)\ncontinue;\nif(strcmp(name, module->nm.name) ==0) {\nif(!module->isFake) {\nINFO_LOG(SCEMODULE,\"%d = sceKernelFindModuleByName(%s)\", module->modulePtr, name);\nreturnmodule->modulePtr;\n}\nelse{\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Fake\", name);\nreturnhleDelayResult(0,\"Module Fake\",1000*1000);\n}\n}\n}\nWARN_LOG(SCEMODULE,\"0 = sceKernelFindModuleByName(%s): Module Not Found\", name);\nreturn0;\n}\n"}
{"Commit title": "Add the slow comment to one more place", "only_addition_codes": "//NOTE: Reading the decoded texture here may be very slow, if we just wrote it to write-combined memory.", "only_deletion_codes": "", "codes_without_addition_and_deletion": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}", "before_commit_codebase": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}", "after_commit_codebase": "//When hardware texture scaling is enabled, this saves the original.\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//NOTE: Reading the decoded texture here may be very slow, if we just wrote it to write-combined memory.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}"}
{"Commit title": "UI: Prevent save textures if not replacing.", "only_addition_codes": "list->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")))->SetEnabledPtr(&g_Config.bReplaceTextures);", "only_deletion_codes": "list->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")));", "codes_without_addition_and_deletion": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow", "before_commit_codebase": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")));\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow", "after_commit_codebase": "list->Add(newChoice(dev->T(\"Load language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnLoadLanguageIni);\nlist->Add(newChoice(dev->T(\"Save language ini\")))->OnClick.Handle(this, &DeveloperToolsScreen::OnSaveLanguageIni);\nlist->Add(newItemHeader(dev->T(\"Texture Replacement\")));\nlist->Add(newCheckBox(&g_Config.bSaveNewTextures, dev->T(\"Save new textures\")))->SetEnabledPtr(&g_Config.bReplaceTextures);\nlist->Add(newCheckBox(&g_Config.bReplaceTextures, dev->T(\"Replace textures\")));\n\n//Makes it easy to get savestates out of an iOS device. The file listing shown in MacOS doesn't allow"}
{"Commit title": "Replacement: Be more consistent about base level.", "only_addition_codes": "actualFmt =ToVulkanFormat(plan.replaced->Format(plan.baseLevelSrc));\nplan.replaced->GetSize(plan.baseLevelSrc+i, mipWidth, mipHeight);\nplan.replaced->Load(plan.baseLevelSrc+i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride,plan.baseLevelSrc+i, w, h);", "only_deletion_codes": "actualFmt =ToVulkanFormat(plan.replaced->Format(0));\nplan.replaced->GetSize(i, mipWidth, mipHeight);\nplan.replaced->Load(i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);", "codes_without_addition_and_deletion": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\n}\n}\n}", "before_commit_codebase": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\nactualFmt =ToVulkanFormat(plan.replaced->Format(0));\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\nplan.replaced->GetSize(i, mipWidth, mipHeight);\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nplan.replaced->Load(i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride, i, w, h);\n}\n}\n}", "after_commit_codebase": "//Any texture scaling is gonna move away from the original 16-bit format, if any.\nVkFormat actualFmt = plan.scaleFactor>1? VULKAN_8888_FORMAT : dstFmt;\nif(plan.replaced->Valid()) {\nactualFmt =ToVulkanFormat(plan.replaced->Format(plan.baseLevelSrc));\n}\n\nboolcomputeUpload =false;\nintmipWidth = mipUnscaledWidth * plan.scaleFactor;\nintmipHeight = mipUnscaledHeight * plan.scaleFactor;\nif(plan.replaced->Valid()) {\nplan.replaced->GetSize(plan.baseLevelSrc+i, mipWidth, mipHeight);\n}\n\nintbpp = actualFmt == VULKAN_8888_FORMAT ?4:2;//output bpp\n//Directly load the replaced image.\ndata = drawEngine_->GetPushBufferForTextureData()->PushAligned(size, &bufferOffset, &texBuf, pushAlignment);\ndoublereplaceStart =time_now_d();\nplan.replaced->Load(plan.baseLevelSrc+i, data, stride);//if it fails, it'll just be garbage data... OK for now.\nreplacementTimeThisFrame_ +=time_now_d() - replaceStart;\nVK_PROFILE_BEGIN(vulkan, cmdInit, VK_PIPELINE_STAGE_TRANSFER_BIT,\n\"Copy Upload (replaced): %dx%d\", mipWidth, mipHeight);\nintw = dataScaled ? mipWidth : mipUnscaledWidth;\ninth = dataScaled ? mipHeight : mipUnscaledHeight;\n//At this point, data should be saveData, and not slow.\nreplacer_.NotifyTextureDecoded(replacedInfo, data, stride,plan.baseLevelSrc+i, w, h);\n}\n}\n}"}
{"Commit title": "Add a heuristic avoiding joining framebuffers horizontally", "only_addition_codes": "//If the framebuffer we can join to is currently bound as a texture, we likely have\n//a situation like in #9324 and don't want to do this.\nu32 curTextureAddress = gstate.getTextureAddress(0);\nif(v->fb_address== curTextureAddress) {\n//Don't try these joining shenanigans.\ncontinue;\n}\n", "only_deletion_codes": "", "codes_without_addition_and_deletion": "u32 v_fb_end_ptr = v->fb_address+ v->fb_stride* v->height* bpp;\n\nif(params.fb_address> v->fb_address&& params.fb_address< v_fb_first_line_end_ptr) {\nconstintx_offset = (params.fb_address- v->fb_address) / bpp;\nif(x_offset < params.fb_stride&& v->height>= drawing_height) {\n//Pretty certainly a pure render-to-X-offset.", "before_commit_codebase": "u32 v_fb_end_ptr = v->fb_address+ v->fb_stride* v->height* bpp;\n\nif(params.fb_address> v->fb_address&& params.fb_address< v_fb_first_line_end_ptr) {\nconstintx_offset = (params.fb_address- v->fb_address) / bpp;\nif(x_offset < params.fb_stride&& v->height>= drawing_height) {\n//Pretty certainly a pure render-to-X-offset.", "after_commit_codebase": "u32 v_fb_end_ptr = v->fb_address+ v->fb_stride* v->height* bpp;\n\nif(params.fb_address> v->fb_address&& params.fb_address< v_fb_first_line_end_ptr) {\n//If the framebuffer we can join to is currently bound as a texture, we likely have\n//a situation like in #9324 and don't want to do this.\nu32 curTextureAddress = gstate.getTextureAddress(0);\nif(v->fb_address== curTextureAddress) {\n//Don't try these joining shenanigans.\ncontinue;\n}\n\nconstintx_offset = (params.fb_address- v->fb_address) / bpp;\nif(x_offset < params.fb_stride&& v->height>= drawing_height) {\n//Pretty certainly a pure render-to-X-offset."}
{"Commit title": "Remove a useless debug message in filetransfer.cc", "only_addition_codes": "", "only_deletion_codes": "debug(\"verify TLS: Nix CA file = '%s'\", settings.caFile);", "codes_without_addition_and_deletion": "}\n\nif(request.verifyTLS) {\nif(settings.caFile!=\"\")\ncurl_easy_setopt(req, CURLOPT_CAINFO, settings.caFile.c_str());\n}else{", "before_commit_codebase": "}\n\nif(request.verifyTLS) {\ndebug(\"verify TLS: Nix CA file = '%s'\", settings.caFile);\nif(settings.caFile!=\"\")\ncurl_easy_setopt(req, CURLOPT_CAINFO, settings.caFile.c_str());\n}else{", "after_commit_codebase": "}\n\nif(request.verifyTLS) {\nif(settings.caFile!=\"\")\ncurl_easy_setopt(req, CURLOPT_CAINFO, settings.caFile.c_str());\n}else{"}
{"Commit title": "+ fix: go to doc begin after global indentation change", "only_addition_codes": "\nSci_GotoPosChooseCaret(0);\n", "only_deletion_codes": "DocPosconstiCurPos=SciCall_GetCurrentPos();\n\nSci_GotoPosChooseCaret(iCurPos);\n", "codes_without_addition_and_deletion": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;", "before_commit_codebase": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nDocPosconstiCurPos=SciCall_GetCurrentPos();\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSci_GotoPosChooseCaret(iCurPos);\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;", "after_commit_codebase": "boolconstbackSpcUnindents=SciCall_GetBackSpaceUnIndents();\nSciCall_SetBackSpaceUnIndents(true);\n\nUndoTransActionBegin();\nEditIndentBlock(Globals.hwndEdit,SCI_TAB, true, true);\nEditIndentBlock(Globals.hwndEdit,SCI_BACKTAB, true, true);\nEndUndoTransAction();\n\nSciCall_SetUseTabs(useTabs);\nSciCall_SetTabIndents(tabIndents);\nSciCall_SetBackSpaceUnIndents(backSpcUnindents);\n\nSci_GotoPosChooseCaret(0);\n\n}else{\nstatus->iGlobalIndent=I_MIX_LN;\nreturnfalse;"}
{"Commit title": "change comment and cache value", "only_addition_codes": "//Returns the path theapplication root.\nstaticconststd::string root =uv::cwd();\nreturnroot;", "only_deletion_codes": "//Returns the pathtothedefault cache database on this system.\nreturnuv::cwd();", "codes_without_addition_and_deletion": "namespacembgl{\nnamespaceplatform{\n\nstd::stringapplicationRoot() {\n}\n\n}", "before_commit_codebase": "namespacembgl{\nnamespaceplatform{\n\n//Returns the pathtothedefault cache database on this system.\nstd::stringapplicationRoot() {\nreturnuv::cwd();\n}\n\n}", "after_commit_codebase": "namespacembgl{\nnamespaceplatform{\n\n//Returns the path theapplication root.\nstd::stringapplicationRoot() {\nstaticconststd::string root =uv::cwd();\nreturnroot;\n}\n\n}"}
{"Commit title": "fixes#621: better performance for iPhone 6 Plus through smaller rend…", "only_addition_codes": "if([UIScreeninstancesRespondToSelector:@selector(nativeScale)]) {\n_glView.contentScaleFactor= [[UIScreenmainScreen]nativeScale];\n}", "only_deletion_codes": "", "codes_without_addition_and_deletion": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];", "before_commit_codebase": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];", "after_commit_codebase": "_glView.enableSetNeedsDisplay=NO;\n_glView.drawableStencilFormat= GLKViewDrawableStencilFormat8;\n_glView.drawableDepthFormat= GLKViewDrawableDepthFormat16;\nif([UIScreeninstancesRespondToSelector:@selector(nativeScale)]) {\n_glView.contentScaleFactor= [[UIScreenmainScreen]nativeScale];\n}\n_glView.delegate= self;\n[_glViewbindDrawable];\n[selfaddSubview:_glView];"}
{"Commit title": "Replace regex usage with basic string manipulation", "only_addition_codes": "std::string::size_type queryIdx = url.rfind(\"?\");\n//Trim off the right end but never touch anything before the extension dot.\nstd::stringurlSansParams((queryIdx == std::string::npos) ? url : url.substr(0, queryIdx));\n\nwhile(!urlSansParams.empty() &&isdigit(urlSansParams.back()))\nurlSansParams.pop_back();\n\nstd::string::size_type extensionIdx = urlSansParams.length() -4;\nif(extensionIdx <=0)\nreturnurl;\nstd::string extension = urlSansParams.substr(extensionIdx);\nif(extension.compare(\".png\") !=0&& extension.compare(\".jpg\") !=0)\nreturnurl;\n\nstd::stringnormalizedURL(url);\nnormalizedURL.insert(extensionIdx,\"{ratio}\");\nreturnnormalizedURL;", "only_deletion_codes": "#include<regex>\nstaticstd::regexextension_re(\"\\\\.((?:png|jpg)\\\\d*)(?=$|\\\\?)\");\nreturnstd::regex_replace(url, extension_re,std::string(\"{ratio}.$1\"));", "codes_without_addition_and_deletion": "#include<mbgl/util/mapbox.hpp>\n\n#include<stdexcept>\n\nnamespacembgl{\nnamespaceutil{\nif(sourceURL.empty() || sourceURL.compare(0, mapbox.length(), mapbox) !=0)\nreturnurl;\n\n}\n\n}", "before_commit_codebase": "#include<mbgl/util/mapbox.hpp>\n\n#include<stdexcept>\n#include<regex>\n\nnamespacembgl{\nnamespaceutil{\nif(sourceURL.empty() || sourceURL.compare(0, mapbox.length(), mapbox) !=0)\nreturnurl;\n\nstaticstd::regexextension_re(\"\\\\.((?:png|jpg)\\\\d*)(?=$|\\\\?)\");\nreturnstd::regex_replace(url, extension_re,std::string(\"{ratio}.$1\"));\n}\n\n}", "after_commit_codebase": "#include<mbgl/util/mapbox.hpp>\n\n#include<stdexcept>\n\nnamespacembgl{\nnamespaceutil{\nif(sourceURL.empty() || sourceURL.compare(0, mapbox.length(), mapbox) !=0)\nreturnurl;\n\nstd::string::size_type queryIdx = url.rfind(\"?\");\n//Trim off the right end but never touch anything before the extension dot.\nstd::stringurlSansParams((queryIdx == std::string::npos) ? url : url.substr(0, queryIdx));\n\nwhile(!urlSansParams.empty() &&isdigit(urlSansParams.back()))\nurlSansParams.pop_back();\n\nstd::string::size_type extensionIdx = urlSansParams.length() -4;\nif(extensionIdx <=0)\nreturnurl;\nstd::string extension = urlSansParams.substr(extensionIdx);\nif(extension.compare(\".png\") !=0&& extension.compare(\".jpg\") !=0)\nreturnurl;\n\nstd::stringnormalizedURL(url);\nnormalizedURL.insert(extensionIdx,\"{ratio}\");\nreturnnormalizedURL;\n}\n\n}"}
{"Commit title": "Disable all Sources when terminating", "only_addition_codes": "\n//Since we don't have a stylesheet anymore, this will disable all Sources and cancel\n//their associated requests.\nupdateSources();\nassert(activeSources.empty());\n\n//It's now safe to destroy/join the workers since there won't be any more callbacks that\n//could dispatch to the worker pool.", "only_deletion_codes": "activeSources.clear();", "codes_without_addition_and_deletion": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\nworkers.reset();\n\nterminating =true;\n", "before_commit_codebase": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\nworkers.reset();\nactiveSources.clear();\n\nterminating =true;\n", "after_commit_codebase": "\n//Remove all of these to make sure they are destructed in the correct thread.\nstyle.reset();\n\n//Since we don't have a stylesheet anymore, this will disable all Sources and cancel\n//their associated requests.\nupdateSources();\nassert(activeSources.empty());\n\n//It's now safe to destroy/join the workers since there won't be any more callbacks that\n//could dispatch to the worker pool.\nworkers.reset();\n\nterminating =true;\n"}
{"Commit title": "add worker cancellation test (failing)", "only_addition_codes": "\nTEST(Worker, WorkRequestCancelsImmediately) {\nRunLooploop(uv_default_loop());\n\nWorkerworker(1);\n\nloop.invoke([&] {\nstd::promise<void> started;\n//First worker item.\nWorkRequest request1 = worker.send([&] {\nusleep(10000);\nstarted.set_value();\n}, [&] {});\n\nWorkRequest request2 = worker.send([&] {\nADD_FAILURE() <<\"Second work item should not be invoked\";\n}, [&] {});\nrequest2.join();\n\nstarted.get_future().get();\nrequest1.join();\n\nloop.stop();\n});\n\nuv_run(uv_default_loop(), UV_RUN_DEFAULT);\n}", "only_deletion_codes": "", "codes_without_addition_and_deletion": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}", "before_commit_codebase": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}", "after_commit_codebase": "uv_run(uv_default_loop(), UV_RUN_DEFAULT);\nEXPECT_FALSE(didAfter);\n}\n\nTEST(Worker, WorkRequestCancelsImmediately) {\nRunLooploop(uv_default_loop());\n\nWorkerworker(1);\n\nloop.invoke([&] {\nstd::promise<void> started;\n//First worker item.\nWorkRequest request1 = worker.send([&] {\nusleep(10000);\nstarted.set_value();\n}, [&] {});\n\nWorkRequest request2 = worker.send([&] {\nADD_FAILURE() <<\"Second work item should not be invoked\";\n}, [&] {});\nrequest2.join();\n\nstarted.get_future().get();\nrequest1.join();\n\nloop.stop();\n});\n\nuv_run(uv_default_loop(), UV_RUN_DEFAULT);\n}"}
{"Commit title": "Deffer updateAnnotationTiles() if Source is not available", "only_addition_codes": "if(!style) {\nreturn;\n}\nSource* shapeAnnotationSource = style->getSource(shapeID);\n\n//Style not parsed yet\nif(!shapeAnnotationSource) {\nreturn;\n}\n\nshapeAnnotationSource->enabled=true;", "only_deletion_codes": "if(!style)return;\nstyle->getSource(shapeID)->enabled=true;", "codes_without_addition_and_deletion": "util::exclusive<AnnotationManager> annotationManager = data.getAnnotationManager();\nannotationManager->markStaleTiles(ids);\n\n\n//grab existing, single shape annotations source\nconstauto& shapeID = AnnotationManager::ShapeLayerID;\n\n//create (if necessary) layers and buckets for each shape\nfor(constauto&shapeAnnotationID : annotationManager->getOrderedShapeAnnotations()) {", "before_commit_codebase": "util::exclusive<AnnotationManager> annotationManager = data.getAnnotationManager();\nannotationManager->markStaleTiles(ids);\n\nif(!style)return;\n\n//grab existing, single shape annotations source\nconstauto& shapeID = AnnotationManager::ShapeLayerID;\nstyle->getSource(shapeID)->enabled=true;\n\n//create (if necessary) layers and buckets for each shape\nfor(constauto&shapeAnnotationID : annotationManager->getOrderedShapeAnnotations()) {", "after_commit_codebase": "util::exclusive<AnnotationManager> annotationManager = data.getAnnotationManager();\nannotationManager->markStaleTiles(ids);\n\nif(!style) {\nreturn;\n}\n\n//grab existing, single shape annotations source\nconstauto& shapeID = AnnotationManager::ShapeLayerID;\nSource* shapeAnnotationSource = style->getSource(shapeID);\n\n//Style not parsed yet\nif(!shapeAnnotationSource) {\nreturn;\n}\n\nshapeAnnotationSource->enabled=true;\n\n//create (if necessary) layers and buckets for each shape\nfor(constauto&shapeAnnotationID : annotationManager->getOrderedShapeAnnotations()) {"}
{"Commit title": "GLFW port now uses nudgeTransitions()", "only_addition_codes": "constboolneedsRerender = map->renderSync();\nmap->nudgeTransitions(needsRerender);", "only_deletion_codes": "map->renderSync();", "codes_without_addition_and_deletion": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\n}\n}\n}", "before_commit_codebase": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\nmap->renderSync();\n}\n}\n}", "after_commit_codebase": "glfwWaitEvents();\nconstbooldirty = !clean.test_and_set();\nif(dirty) {\nconstboolneedsRerender = map->renderSync();\nmap->nudgeTransitions(needsRerender);\n}\n}\n}"}
{"Commit title": "Ignore tile URL sharding", "only_addition_codes": "std::string result = tiles.at(0);", "only_deletion_codes": "std::string result = tiles.at((id.x+ id.y) % tiles.size());", "codes_without_addition_and_deletion": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));", "before_commit_codebase": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nstd::string result = tiles.at((id.x+ id.y) % tiles.size());\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));", "after_commit_codebase": "}\n\nstd::stringSourceInfo::tileURL(constTileID& id,floatpixelRatio)const{\nstd::string result = tiles.at(0);\nresult =util::mapbox::normalizeTileURL(result, url, type);\nresult =util::replaceTokens(result, [&](conststd::string &token) -> std::string {\nif(token ==\"z\")returnutil::toString(std::min(id.z,static_cast<int8_t>(max_zoom)));"}
{"Commit title": "Make Bucket::uploaded an atomic bool", "only_addition_codes": "#include<atomic>\n\nBucket() : uploaded(false) {}\n\nstd::atomic<bool>uploaded;", "only_deletion_codes": "booluploaded=false;", "codes_without_addition_and_deletion": "#include<mbgl/util/noncopyable.hpp>\n#include<mbgl/util/mat4.hpp>\n\n#defineBUFFER_OFFSET(i) ((char*)nullptr+ (i))\n\nnamespacembgl{\n\nclassBucket:privateutil::noncopyable {\npublic:\n//As long as this bucket has a Prepare render pass, this function is getting called. Typically,\n//this only happens once when the bucket is being rendered for the first time.\nvirtualvoidupload() = 0;\nvirtualvoidswapRenderData() {}\n\nprotected:\n\n};\n", "before_commit_codebase": "#include<mbgl/util/noncopyable.hpp>\n#include<mbgl/util/mat4.hpp>\n\n#defineBUFFER_OFFSET(i) ((char*)nullptr+ (i))\n\nnamespacembgl{\n\nclassBucket:privateutil::noncopyable {\npublic:\n//As long as this bucket has a Prepare render pass, this function is getting called. Typically,\n//this only happens once when the bucket is being rendered for the first time.\nvirtualvoidupload() = 0;\nvirtualvoidswapRenderData() {}\n\nprotected:\nbooluploaded=false;\n\n};\n", "after_commit_codebase": "#include<mbgl/util/noncopyable.hpp>\n#include<mbgl/util/mat4.hpp>\n\n#include<atomic>\n\n#defineBUFFER_OFFSET(i) ((char*)nullptr+ (i))\n\nnamespacembgl{\n\nclassBucket:privateutil::noncopyable {\npublic:\nBucket() : uploaded(false) {}\n\n//As long as this bucket has a Prepare render pass, this function is getting called. Typically,\n//this only happens once when the bucket is being rendered for the first time.\nvirtualvoidupload() = 0;\nvirtualvoidswapRenderData() {}\n\nprotected:\nstd::atomic<bool>uploaded;\n\n};\n"}
{"Commit title": "Disable heading updates for .FollowWithCourse", "only_addition_codes": "caseMGLUserTrackingModeFollowWithCourse:", "only_deletion_codes": "caseMGLUserTrackingModeFollowWithCourse:", "codes_without_addition_and_deletion": "break;\n}\ncaseMGLUserTrackingModeFollow:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\n{\nself.showsUserLocation=YES;\n", "before_commit_codebase": "break;\n}\ncaseMGLUserTrackingModeFollow:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\ncaseMGLUserTrackingModeFollowWithCourse:\n{\nself.showsUserLocation=YES;\n", "after_commit_codebase": "break;\n}\ncaseMGLUserTrackingModeFollow:\ncaseMGLUserTrackingModeFollowWithCourse:\n{\nself.showsUserLocation=YES;\n\nbreak;\n}\ncaseMGLUserTrackingModeFollowWithHeading:\n{\nself.showsUserLocation=YES;\n"}
{"Commit title": "[ios][bench] Add total and avg FPS to final summary", "only_addition_codes": "doubletotalFPS =0;\ntotalFPS += row.second;\nNSLog(@\"Total FPS:%4.1f\", totalFPS);\nNSLog(@\"Average FPS:%4.1f\", totalFPS / result.size());", "only_deletion_codes": "", "codes_without_addition_and_deletion": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\n}\nexit(0);\n}\n}", "before_commit_codebase": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\n}\nexit(0);\n}\n}", "after_commit_codebase": "//Do nothing. The benchmark is completed.\nNSLog(@\"Benchmark completed.\");\nNSLog(@\"Result:\");\ndoubletotalFPS =0;\nsize_tcolWidth =0;\nfor(constauto& row : result) {\ncolWidth =std::max(row.first.size(), colWidth);\n}\nfor(constauto& row : result) {\nNSLog(@\"|%-*s|%4.1ffps |\",int(colWidth), row.first.c_str(), row.second);\ntotalFPS += row.second;\n}\nNSLog(@\"Total FPS:%4.1f\", totalFPS);\nNSLog(@\"Average FPS:%4.1f\", totalFPS / result.size());\nexit(0);\n}\n}"}
{"Commit title": "[core] Fix deleter mismatch", "only_addition_codes": "intstride = width *4;\nsize_twebpSize = stride * height;\nautowebp = std::make_unique<uint8_t[]>(webpSize);\n\nif(!WebPDecodeRGBAInto(data, size, webp.get(), webpSize, stride)) {", "only_deletion_codes": "std::unique_ptr<uint8_t[]>webp(WebPDecodeRGBA(data, size, &width, &height));\nif(!webp) {", "codes_without_addition_and_deletion": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n", "before_commit_codebase": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nstd::unique_ptr<uint8_t[]>webp(WebPDecodeRGBA(data, size, &width, &height));\nif(!webp) {\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n", "after_commit_codebase": "throwstd::runtime_error(\"failed to retrieve WebP basic header information\");\n}\n\nintstride = width *4;\nsize_twebpSize = stride * height;\nautowebp = std::make_unique<uint8_t[]>(webpSize);\n\nif(!WebPDecodeRGBAInto(data, size, webp.get(), webpSize, stride)) {\nthrowstd::runtime_error(\"failed to decode WebP data\");\n}\n"}
{"Commit title": "Adjust for scale", "only_addition_codes": "constuint32_tzoomlevelScaled= zoomlevels[p] +1-(2*scale);\nconstuint32_tstrideRow = skipInterpolate[p] ?1:1<<((zoomlevelScaled+1)/2);\nconstuint32_tstrideCol = skipInterpolate[p] ?1:1<<((zoomlevelScaled)/2);", "only_deletion_codes": "constuint32_tzoomlevel= zoomlevels[p] +1;\nconstuint32_tstrideRow = skipInterpolate[p] ?1:1<<((zoomlevel+1)/2);\nconstuint32_tstrideCol = skipInterpolate[p] ?1:1<<((zoomlevel)/2);", "codes_without_addition_and_deletion": "for(intp=0; p<num; p++) {\nGeneralPlane& planeDest =getPlane(p);\nconstGeneralPlane& planeSrc = other.getPlane(p);\nfor(uint32_tr=0; r<scaledHeight; r+=strideRow) {\nfor(uint32_tc=0; c<scaledWidth; c+=strideCol) {\nplaneDest.set(r,c,planeSrc.get(r,c));", "before_commit_codebase": "for(intp=0; p<num; p++) {\nGeneralPlane& planeDest =getPlane(p);\nconstGeneralPlane& planeSrc = other.getPlane(p);\nconstuint32_tzoomlevel= zoomlevels[p] +1;\nconstuint32_tstrideRow = skipInterpolate[p] ?1:1<<((zoomlevel+1)/2);\nconstuint32_tstrideCol = skipInterpolate[p] ?1:1<<((zoomlevel)/2);\nfor(uint32_tr=0; r<scaledHeight; r+=strideRow) {\nfor(uint32_tc=0; c<scaledWidth; c+=strideCol) {\nplaneDest.set(r,c,planeSrc.get(r,c));", "after_commit_codebase": "for(intp=0; p<num; p++) {\nGeneralPlane& planeDest =getPlane(p);\nconstGeneralPlane& planeSrc = other.getPlane(p);\nconstuint32_tzoomlevelScaled= zoomlevels[p] +1-(2*scale);\nconstuint32_tstrideRow = skipInterpolate[p] ?1:1<<((zoomlevelScaled+1)/2);\nconstuint32_tstrideCol = skipInterpolate[p] ?1:1<<((zoomlevelScaled)/2);\nfor(uint32_tr=0; r<scaledHeight; r+=strideRow) {\nfor(uint32_tc=0; c<scaledWidth; c+=strideCol) {\nplaneDest.set(r,c,planeSrc.get(r,c));"}
{"Commit title": "fix intersecting extents in different projections", "only_addition_codes": "constbox2d<double> buffered_query_ext_map_srs = buffered_query_ext;\nelseif(prj_trans.backward(layer_ext, PROJ_ENVELOPE_POINTS) &&buffered_query_ext_map_srs.intersects(layer_ext))\nlayer_ext.clip(buffered_query_ext_map_srs);", "only_deletion_codes": "elseif(prj_trans.backward(layer_ext, PROJ_ENVELOPE_POINTS) &&buffered_query_ext.intersects(layer_ext))\nlayer_ext.clip(buffered_query_ext);", "codes_without_addition_and_deletion": "}\n\nbox2d<double> layer_ext = lay.envelope();\nboolfw_success =false;\nboolearly_return =false;\n\nearly_return =true;\n}\n//next try intersection of layer extent back projected into map srs\n{\n//forward project layer extent back into native projection\nif(! prj_trans.forward(layer_ext, PROJ_ENVELOPE_POINTS))\n{", "before_commit_codebase": "}\n\nbox2d<double> layer_ext = lay.envelope();\nboolfw_success =false;\nboolearly_return =false;\n\nearly_return =true;\n}\n//next try intersection of layer extent back projected into map srs\nelseif(prj_trans.backward(layer_ext, PROJ_ENVELOPE_POINTS) &&buffered_query_ext.intersects(layer_ext))\n{\nlayer_ext.clip(buffered_query_ext);\n//forward project layer extent back into native projection\nif(! prj_trans.forward(layer_ext, PROJ_ENVELOPE_POINTS))\n{", "after_commit_codebase": "}\n\nbox2d<double> layer_ext = lay.envelope();\nconstbox2d<double> buffered_query_ext_map_srs = buffered_query_ext;\nboolfw_success =false;\nboolearly_return =false;\n\nearly_return =true;\n}\n//next try intersection of layer extent back projected into map srs\nelseif(prj_trans.backward(layer_ext, PROJ_ENVELOPE_POINTS) &&buffered_query_ext_map_srs.intersects(layer_ext))\n{\nlayer_ext.clip(buffered_query_ext_map_srs);\n//forward project layer extent back into native projection\nif(! prj_trans.forward(layer_ext, PROJ_ENVELOPE_POINTS))\n{"}
{"Commit title": "Fix deadlock in ringbuffer::get_all", "only_addition_codes": "if(first ==next(wr_pos_))", "only_deletion_codes": "if(first ==next(last))", "codes_without_addition_and_deletion": "guard_type guard{mtx_};\nrd_pos_ = (first + n) %Size;\n//Wakeup a waiting producers if the queue became non-full.\ncv_full_.notify_all();\nreturni;\n}", "before_commit_codebase": "guard_type guard{mtx_};\nrd_pos_ = (first + n) %Size;\n//Wakeup a waiting producers if the queue became non-full.\nif(first ==next(last))\ncv_full_.notify_all();\nreturni;\n}", "after_commit_codebase": "guard_type guard{mtx_};\nrd_pos_ = (first + n) %Size;\n//Wakeup a waiting producers if the queue became non-full.\nif(first ==next(wr_pos_))\ncv_full_.notify_all();\nreturni;\n}"}
{"Commit title": "rwgame: remove undefined behavior in CharacterObjects", "only_addition_codes": "if(isPlayer() &&static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;", "only_deletion_codes": "if(controller) {\nif(static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}", "codes_without_addition_and_deletion": "}\n}\n\n}\n\n//Check if we need to change the animation or change speed", "before_commit_codebase": "}\n}\n\nif(controller) {\nif(static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}\n}\n\n//Check if we need to change the animation or change speed", "after_commit_codebase": "}\n}\n\nif(isPlayer() &&static_cast<PlayerController*>(controller)->isAdrenalineActive() &&\nmovementAnimation == animations->animation(AnimCycle::WalkStart)) {\nanimationSpeed *=2;\n}\n\n//Check if we need to change the animation or change speed"}
{"Commit title": "setForcedUpdateAllAabbs to false; Reduces stepSimulation time by 35%.", "only_addition_codes": "dynamicsWorld->setForceUpdateAllAabbs(false);", "only_deletion_codes": "", "codes_without_addition_and_deletion": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\n}\n\nGameWorld::~GameWorld() {", "before_commit_codebase": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\n}\n\nGameWorld::~GameWorld() {", "after_commit_codebase": "_overlappingPairCallback.get());\ngContactProcessedCallback= ContactProcessedCallback;\ndynamicsWorld->setInternalTickCallback(PhysicsTickCallback,this);\ndynamicsWorld->setForceUpdateAllAabbs(false);\n}\n\nGameWorld::~GameWorld() {"}
{"Commit title": "OpenMP: Adding an ifdef around chunksize for static schedule for GCC …", "only_addition_codes": "//Specifying an chunksize with GCC compiler leads to performance regression\n//with static schedule.\n#ifdefKOKKOS_COMPILER_GNU\n#pragmaomp parallel for schedule(static) \\\nnum_threads(m_instance->thread_pool_size())\n#else\n#endif", "only_deletion_codes": "", "codes_without_addition_and_deletion": "std::enable_if_t<!std::is_same<typenamePolicy::schedule_type::type,\nKokkos::Dynamic>::value>\nexecute_parallel()const{\n#pragmaomp parallel for schedule(static KOKKOS_OPENMP_OPTIONAL_CHUNK_SIZE) \\\nnum_threads(m_instance->thread_pool_size())\nKOKKOS_PRAGMA_IVDEP_IF_ENABLED\nfor(autoiwork = m_policy.begin(); iwork < m_policy.end(); ++iwork) {\nexec_work(m_functor, iwork);", "before_commit_codebase": "std::enable_if_t<!std::is_same<typenamePolicy::schedule_type::type,\nKokkos::Dynamic>::value>\nexecute_parallel()const{\n#pragmaomp parallel for schedule(static KOKKOS_OPENMP_OPTIONAL_CHUNK_SIZE) \\\nnum_threads(m_instance->thread_pool_size())\nKOKKOS_PRAGMA_IVDEP_IF_ENABLED\nfor(autoiwork = m_policy.begin(); iwork < m_policy.end(); ++iwork) {\nexec_work(m_functor, iwork);", "after_commit_codebase": "std::enable_if_t<!std::is_same<typenamePolicy::schedule_type::type,\nKokkos::Dynamic>::value>\nexecute_parallel()const{\n//Specifying an chunksize with GCC compiler leads to performance regression\n//with static schedule.\n#ifdefKOKKOS_COMPILER_GNU\n#pragmaomp parallel for schedule(static) \\\nnum_threads(m_instance->thread_pool_size())\n#else\n#pragmaomp parallel for schedule(static KOKKOS_OPENMP_OPTIONAL_CHUNK_SIZE) \\\nnum_threads(m_instance->thread_pool_size())\n#endif\nKOKKOS_PRAGMA_IVDEP_IF_ENABLED\nfor(autoiwork = m_policy.begin(); iwork < m_policy.end(); ++iwork) {\nexec_work(m_functor, iwork);"}
{"Commit title": "ConstProp: Adds constpool distance heuristic", "only_addition_codes": "structConstPoolData{\nOrderedNode *Node;\nIR::NodeID NodeID;\n};\nfextl::unordered_map<uint64_t, ConstPoolData> ConstPool;\n//This is a heuristic to limit constant pool live ranges to reduce RA interference pressure.\n//If the range is unbounded then RA interference pressure seems to increase to the point\n//that long blocks of constant usage can slow to a crawl.\n//See https://github.com/FEX-Emu/FEX/issues/2688 for more information.\nconstexprstaticuint32_tCONSTANT_POOL_RANGE_LIMIT =200;\nconstautoNewNodeID = CurrentIR.GetID(CodeNode);\n\nautoit = ConstPool.find(Op->Constant);\nif(it != ConstPool.end()) {\nconstautoOldNodeID = it->second.NodeID;\n\nif((NewNodeID.Value- OldNodeID.Value) > CONSTANT_POOL_RANGE_LIMIT) {\n//Don't reuse if the live range is beyond the heurstic range.\n//Update the tracked value to this new constant.\nit->second.Node= CodeNode;\nit->second.NodeID= NewNodeID;\ncontinue;\n}\n\nautoCodeIter = CurrentIR.at(CodeNode);\nIREmit->ReplaceUsesWithAfter(CodeNode, it->second.Node, CodeIter);\nConstPool[Op->Constant] = ConstPoolData {\n.Node= CodeNode,\n.NodeID= NewNodeID,\n};", "only_deletion_codes": "fextl::unordered_map<uint64_t, OrderedNode*> ConstPool;\nif(ConstPool.count(Op->Constant)) {\nIREmit->ReplaceAllUsesWith(CodeNode, ConstPool[Op->Constant]);\nConstPool[Op->Constant] = CodeNode;", "codes_without_addition_and_deletion": "OrderedNode* CodeNode, IROp_Header* IROp);\nboolConstantInlining(IREmitter *IREmit,constIRListView& CurrentIR);\n\nfextl::map<OrderedNode*,uint64_t> AddressgenConsts;\n\n//Pool inline constant generation. These are typically very small and pool efficiently.\nreturnResult.first->second;\n}\nboolSupportsTSOImm9{};\n};\n\nboolConstProp::HandleConstantPools(IREmitter *IREmit,constIRListView& CurrentIR) {\nfor(auto[CodeNode, IROp] : CurrentIR.GetCode(BlockNode)) {\nif(IROp->Op== OP_CONSTANT) {\nautoOp = IROp->C<IR::IROp_Constant>();\nChanged =true;\n}else{\n}\n}\n}", "before_commit_codebase": "OrderedNode* CodeNode, IROp_Header* IROp);\nboolConstantInlining(IREmitter *IREmit,constIRListView& CurrentIR);\n\nfextl::unordered_map<uint64_t, OrderedNode*> ConstPool;\nfextl::map<OrderedNode*,uint64_t> AddressgenConsts;\n\n//Pool inline constant generation. These are typically very small and pool efficiently.\nreturnResult.first->second;\n}\nboolSupportsTSOImm9{};\n};\n\nboolConstProp::HandleConstantPools(IREmitter *IREmit,constIRListView& CurrentIR) {\nfor(auto[CodeNode, IROp] : CurrentIR.GetCode(BlockNode)) {\nif(IROp->Op== OP_CONSTANT) {\nautoOp = IROp->C<IR::IROp_Constant>();\nif(ConstPool.count(Op->Constant)) {\nIREmit->ReplaceAllUsesWith(CodeNode, ConstPool[Op->Constant]);\nChanged =true;\n}else{\nConstPool[Op->Constant] = CodeNode;\n}\n}\n}", "after_commit_codebase": "OrderedNode* CodeNode, IROp_Header* IROp);\nboolConstantInlining(IREmitter *IREmit,constIRListView& CurrentIR);\n\nstructConstPoolData{\nOrderedNode *Node;\nIR::NodeID NodeID;\n};\nfextl::unordered_map<uint64_t, ConstPoolData> ConstPool;\nfextl::map<OrderedNode*,uint64_t> AddressgenConsts;\n\n//Pool inline constant generation. These are typically very small and pool efficiently.\nreturnResult.first->second;\n}\nboolSupportsTSOImm9{};\n//This is a heuristic to limit constant pool live ranges to reduce RA interference pressure.\n//If the range is unbounded then RA interference pressure seems to increase to the point\n//that long blocks of constant usage can slow to a crawl.\n//See https://github.com/FEX-Emu/FEX/issues/2688 for more information.\nconstexprstaticuint32_tCONSTANT_POOL_RANGE_LIMIT =200;\n};\n\nboolConstProp::HandleConstantPools(IREmitter *IREmit,constIRListView& CurrentIR) {\nfor(auto[CodeNode, IROp] : CurrentIR.GetCode(BlockNode)) {\nif(IROp->Op== OP_CONSTANT) {\nautoOp = IROp->C<IR::IROp_Constant>();\nconstautoNewNodeID = CurrentIR.GetID(CodeNode);\n\nautoit = ConstPool.find(Op->Constant);\nif(it != ConstPool.end()) {\nconstautoOldNodeID = it->second.NodeID;\n\nif((NewNodeID.Value- OldNodeID.Value) > CONSTANT_POOL_RANGE_LIMIT) {\n//Don't reuse if the live range is beyond the heurstic range.\n//Update the tracked value to this new constant.\nit->second.Node= CodeNode;\nit->second.NodeID= NewNodeID;\ncontinue;\n}\n\nautoCodeIter = CurrentIR.at(CodeNode);\nIREmit->ReplaceUsesWithAfter(CodeNode, it->second.Node, CodeIter);\nChanged =true;\n}else{\nConstPool[Op->Constant] = ConstPoolData {\n.Node= CodeNode,\n.NodeID= NewNodeID,\n};\n}\n}\n}"}
{"Commit title": "Arm64: Implement support for SVE bitperm", "only_addition_codes": "if(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PDEP but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), OrigInput.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), OrigMask.W());\nbdep(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), OrigInput.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), OrigMask.X());\nbdep(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PEXT but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), Input.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), Mask.W());\nbext(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), Input.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), Mask.X());\nbext(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}", "only_deletion_codes": "//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);", "codes_without_addition_and_deletion": "\nconstautoDest =GetReg(Node);\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\n}\n\nDEF_OP(LDiv) {", "before_commit_codebase": "\nconstautoDest =GetReg(Node);\n\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}\n\nDEF_OP(LDiv) {", "after_commit_codebase": "\nconstautoDest =GetReg(Node);\n\n//We can't clobber these\nconstautoOrigInput =GetReg(Op->Input.ID());\nconstautoOrigMask =GetReg(Op->Mask.ID());\n\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PDEP but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), OrigInput.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), OrigMask.W());\nbdep(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), OrigInput.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), OrigMask.X());\nbdep(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\n//PDep implementation follows the ideas from\n//http://0x80.pl/articles/pdep-soft-emu.html ... Basically, iterate the *set*\n//bits only, which will be faster than the naive implementation as long as\n//there are enough holes in the mask.\n//\n//The specific arm64 assembly used is based on the sequence that clang\n//generates for the C code, giving context to the scheduling yielding better\n//ILP than I would do by hand. The registers are allocated by hand however,\n//to fit within the tight constraints we have here withot spilling. Also, we\n//use cbz/cbnz for conditional branching to avoid clobbering NZCV.\n\n//So we have shadow as temporaries\nconstautoInput = TMP1.R();\nconstautoMask = TMP2.R();\n\n//these get used variously as scratch\nconstautoT0 = TMP3.R();\nconstautoT1 = TMP4.R();\n\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\n//First, copy the input/mask, since we'll be clobbering. Copy as 64-bit to\n//make this 0-uop on Firestorm.\nmov(ARMEmitter::Size::i64Bit, Input, OrigInput);\nmov(ARMEmitter::Size::i64Bit, Mask, OrigMask);\n\n//Now, they're copied, so we can start setting Dest (even if it overlaps with\n//one of them).  Handle early exit case\nmov(EmitSize, Dest,0);\ncbz(EmitSize, OrigMask, &Done);\n\n//Setup for first iteration\nneg(EmitSize, T0, Mask);\nand_(EmitSize, T0, T0, Mask);\n\n//Main loop\nBind(&NextBit);\nsbfx(EmitSize, T1, Input,0,1);\neor(EmitSize, Mask, Mask, T0);\nand_(EmitSize, T0, T1, T0);\nneg(EmitSize, T1, Mask);\norr(EmitSize, Dest, Dest, T0);\nlsr(EmitSize, Input, Input,1);\nand_(EmitSize, T0, Mask, T1);\ncbnz(EmitSize, T0, &NextBit);\n\n//All done with nothing to do.\nBind(&Done);\n}\n}\n\nDEF_OP(PExt) {\nconstautoMask =GetReg(Op->Mask.ID());\nconstautoDest =GetReg(Node);\n\nif(CTX->HostFeatures.SupportsSVEBitPerm) {\n//SVE added support for PEXT but it needs to be done in a vector register.\nif(EmitSize == ARMEmitter::Size::i32Bit) {\nfmov(ARMEmitter::Size::i32Bit, VTMP1.S(), Input.W());\nfmov(ARMEmitter::Size::i32Bit, VTMP2.S(), Mask.W());\nbext(ARMEmitter::SubRegSize::i32Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i32Bit>(Dest, VTMP1,0);\n}else{\nfmov(ARMEmitter::Size::i64Bit, VTMP1.D(), Input.X());\nfmov(ARMEmitter::Size::i64Bit, VTMP2.D(), Mask.X());\nbext(ARMEmitter::SubRegSize::i64Bit, VTMP1.Z(), VTMP1.Z(), VTMP2.Z());\numov<ARMEmitter::SubRegSize::i64Bit>(Dest, VTMP1,0);\n}\n}else{\nconstautoMaskReg = TMP1;\nconstautoBitReg = TMP2;\nconstautoValueReg = TMP3;\n\nARMEmitter::SingleUseForwardLabel EarlyExit;\nARMEmitter::BackwardLabel NextBit;\nARMEmitter::SingleUseForwardLabel Done;\n\ncbz(EmitSize, Mask, &EarlyExit);\nmov(EmitSize, MaskReg, Mask);\nmov(EmitSize, ValueReg, Input);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//Main loop\nBind(&NextBit);\ncbz(EmitSize, MaskReg, &Done);\nclz(EmitSize, BitReg, MaskReg);\nlslv(EmitSize, ValueReg, ValueReg, BitReg);\nlslv(EmitSize, MaskReg, MaskReg, BitReg);\nextr(EmitSize, Dest, Dest, ValueReg, OpSizeBitsM1);\nbfc(EmitSize, MaskReg, OpSizeBitsM1,1);\nb(&NextBit);\n\n//Early exit\nBind(&EarlyExit);\nmov(EmitSize, Dest, ARMEmitter::Reg::zr);\n\n//All done with nothing to do.\nBind(&Done);\n}\n}\n\nDEF_OP(LDiv) {"}
{"Commit title": "fixup formatting", "only_addition_codes": "autorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\nexpect_end_element(row_el);", "only_deletion_codes": "//auto row_index = parser().attribute<row_t>(\"r\");\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\nexpect_end_element(row_el);", "codes_without_addition_and_deletion": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\n\nif(!in_element(sheetData_el))\n{", "before_commit_codebase": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\n//auto row_index = parser().attribute<row_t>(\"r\");\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\nexpect_end_element(row_el);\n\nif(!in_element(sheetData_el))\n{", "after_commit_codebase": "if(in_element(sheetData_el))\n{\nexpect_start_element(row_el, xml::content::complex);//CT_Row\nautorow_index =static_cast<row_t>(std::stoul(parser().attribute(\"r\")));\n\nif(parser().attribute_present(\"ht\"))\n{\n\nif(!in_element(row_el))\n{\nexpect_end_element(row_el);\n\nif(!in_element(sheetData_el))\n{"}
{"Commit title": "Capture fewer variables for lamdba", "only_addition_codes": "modify(acct, [&new_vbid]( account_object& _acct )\nmodify(acct.statistics( *this), []( account_statistics_object& aso )", "only_deletion_codes": "modify(acct, [&]( account_object& _acct )\nmodify(acct.statistics( *this), [&]( account_statistics_object& aso )", "codes_without_addition_and_deletion": "\nif( new_vbid.valid() )\n{\n{\n_acct.cashback_vb= *new_vbid;\n} );\n{\naso.has_cashback_vb=true;\n} );", "before_commit_codebase": "\nif( new_vbid.valid() )\n{\nmodify(acct, [&]( account_object& _acct )\n{\n_acct.cashback_vb= *new_vbid;\n} );\nmodify(acct.statistics( *this), [&]( account_statistics_object& aso )\n{\naso.has_cashback_vb=true;\n} );", "after_commit_codebase": "\nif( new_vbid.valid() )\n{\nmodify(acct, [&new_vbid]( account_object& _acct )\n{\n_acct.cashback_vb= *new_vbid;\n} );\nmodify(acct.statistics( *this), []( account_statistics_object& aso )\n{\naso.has_cashback_vb=true;\n} );"}
{"Commit title": "remove needless find()", "only_addition_codes": "autoadv_to_peer = peer->inventory_advertised_to_peer.find(item_to_advertise);\nautoadv_to_us   = peer->inventory_peer_advertised_to_us.find(item_to_advertise);\nif(adv_to_peer== peer->inventory_advertised_to_peer.end() &&\nadv_to_us== peer->inventory_peer_advertised_to_us.end())\nelse\n{\nif(adv_to_peer != peer->inventory_advertised_to_peer.end() )\nidump( (*adv_to_peer) );\nif(adv_to_us != peer->inventory_peer_advertised_to_us.end() )\nidump( (*adv_to_us) );\n}", "only_deletion_codes": "if(peer->inventory_advertised_to_peer.find(item_to_advertise) != peer->inventory_advertised_to_peer.end() )\nidump((*peer->inventory_advertised_to_peer.find(item_to_advertise)));\nif(peer->inventory_peer_advertised_to_us.find(item_to_advertise) != peer->inventory_peer_advertised_to_us.end() )\nidump((*peer->inventory_peer_advertised_to_us.find(item_to_advertise)));\nif(peer->inventory_advertised_to_peer.find(item_to_advertise)== peer->inventory_advertised_to_peer.end() &&\npeer->inventory_peer_advertised_to_us.find(item_to_advertise)== peer->inventory_peer_advertised_to_us.end())", "codes_without_addition_and_deletion": "idump((inventory_to_advertise));\nfor(constitem_id& item_to_advertise : inventory_to_advertise)\n{\n\n{\nitems_to_advertise_by_type[item_to_advertise.item_type].push_back(item_to_advertise.item_hash);\npeer->inventory_advertised_to_peer.insert(peer_connection::timestamped_item_id(item_to_advertise,fc::time_point::now()));\ntestnetlog(\"advertising transaction ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\ndlog(\"advertising item ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\n}\n}\ndlog(\"advertising ${count} new item(s) of ${types} type(s) to peer ${endpoint}\",\n(\"count\", total_items_to_send_to_this_peer)", "before_commit_codebase": "idump((inventory_to_advertise));\nfor(constitem_id& item_to_advertise : inventory_to_advertise)\n{\nif(peer->inventory_advertised_to_peer.find(item_to_advertise) != peer->inventory_advertised_to_peer.end() )\nidump((*peer->inventory_advertised_to_peer.find(item_to_advertise)));\nif(peer->inventory_peer_advertised_to_us.find(item_to_advertise) != peer->inventory_peer_advertised_to_us.end() )\nidump((*peer->inventory_peer_advertised_to_us.find(item_to_advertise)));\n\nif(peer->inventory_advertised_to_peer.find(item_to_advertise)== peer->inventory_advertised_to_peer.end() &&\npeer->inventory_peer_advertised_to_us.find(item_to_advertise)== peer->inventory_peer_advertised_to_us.end())\n{\nitems_to_advertise_by_type[item_to_advertise.item_type].push_back(item_to_advertise.item_hash);\npeer->inventory_advertised_to_peer.insert(peer_connection::timestamped_item_id(item_to_advertise,fc::time_point::now()));\ntestnetlog(\"advertising transaction ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\ndlog(\"advertising item ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\n}\n}\ndlog(\"advertising ${count} new item(s) of ${types} type(s) to peer ${endpoint}\",\n(\"count\", total_items_to_send_to_this_peer)", "after_commit_codebase": "idump((inventory_to_advertise));\nfor(constitem_id& item_to_advertise : inventory_to_advertise)\n{\nautoadv_to_peer = peer->inventory_advertised_to_peer.find(item_to_advertise);\nautoadv_to_us   = peer->inventory_peer_advertised_to_us.find(item_to_advertise);\n\nif(adv_to_peer== peer->inventory_advertised_to_peer.end() &&\nadv_to_us== peer->inventory_peer_advertised_to_us.end())\n{\nitems_to_advertise_by_type[item_to_advertise.item_type].push_back(item_to_advertise.item_hash);\npeer->inventory_advertised_to_peer.insert(peer_connection::timestamped_item_id(item_to_advertise,fc::time_point::now()));\ntestnetlog(\"advertising transaction ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\ndlog(\"advertising item ${id} to peer ${endpoint}\", (\"id\", item_to_advertise.item_hash)(\"endpoint\", peer->get_remote_endpoint()));\n}\nelse\n{\nif(adv_to_peer != peer->inventory_advertised_to_peer.end() )\nidump( (*adv_to_peer) );\nif(adv_to_us != peer->inventory_peer_advertised_to_us.end() )\nidump( (*adv_to_us) );\n}\n}\ndlog(\"advertising ${count} new item(s) of ${types} type(s) to peer ${endpoint}\",\n(\"count\", total_items_to_send_to_this_peer)"}
{"Commit title": "Use RequestSizing for DX Coil SHR", "only_addition_codes": "if (Mode == DXCoil(DXCoilNum).NumOfSpeeds) {\nSizingMethod = CoolingSHRSizing;\nCompType = DXCoil(DXCoilNum).DXCoilType;\nCompName = DXCoil(DXCoilNum).Name;\nTempSize = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nSizingString = \"Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\";\nDataFlowUsedForSizing = MSRatedAirVolFlowRateDes;\nDataCapacityUsedForSizing = MSRatedTotCapDesAtMaxSpeed;\nDataEMSOverrideON = DXCoil(DXCoilNum).RatedSHREMSOverrideOn(Mode);\nDataEMSOverride = DXCoil(DXCoilNum).RatedSHREMSOverrideValue(Mode);\nRequestSizing(CompType, CompName, SizingMethod, SizingString, TempSize, bPRINT, RoutineName);\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = TempSize;\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil(DXCoilNum).RatedSHR(1) = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nMSRatedSHRDes = DXCoil(DXCoilNum).MSRatedSHR(Mode);\n//TempSize = DXCoil(DXCoilNum).MSRatedSHR(Mode);\n//SizingString = \"Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\";\n//DataFlowUsedForSizing = DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode);\n//DataCapacityUsedForSizing = DXCoil(DXCoilNum).MSRatedTotCap(Mode);\n//DataEMSOverrideON = DXCoil(DXCoilNum).RatedSHREMSOverrideOn(Mode);\n//DataEMSOverride = DXCoil(DXCoilNum).RatedSHREMSOverrideValue(Mode);\n//RequestSizing(CompType, CompName, SizingMethod, SizingString, TempSize, bPRINT, RoutineName);\n//DXCoil(DXCoilNum).MSRatedSHR(Mode) = TempSize;\nif (IsAutoSize) {\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = MSRatedSHRDes;\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes);\n\n} else if (HardSizeNoDesRun) {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\n}\n} else {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0 && MSRatedSHRDes > 0.0 && !HardSizeNoDesRun) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\nif (DisplayExtraWarnings) {\nif ((std::abs(MSRatedSHRDes - MSRatedSHRUser) / MSRatedSHRUser) > AutoVsHardSizingThreshold) {\nShowMessage(\"SizeDxCoil: Potential issue with equipment sizing for \" + DXCoil(DXCoilNum).DXCoilType + ' ' +\nDXCoil(DXCoilNum).Name);\nShowContinueError(\"User-Specified Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRUser, 3));\nShowContinueError(\"differs from Design Size Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRDes, 3));\nShowContinueError(\"This may, or may not, indicate mismatched component sizes.\");\nShowContinueError(\"Verify that the value entered is intended and is consistent with other components.\");\n}\n}\nDataFlowUsedForSizing = 0.0;\nDataCapacityUsedForSizing = 0.0;\nDataEMSOverrideON = false;\nDataEMSOverride = 0.0;", "only_deletion_codes": "if ( Mode == DXCoil( DXCoilNum ).NumOfSpeeds ) {\nif ( CurSysNum > 0 ) {\nif ( SizingDesRunThisAirSys ) HardSizeNoDesRun = false;\nif ( !IsAutoSize && !SizingDesRunThisAirSys ) {\nHardSizeNoDesRun = true;\nif ( DXCoil( DXCoilNum ).MSRatedSHR( Mode ) > 0.0 ) {\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil( DXCoilNum ).RatedSHR( 1 ) = DXCoil( DXCoilNum ).MSRatedSHR( Mode );\n}\n} else { // autosize or hard-sized with system sizing data\nCheckSysSizing( DXCoil( DXCoilNum ).DXCoilType, DXCoil( DXCoilNum ).Name );\n}\n} else if ( CurZoneEqNum > 0 ) {\nif ( SizingDesRunThisZone ) HardSizeNoDesRun = false;\nif ( !IsAutoSize && !SizingDesRunThisZone ) {\nHardSizeNoDesRun = true;\nif ( DXCoil( DXCoilNum ).MSRatedSHR( Mode ) > 0.0 ) {\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil( DXCoilNum ).RatedSHR( 1 ) = DXCoil( DXCoilNum ).MSRatedSHR( Mode );\n}\n} else { // autosize or hard-sized with system sizing data\nCheckZoneSizing( DXCoil( DXCoilNum ).DXCoilType, DXCoil( DXCoilNum ).Name );\n}\n}\nif (DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode) >= SmallAirVolFlow && DXCoil(DXCoilNum).MSRatedTotCap(Mode) > 0.0) {\n// For autosizing the rated SHR, we set a minimum SHR of 0.676 and a maximum of 0.798. The min SHR occurs occurs at the\n// minimum flow / capacity ratio = MinRatedVolFlowPerRatedTotCap = 0.00004027 [m3/s / W] = 300 [cfm/ton].\n// The max SHR occurs at maximum flow / capacity ratio = MaxRatedVolFlowPerRatedTotCap = 0.00006041 [m3/s / W] = 450\n// [cfm/ton]. For flow / capacity ratios between the min and max we linearly interpolate between min and max SHR. Thus rated\n// SHR is a linear function of the rated flow / capacity ratio. This linear function (see below) is the result of a regression\n// of flow/capacity ratio vs SHR for several actual coils.\nif ( IsAutoSize || !HardSizeNoDesRun ) {\n// this ratio is the same for all speeds if all autosized\nif ( MSRatedTotCapDesAtMaxSpeed > 0.0 ) {\nRatedVolFlowPerRatedTotCap = MSRatedAirVolFlowRateDes / MSRatedTotCapDesAtMaxSpeed;\n} else {\nRatedVolFlowPerRatedTotCap = 0.0;\n}\n} else {\nRatedVolFlowPerRatedTotCap = DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode) / DXCoil(DXCoilNum).MSRatedTotCap(Mode);\n}\nif (RatedVolFlowPerRatedTotCap > MaxRatedVolFlowPerRatedTotCap(DXCT)) {\nMSRatedSHRDes = 0.431 + 6086.0 * MaxRatedVolFlowPerRatedTotCap(DXCT);\n} else if (RatedVolFlowPerRatedTotCap < MinRatedVolFlowPerRatedTotCap(DXCT)) {\nMSRatedSHRDes = 0.431 + 6086.0 * MinRatedVolFlowPerRatedTotCap(DXCT);\n} else {\nMSRatedSHRDes = 0.431 + 6086.0 * RatedVolFlowPerRatedTotCap;\n}\n} else {\nMSRatedSHRDes = 1.0;\n}\n} else {\nMSRatedSHRDes = DXCoil( DXCoilNum ).MSRatedSHR( Mode + 1 );\n}\n\nif (IsAutoSize) {\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = MSRatedSHRDes;\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes);\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil(DXCoilNum).RatedSHR(1) = MSRatedSHRDes;\n\n} else if ( HardSizeNoDesRun ) {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\n}\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0 && MSRatedSHRDes > 0.0 && !HardSizeNoDesRun) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\nif (DisplayExtraWarnings) {\nif ((std::abs(MSRatedSHRDes - MSRatedSHRUser) / MSRatedSHRUser) > AutoVsHardSizingThreshold) {\nShowMessage(\"SizeDxCoil: Potential issue with equipment sizing for \" + DXCoil(DXCoilNum).DXCoilType + ' ' +\nDXCoil(DXCoilNum).Name);\nShowContinueError(\"User-Specified Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRUser, 3));\nShowContinueError(\"differs from Design Size Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRDes, 3));\nShowContinueError(\"This may, or may not, indicate mismatched component sizes.\");\nShowContinueError(\"Verify that the value entered is intended and is consistent with other components.\");\n}", "codes_without_addition_and_deletion": "if (DXCoil(DXCoilNum).MSRatedSHR(Mode) == AutoSize) {\nIsAutoSize = true;\n}\n// design SHR value at the maxiumum speed calculated above was supposed to be used for all speeds\n// Now user specified SHR value is used when the SHR field is not autosized and design day run is\n// set to yes unless the code below is commented out\n} else {\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\n}\n}\n}\n}\n\n// Rated Evapovative condenser airflow rates\nfor (Mode = 1; Mode <= DXCoil(DXCoilNum).NumOfSpeeds; ++Mode) {", "before_commit_codebase": "if (DXCoil(DXCoilNum).MSRatedSHR(Mode) == AutoSize) {\nIsAutoSize = true;\n}\nif ( Mode == DXCoil( DXCoilNum ).NumOfSpeeds ) {\nif ( CurSysNum > 0 ) {\nif ( SizingDesRunThisAirSys ) HardSizeNoDesRun = false;\nif ( !IsAutoSize && !SizingDesRunThisAirSys ) {\nHardSizeNoDesRun = true;\nif ( DXCoil( DXCoilNum ).MSRatedSHR( Mode ) > 0.0 ) {\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil( DXCoilNum ).RatedSHR( 1 ) = DXCoil( DXCoilNum ).MSRatedSHR( Mode );\n}\n} else { // autosize or hard-sized with system sizing data\nCheckSysSizing( DXCoil( DXCoilNum ).DXCoilType, DXCoil( DXCoilNum ).Name );\n}\n} else if ( CurZoneEqNum > 0 ) {\nif ( SizingDesRunThisZone ) HardSizeNoDesRun = false;\nif ( !IsAutoSize && !SizingDesRunThisZone ) {\nHardSizeNoDesRun = true;\nif ( DXCoil( DXCoilNum ).MSRatedSHR( Mode ) > 0.0 ) {\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil( DXCoilNum ).RatedSHR( 1 ) = DXCoil( DXCoilNum ).MSRatedSHR( Mode );\n}\n} else { // autosize or hard-sized with system sizing data\nCheckZoneSizing( DXCoil( DXCoilNum ).DXCoilType, DXCoil( DXCoilNum ).Name );\n}\n}\nif (DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode) >= SmallAirVolFlow && DXCoil(DXCoilNum).MSRatedTotCap(Mode) > 0.0) {\n// For autosizing the rated SHR, we set a minimum SHR of 0.676 and a maximum of 0.798. The min SHR occurs occurs at the\n// minimum flow / capacity ratio = MinRatedVolFlowPerRatedTotCap = 0.00004027 [m3/s / W] = 300 [cfm/ton].\n// The max SHR occurs at maximum flow / capacity ratio = MaxRatedVolFlowPerRatedTotCap = 0.00006041 [m3/s / W] = 450\n// [cfm/ton]. For flow / capacity ratios between the min and max we linearly interpolate between min and max SHR. Thus rated\n// SHR is a linear function of the rated flow / capacity ratio. This linear function (see below) is the result of a regression\n// of flow/capacity ratio vs SHR for several actual coils.\nif ( IsAutoSize || !HardSizeNoDesRun ) {\n// this ratio is the same for all speeds if all autosized\nif ( MSRatedTotCapDesAtMaxSpeed > 0.0 ) {\nRatedVolFlowPerRatedTotCap = MSRatedAirVolFlowRateDes / MSRatedTotCapDesAtMaxSpeed;\n} else {\nRatedVolFlowPerRatedTotCap = 0.0;\n}\n} else {\nRatedVolFlowPerRatedTotCap = DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode) / DXCoil(DXCoilNum).MSRatedTotCap(Mode);\n}\nif (RatedVolFlowPerRatedTotCap > MaxRatedVolFlowPerRatedTotCap(DXCT)) {\nMSRatedSHRDes = 0.431 + 6086.0 * MaxRatedVolFlowPerRatedTotCap(DXCT);\n} else if (RatedVolFlowPerRatedTotCap < MinRatedVolFlowPerRatedTotCap(DXCT)) {\nMSRatedSHRDes = 0.431 + 6086.0 * MinRatedVolFlowPerRatedTotCap(DXCT);\n} else {\nMSRatedSHRDes = 0.431 + 6086.0 * RatedVolFlowPerRatedTotCap;\n}\n} else {\nMSRatedSHRDes = 1.0;\n}\n} else {\n// design SHR value at the maxiumum speed calculated above was supposed to be used for all speeds\n// Now user specified SHR value is used when the SHR field is not autosized and design day run is\n// set to yes unless the code below is commented out\nMSRatedSHRDes = DXCoil( DXCoilNum ).MSRatedSHR( Mode + 1 );\n}\n\nif (IsAutoSize) {\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = MSRatedSHRDes;\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes);\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil(DXCoilNum).RatedSHR(1) = MSRatedSHRDes;\n\n} else if ( HardSizeNoDesRun ) {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\n}\n} else {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0 && MSRatedSHRDes > 0.0 && !HardSizeNoDesRun) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\nif (DisplayExtraWarnings) {\nif ((std::abs(MSRatedSHRDes - MSRatedSHRUser) / MSRatedSHRUser) > AutoVsHardSizingThreshold) {\nShowMessage(\"SizeDxCoil: Potential issue with equipment sizing for \" + DXCoil(DXCoilNum).DXCoilType + ' ' +\nDXCoil(DXCoilNum).Name);\nShowContinueError(\"User-Specified Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRUser, 3));\nShowContinueError(\"differs from Design Size Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRDes, 3));\nShowContinueError(\"This may, or may not, indicate mismatched component sizes.\");\nShowContinueError(\"Verify that the value entered is intended and is consistent with other components.\");\n}\n}\n}\n}\n}\n\n// Rated Evapovative condenser airflow rates\nfor (Mode = 1; Mode <= DXCoil(DXCoilNum).NumOfSpeeds; ++Mode) {", "after_commit_codebase": "if (DXCoil(DXCoilNum).MSRatedSHR(Mode) == AutoSize) {\nIsAutoSize = true;\n}\nif (Mode == DXCoil(DXCoilNum).NumOfSpeeds) {\nSizingMethod = CoolingSHRSizing;\nCompType = DXCoil(DXCoilNum).DXCoilType;\nCompName = DXCoil(DXCoilNum).Name;\nTempSize = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nSizingString = \"Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\";\nDataFlowUsedForSizing = MSRatedAirVolFlowRateDes;\nDataCapacityUsedForSizing = MSRatedTotCapDesAtMaxSpeed;\nDataEMSOverrideON = DXCoil(DXCoilNum).RatedSHREMSOverrideOn(Mode);\nDataEMSOverride = DXCoil(DXCoilNum).RatedSHREMSOverrideValue(Mode);\nRequestSizing(CompType, CompName, SizingMethod, SizingString, TempSize, bPRINT, RoutineName);\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = TempSize;\n// added for rated sensible cooling capacity estimate for html reporting, issue #7381\nDXCoil(DXCoilNum).RatedSHR(1) = DXCoil(DXCoilNum).MSRatedSHR(Mode);\n// design SHR value at the maxiumum speed calculated above was supposed to be used for all speeds\n// Now user specified SHR value is used when the SHR field is not autosized and design day run is\n// set to yes unless the code below is commented out\nMSRatedSHRDes = DXCoil(DXCoilNum).MSRatedSHR(Mode);\n} else {\n//TempSize = DXCoil(DXCoilNum).MSRatedSHR(Mode);\n//SizingString = \"Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\";\n//DataFlowUsedForSizing = DXCoil(DXCoilNum).MSRatedAirVolFlowRate(Mode);\n//DataCapacityUsedForSizing = DXCoil(DXCoilNum).MSRatedTotCap(Mode);\n//DataEMSOverrideON = DXCoil(DXCoilNum).RatedSHREMSOverrideOn(Mode);\n//DataEMSOverride = DXCoil(DXCoilNum).RatedSHREMSOverrideValue(Mode);\n//RequestSizing(CompType, CompName, SizingMethod, SizingString, TempSize, bPRINT, RoutineName);\n//DXCoil(DXCoilNum).MSRatedSHR(Mode) = TempSize;\nif (IsAutoSize) {\nDXCoil(DXCoilNum).MSRatedSHR(Mode) = MSRatedSHRDes;\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes);\n\n} else if (HardSizeNoDesRun) {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\n}\n} else {\nif (DXCoil(DXCoilNum).MSRatedSHR(Mode) > 0.0 && MSRatedSHRDes > 0.0 && !HardSizeNoDesRun) {\nMSRatedSHRUser = DXCoil(DXCoilNum).MSRatedSHR(Mode);\nReportSizingOutput(DXCoil(DXCoilNum).DXCoilType,\nDXCoil(DXCoilNum).Name,\n\"Design Size Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRDes,\n\"User-Specified Speed \" + TrimSigDigits(Mode) + \" Rated Sensible Heat Ratio\",\nMSRatedSHRUser);\nif (DisplayExtraWarnings) {\nif ((std::abs(MSRatedSHRDes - MSRatedSHRUser) / MSRatedSHRUser) > AutoVsHardSizingThreshold) {\nShowMessage(\"SizeDxCoil: Potential issue with equipment sizing for \" + DXCoil(DXCoilNum).DXCoilType + ' ' +\nDXCoil(DXCoilNum).Name);\nShowContinueError(\"User-Specified Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRUser, 3));\nShowContinueError(\"differs from Design Size Rated Sensible Heat Ratio of \" + RoundSigDigits(MSRatedSHRDes, 3));\nShowContinueError(\"This may, or may not, indicate mismatched component sizes.\");\nShowContinueError(\"Verify that the value entered is intended and is consistent with other components.\");\n}\n}\n}\n}\n}\n}\nDataFlowUsedForSizing = 0.0;\nDataCapacityUsedForSizing = 0.0;\nDataEMSOverrideON = false;\nDataEMSOverride = 0.0;\n\n// Rated Evapovative condenser airflow rates\nfor (Mode = 1; Mode <= DXCoil(DXCoilNum).NumOfSpeeds; ++Mode) {"}
{"Commit title": "Revert consolidation of CpAir calculation", "only_addition_codes": "CpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));\nReal64constair_hum_rat(ZoneAirHumRat(ZoneNum));\nCpAir =PsyCpAirFnW(air_hum_rat);\nCpAir =PsyCpAirFnW(air_hum_rat);\nCpAir =PsyCpAirFnW(air_hum_rat);\nCpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));", "only_deletion_codes": "\nCpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));", "codes_without_addition_and_deletion": "//Check to see if this is a controlled zone\nControlledZoneAirFlag =Zone(ZoneNum).IsControlled;\nif(CorrectorFlag) {\n//Check to see if this is a plenum zone\nZoneRetPlenumAirFlag =Zone(ZoneNum).IsReturnPlenum;\nZoneSupPlenumAirFlag =Zone(ZoneNum).IsSupplyPlenum;\n\n//Plenum and controlled zones have a different set of inlet nodes which must be calculated.\nif(ControlledZoneAirFlag) {\nautoconst&node(Node(zec.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\n}elseif(ZoneRetPlenumAirFlag) {\nZoneRetPlenumNum =Zone(ZoneNum).PlenumCondNum;\nautoconst&zrpc(dataZonePlenum.ZoneRetPlenCond(ZoneRetPlenumNum));\nfor(intNodeNum =1, NodeNum_end = zrpc.NumInletNodes; NodeNum <= NodeNum_end; ++NodeNum) {\n//Get node conditions\nautoconst&node(Node(zrpc.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nADUInNode =AirDistUnit(ADUNum).InletNodeNum;\nNodeTemp =Node(ADUInNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateUpStrLk;\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\nADUOutNode =AirDistUnit(ADUNum).OutletNodeNum;\nNodeTemp =Node(ADUOutNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateDnStrLk;\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\n//Get node conditions\nNodeTemp =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).Temp;\nMassFlowRate =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).MassFlowRate;\n\nSumSysMCp += MassFlowRate * CpAir;\nSumSysMCpT += MassFlowRate * CpAir * NodeTemp;", "before_commit_codebase": "//Check to see if this is a controlled zone\nControlledZoneAirFlag =Zone(ZoneNum).IsControlled;\nif(CorrectorFlag) {\n\n//Check to see if this is a plenum zone\nZoneRetPlenumAirFlag =Zone(ZoneNum).IsReturnPlenum;\nZoneSupPlenumAirFlag =Zone(ZoneNum).IsSupplyPlenum;\nCpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));\n\n//Plenum and controlled zones have a different set of inlet nodes which must be calculated.\nif(ControlledZoneAirFlag) {\nautoconst&node(Node(zec.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\n}elseif(ZoneRetPlenumAirFlag) {\nZoneRetPlenumNum =Zone(ZoneNum).PlenumCondNum;\nautoconst&zrpc(dataZonePlenum.ZoneRetPlenCond(ZoneRetPlenumNum));\nfor(intNodeNum =1, NodeNum_end = zrpc.NumInletNodes; NodeNum <= NodeNum_end; ++NodeNum) {\n//Get node conditions\nautoconst&node(Node(zrpc.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nADUInNode =AirDistUnit(ADUNum).InletNodeNum;\nNodeTemp =Node(ADUInNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateUpStrLk;\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\nADUOutNode =AirDistUnit(ADUNum).OutletNodeNum;\nNodeTemp =Node(ADUOutNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateDnStrLk;\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\n//Get node conditions\nNodeTemp =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).Temp;\nMassFlowRate =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).MassFlowRate;\n\nSumSysMCp += MassFlowRate * CpAir;\nSumSysMCpT += MassFlowRate * CpAir * NodeTemp;", "after_commit_codebase": "//Check to see if this is a controlled zone\nControlledZoneAirFlag =Zone(ZoneNum).IsControlled;\nif(CorrectorFlag) {\n//Check to see if this is a plenum zone\nZoneRetPlenumAirFlag =Zone(ZoneNum).IsReturnPlenum;\nZoneSupPlenumAirFlag =Zone(ZoneNum).IsSupplyPlenum;\n\n//Plenum and controlled zones have a different set of inlet nodes which must be calculated.\nif(ControlledZoneAirFlag) {\nautoconst&node(Node(zec.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\nCpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\n}elseif(ZoneRetPlenumAirFlag) {\nZoneRetPlenumNum =Zone(ZoneNum).PlenumCondNum;\nautoconst&zrpc(dataZonePlenum.ZoneRetPlenCond(ZoneRetPlenumNum));\nReal64constair_hum_rat(ZoneAirHumRat(ZoneNum));\nfor(intNodeNum =1, NodeNum_end = zrpc.NumInletNodes; NodeNum <= NodeNum_end; ++NodeNum) {\n//Get node conditions\nautoconst&node(Node(zrpc.InletNode(NodeNum)));\nNodeTemp = node.Temp;\nMassFlowRate = node.MassFlowRate;\nCpAir =PsyCpAirFnW(air_hum_rat);\n\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nADUInNode =AirDistUnit(ADUNum).InletNodeNum;\nNodeTemp =Node(ADUInNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateUpStrLk;\nCpAir =PsyCpAirFnW(air_hum_rat);\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\nADUOutNode =AirDistUnit(ADUNum).OutletNodeNum;\nNodeTemp =Node(ADUOutNode).Temp;\nMassFlowRate =AirDistUnit(ADUNum).MassFlowRateDnStrLk;\nCpAir =PsyCpAirFnW(air_hum_rat);\nReal64constMassFlowRate_CpAir(MassFlowRate * CpAir);\nSumSysMCp += MassFlowRate_CpAir;\nSumSysMCpT += MassFlowRate_CpAir * NodeTemp;\n//Get node conditions\nNodeTemp =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).Temp;\nMassFlowRate =Node(dataZonePlenum.ZoneSupPlenCond(ZoneSupPlenumNum).InletNode).MassFlowRate;\nCpAir =PsyCpAirFnW(ZoneAirHumRat(ZoneNum));\n\nSumSysMCp += MassFlowRate * CpAir;\nSumSysMCpT += MassFlowRate * CpAir * NodeTemp;"}
{"Commit title": "Don't copy structs into kiva convection lambdas.", "only_addition_codes": "Real64 height = state.dataSurface->Surface(SurfNum).Height;\nbool isWindow = state.dataConstruction->Construct(state.dataSurface->Surface(SurfNum).Construction).TypeIsWindow;\nreturn CalcCeilingDiffuserIntConvCoeff(state, ACH, Tsurf, Tamb, cosTilt, AirHumRat, height, isWindow);", "only_deletion_codes": "return CalcCeilingDiffuserIntConvCoeff(state,\nACH,\nTsurf,\nTamb,\ncosTilt,\nAirHumRat,\nSurface(SurfNum).Height,\nstate.dataConstruction->Construct(Surface(SurfNum).Construction).TypeIsWindow);", "codes_without_addition_and_deletion": "\nfor (auto SurfNum = Zone(ZoneNum).HTSurfaceFirst; SurfNum <= Zone(ZoneNum).HTSurfaceLast; ++SurfNum) {\nif (Surface(SurfNum).ExtBoundCond == DataSurfaces::KivaFoundation) {\nstate.dataSurfaceGeometry->kivaManager.surfaceConvMap[SurfNum].in =\n[=, &state](double Tsurf, double Tamb, double, double, double cosTilt) -> double {\n};\n} else {\nstate.dataHeatBalSurf->SurfHConvInt(SurfNum) =", "before_commit_codebase": "\nfor (auto SurfNum = Zone(ZoneNum).HTSurfaceFirst; SurfNum <= Zone(ZoneNum).HTSurfaceLast; ++SurfNum) {\nif (Surface(SurfNum).ExtBoundCond == DataSurfaces::KivaFoundation) {\nstate.dataSurfaceGeometry->kivaManager.surfaceConvMap[SurfNum].in =\n[=, &state](double Tsurf, double Tamb, double, double, double cosTilt) -> double {\nreturn CalcCeilingDiffuserIntConvCoeff(state,\nACH,\nTsurf,\nTamb,\ncosTilt,\nAirHumRat,\nSurface(SurfNum).Height,\nstate.dataConstruction->Construct(Surface(SurfNum).Construction).TypeIsWindow);\n};\n} else {\nstate.dataHeatBalSurf->SurfHConvInt(SurfNum) =", "after_commit_codebase": "\nfor (auto SurfNum = Zone(ZoneNum).HTSurfaceFirst; SurfNum <= Zone(ZoneNum).HTSurfaceLast; ++SurfNum) {\nif (Surface(SurfNum).ExtBoundCond == DataSurfaces::KivaFoundation) {\nReal64 height = state.dataSurface->Surface(SurfNum).Height;\nbool isWindow = state.dataConstruction->Construct(state.dataSurface->Surface(SurfNum).Construction).TypeIsWindow;\nstate.dataSurfaceGeometry->kivaManager.surfaceConvMap[SurfNum].in =\n[=, &state](double Tsurf, double Tamb, double, double, double cosTilt) -> double {\nreturn CalcCeilingDiffuserIntConvCoeff(state, ACH, Tsurf, Tamb, cosTilt, AirHumRat, height, isWindow);\n};\n} else {\nstate.dataHeatBalSurf->SurfHConvInt(SurfNum) ="}
{"Commit title": "[StructuralMechanicsApplication] Adding patch test for Quad9", "only_addition_codes": "deftest_SmallDisplacementElement_2D_quadratic_quadrilateral(self):\ndim=2\ncurrent_model=KratosMultiphysics.Model()\nmp=current_model.CreateModelPart(\"solid_part\")\nself._add_variables(mp)\nself._apply_material_properties(mp,dim)\n\n# Create nodes\nmp.CreateNewNode(1,2.0000000000,1.0000000000,0.0000000000)\nmp.CreateNewNode(2,1.8333333333,0.8333333333,0.0000000000)\nmp.CreateNewNode(3,1.7500000000,0.9166666667,0.0000000000)\nmp.CreateNewNode(4,1.6501412600,0.7903466431,0.0000000000)\nmp.CreateNewNode(5,1.6666666667,0.6666666667,0.0000000000)\nmp.CreateNewNode(6,1.5000000000,0.8333333333,0.0000000000)\nmp.CreateNewNode(7,1.5502825201,0.6640266196,0.0000000000)\nmp.CreateNewNode(8,1.4669491867,0.7473599529,0.0000000000)\nmp.CreateNewNode(9,1.4338983735,0.6613865725,0.0000000000)\nmp.CreateNewNode(10,1.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(11,1.3930628337,0.5373333663,0.0000000000)\nmp.CreateNewNode(12,1.2500000000,0.7500000000,0.0000000000)\nmp.CreateNewNode(13,1.2680628337,0.6623333663,0.0000000000)\nmp.CreateNewNode(14,1.2861256675,0.5746667326,0.0000000000)\nmp.CreateNewNode(15,1.3333333333,0.3333333333,0.0000000000)\nmp.CreateNewNode(16,1.2358431474,0.4106401130,0.0000000000)\nmp.CreateNewNode(17,1.1383529614,0.4879468926,0.0000000000)\nmp.CreateNewNode(18,1.0691764807,0.5773067797,0.0000000000)\nmp.CreateNewNode(19,1.0000000000,0.6666666667,0.0000000000)\nmp.CreateNewNode(20,1.1666666667,0.1666666667,0.0000000000)\nmp.CreateNewNode(21,1.0644666084,0.2779203060,0.0000000000)\nmp.CreateNewNode(22,0.9622665502,0.3891739453,0.0000000000)\nmp.CreateNewNode(23,0.8561332751,0.4862536393,0.0000000000)\nmp.CreateNewNode(24,0.7500000000,0.5833333333,0.0000000000)\nmp.CreateNewNode(25,0.8930900695,0.1452004990,0.0000000000)\nmp.CreateNewNode(26,0.7861801389,0.2904009980,0.0000000000)\nmp.CreateNewNode(27,1.0000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(28,0.6430900695,0.3952004990,0.0000000000)\nmp.CreateNewNode(29,0.6479361204,0.2339226363,0.0000000000)\nmp.CreateNewNode(30,0.6989680602,0.1169613182,0.0000000000)\nmp.CreateNewNode(31,0.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(32,0.7500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(33,0.5114680602,0.3044613182,0.0000000000)\nmp.CreateNewNode(34,0.5096921019,0.1774442747,0.0000000000)\nmp.CreateNewNode(35,0.3750000000,0.3750000000,0.0000000000)\nmp.CreateNewNode(36,0.5048460509,0.0887221373,0.0000000000)\nmp.CreateNewNode(37,0.3798460509,0.2137221373,0.0000000000)\nmp.CreateNewNode(38,0.5000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(39,0.2500000000,0.2500000000,0.0000000000)\nmp.CreateNewNode(40,0.3149230255,0.1068610687,0.0000000000)\nmp.CreateNewNode(41,0.2500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(42,0.1250000000,0.1250000000,0.0000000000)\nmp.CreateNewNode(43,0.0000000000,0.0000000000,0.0000000000)\n\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_X,KratosMultiphysics.REACTION_X,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Y,KratosMultiphysics.REACTION_Y,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Z,KratosMultiphysics.REACTION_Z,mp)\n\n#create a submodelpart for boundary conditions\nbcs=mp.CreateSubModelPart(\"BoundaryCondtions\")\nbcs.AddNodes([1,2,3,5,6,10,12,15,19,20,24,27,31,32,35,38,39,41,42,43])\n\n# Create Element\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",1, [39,43,38,34,42,41,36,37,40],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",2, [31,39,34,26,35,37,29,28,33],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",3, [34,38,27,26,36,32,25,29,30],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",4, [5,1,6,9,2,3,8,7,4],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",5, [27,15,17,26,20,16,22,25,21],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",6, [31,26,17,19,28,22,18,24,23],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",7, [15,5,9,17,10,7,14,16,11],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",8, [19,17,9,6,18,14,8,12,13],mp.GetProperties()[1])\n\nA,b=self._define_movement(dim)\n\nself._apply_BCs(bcs,A,b)\nself._solve(mp)\nself._check_results(mp,A,b)\nself._check_outputs(mp,A,dim)\n\n#self.__post_process(mp)\n", "only_deletion_codes": "", "codes_without_addition_and_deletion": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()", "before_commit_codebase": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()", "after_commit_codebase": "\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_2D_quadratic_quadrilateral(self):\ndim=2\ncurrent_model=KratosMultiphysics.Model()\nmp=current_model.CreateModelPart(\"solid_part\")\nself._add_variables(mp)\nself._apply_material_properties(mp,dim)\n\n# Create nodes\nmp.CreateNewNode(1,2.0000000000,1.0000000000,0.0000000000)\nmp.CreateNewNode(2,1.8333333333,0.8333333333,0.0000000000)\nmp.CreateNewNode(3,1.7500000000,0.9166666667,0.0000000000)\nmp.CreateNewNode(4,1.6501412600,0.7903466431,0.0000000000)\nmp.CreateNewNode(5,1.6666666667,0.6666666667,0.0000000000)\nmp.CreateNewNode(6,1.5000000000,0.8333333333,0.0000000000)\nmp.CreateNewNode(7,1.5502825201,0.6640266196,0.0000000000)\nmp.CreateNewNode(8,1.4669491867,0.7473599529,0.0000000000)\nmp.CreateNewNode(9,1.4338983735,0.6613865725,0.0000000000)\nmp.CreateNewNode(10,1.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(11,1.3930628337,0.5373333663,0.0000000000)\nmp.CreateNewNode(12,1.2500000000,0.7500000000,0.0000000000)\nmp.CreateNewNode(13,1.2680628337,0.6623333663,0.0000000000)\nmp.CreateNewNode(14,1.2861256675,0.5746667326,0.0000000000)\nmp.CreateNewNode(15,1.3333333333,0.3333333333,0.0000000000)\nmp.CreateNewNode(16,1.2358431474,0.4106401130,0.0000000000)\nmp.CreateNewNode(17,1.1383529614,0.4879468926,0.0000000000)\nmp.CreateNewNode(18,1.0691764807,0.5773067797,0.0000000000)\nmp.CreateNewNode(19,1.0000000000,0.6666666667,0.0000000000)\nmp.CreateNewNode(20,1.1666666667,0.1666666667,0.0000000000)\nmp.CreateNewNode(21,1.0644666084,0.2779203060,0.0000000000)\nmp.CreateNewNode(22,0.9622665502,0.3891739453,0.0000000000)\nmp.CreateNewNode(23,0.8561332751,0.4862536393,0.0000000000)\nmp.CreateNewNode(24,0.7500000000,0.5833333333,0.0000000000)\nmp.CreateNewNode(25,0.8930900695,0.1452004990,0.0000000000)\nmp.CreateNewNode(26,0.7861801389,0.2904009980,0.0000000000)\nmp.CreateNewNode(27,1.0000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(28,0.6430900695,0.3952004990,0.0000000000)\nmp.CreateNewNode(29,0.6479361204,0.2339226363,0.0000000000)\nmp.CreateNewNode(30,0.6989680602,0.1169613182,0.0000000000)\nmp.CreateNewNode(31,0.5000000000,0.5000000000,0.0000000000)\nmp.CreateNewNode(32,0.7500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(33,0.5114680602,0.3044613182,0.0000000000)\nmp.CreateNewNode(34,0.5096921019,0.1774442747,0.0000000000)\nmp.CreateNewNode(35,0.3750000000,0.3750000000,0.0000000000)\nmp.CreateNewNode(36,0.5048460509,0.0887221373,0.0000000000)\nmp.CreateNewNode(37,0.3798460509,0.2137221373,0.0000000000)\nmp.CreateNewNode(38,0.5000000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(39,0.2500000000,0.2500000000,0.0000000000)\nmp.CreateNewNode(40,0.3149230255,0.1068610687,0.0000000000)\nmp.CreateNewNode(41,0.2500000000,0.0000000000,0.0000000000)\nmp.CreateNewNode(42,0.1250000000,0.1250000000,0.0000000000)\nmp.CreateNewNode(43,0.0000000000,0.0000000000,0.0000000000)\n\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_X,KratosMultiphysics.REACTION_X,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Y,KratosMultiphysics.REACTION_Y,mp)\nKratosMultiphysics.VariableUtils().AddDof(KratosMultiphysics.DISPLACEMENT_Z,KratosMultiphysics.REACTION_Z,mp)\n\n#create a submodelpart for boundary conditions\nbcs=mp.CreateSubModelPart(\"BoundaryCondtions\")\nbcs.AddNodes([1,2,3,5,6,10,12,15,19,20,24,27,31,32,35,38,39,41,42,43])\n\n# Create Element\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",1, [39,43,38,34,42,41,36,37,40],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",2, [31,39,34,26,35,37,29,28,33],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",3, [34,38,27,26,36,32,25,29,30],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",4, [5,1,6,9,2,3,8,7,4],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",5, [27,15,17,26,20,16,22,25,21],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",6, [31,26,17,19,28,22,18,24,23],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",7, [15,5,9,17,10,7,14,16,11],mp.GetProperties()[1])\nmp.CreateNewElement(\"SmallDisplacementElement2D9N\",8, [19,17,9,6,18,14,8,12,13],mp.GetProperties()[1])\n\nA,b=self._define_movement(dim)\n\nself._apply_BCs(bcs,A,b)\nself._solve(mp)\nself._check_results(mp,A,b)\nself._check_outputs(mp,A,dim)\n\n#self.__post_process(mp)\n\ndeftest_SmallDisplacementElement_3D_tetra(self):\ndim=3\ncurrent_model=KratosMultiphysics.Model()"}
{"Commit title": "Missing changes in CompressiblePotentialFlowApp", "only_addition_codes": "std::vector<array_1d<double,3>> cut_normal;", "only_deletion_codes": "std::vector<Vector> cut_normal;", "codes_without_addition_and_deletion": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;", "before_commit_codebase": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\nstd::vector<Vector> cut_normal;\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;", "after_commit_codebase": "ModifiedShapeFunctions::Pointer pModifiedShFunc =this->pGetModifiedShapeFunctions(it_elem->pGetGeometry(),Vector(geometry_distances));\n\n//Computing Normal\nstd::vector<array_1d<double,3>> cut_normal;\npModifiedShFunc ->ComputePositiveSideInterfaceAreaNormals(cut_normal,GeometryData::GI_GAUSS_1);\n\nstd::vector<double> pressure_coefficient;"}
{"Commit title": "AsyncHandler - use unordered_map", "only_addition_codes": "std::unordered_map<std::string, FileRequestAsync> async_requests;\nstd::unordered_map<std::string, std::string> file_mapping;\nautoit = async_requests.find(path);", "only_deletion_codes": "std::map<std::string, FileRequestAsync> async_requests;\nstd::map<std::string, std::string> file_mapping;\nstd::map<std::string, FileRequestAsync>::iteratorit = async_requests.find(path);", "codes_without_addition_and_deletion": "//#define EP_DEBUG_SIMULATE_ASYNC\n\nnamespace{\nintnext_id =0;\n\nFileRequestAsync*GetRequest(conststd::string& path) {\n\nif(it != async_requests.end()) {\nreturn&(it->second);", "before_commit_codebase": "//#define EP_DEBUG_SIMULATE_ASYNC\n\nnamespace{\nstd::map<std::string, FileRequestAsync> async_requests;\nstd::map<std::string, std::string> file_mapping;\nintnext_id =0;\n\nFileRequestAsync*GetRequest(conststd::string& path) {\nstd::map<std::string, FileRequestAsync>::iteratorit = async_requests.find(path);\n\nif(it != async_requests.end()) {\nreturn&(it->second);", "after_commit_codebase": "//#define EP_DEBUG_SIMULATE_ASYNC\n\nnamespace{\nstd::unordered_map<std::string, FileRequestAsync> async_requests;\nstd::unordered_map<std::string, std::string> file_mapping;\nintnext_id =0;\n\nFileRequestAsync*GetRequest(conststd::string& path) {\nautoit = async_requests.find(path);\n\nif(it != async_requests.end()) {\nreturn&(it->second);"}
{"Commit title": "WaverBlit fixes", "only_addition_codes": "constautoxoff = src_rect.x* zoom_x;\nconstautoyoff = src_rect.y* zoom_y;\nxoff, yoff +i,\n0, i,", "only_deletion_codes": "src_rect.x,i,\nsrc_rect.x, i,", "codes_without_addition_and_deletion": "\nintheight =static_cast<int>(std::floor(src_rect.height* zoom_y));\nintwidth  =static_cast<int>(std::floor(src_rect.width* zoom_x));\nconstautoyclip = y <0? -y :0;\nconstautoyend =std::min(height,this->height() - y);\nfor(inti = yclip; i < yend; i++) {\n\npixman_image_composite32(src.GetOperator(mask.get()),\nsrc.bitmap.get(), mask.get(), bitmap.get(),\nx + offset, dy,\nwidth,1);\n}", "before_commit_codebase": "\nintheight =static_cast<int>(std::floor(src_rect.height* zoom_y));\nintwidth  =static_cast<int>(std::floor(src_rect.width* zoom_x));\nconstautoyclip = y <0? -y :0;\nconstautoyend =std::min(height,this->height() - y);\nfor(inti = yclip; i < yend; i++) {\n\npixman_image_composite32(src.GetOperator(mask.get()),\nsrc.bitmap.get(), mask.get(), bitmap.get(),\nsrc_rect.x,i,\nsrc_rect.x, i,\nx + offset, dy,\nwidth,1);\n}", "after_commit_codebase": "\nintheight =static_cast<int>(std::floor(src_rect.height* zoom_y));\nintwidth  =static_cast<int>(std::floor(src_rect.width* zoom_x));\nconstautoxoff = src_rect.x* zoom_x;\nconstautoyoff = src_rect.y* zoom_y;\nconstautoyclip = y <0? -y :0;\nconstautoyend =std::min(height,this->height() - y);\nfor(inti = yclip; i < yend; i++) {\n\npixman_image_composite32(src.GetOperator(mask.get()),\nsrc.bitmap.get(), mask.get(), bitmap.get(),\nxoff, yoff +i,\n0, i,\nx + offset, dy,\nwidth,1);\n}"}
{"Commit title": "fix(decklink): guard against null video or audio frame from decklink", "only_addition_codes": "if(video) {\nstate_[\"file/video/width\"]  = video->GetWidth();\nstate_[\"file/video/height\"] = video->GetHeight();\n}\n\ngraph_->set_value(\"frame-time\", frame_timer.elapsed() * format_desc_.fps*0.5);\nif(video){\nif(SUCCEEDED(video->GetBytes(&video_bytes)) && video_bytes) {\nif(audio){\nif(SUCCEEDED(audio->GetBytes(&audio_bytes)) && audio_bytes) {\n//TODO (fix) this may get stuck if the decklink sends a frame of video or audio\n", "only_deletion_codes": "state_[\"file/video/width\"]       = video->GetWidth();\nstate_[\"file/video/height\"]      = video->GetHeight();\ngraph_->set_value(\"frame-time\", frame_timer.elapsed() * format_desc_.fps/ format_desc_.field_count*0.5);\n{\nif(video &&SUCCEEDED(video->GetBytes(&video_bytes)) && video_bytes) {\n{\nif(audio &&SUCCEEDED(audio->GetBytes(&audio_bytes)) && audio_bytes) {", "codes_without_addition_and_deletion": "{\nstate_[\"file/name\"]              = model_name_;\nstate_[\"file/path\"]              = device_index_;\nstate_[\"file/audio/sample-rate\"] = format_desc_.audio_sample_rate;\nstate_[\"file/audio/channels\"]    = format_desc_.audio_channels;\nstate_[\"file/fps\"]               = format_desc_.fps;\nstate_[\"profiler/time\"]          = {frame_timer.elapsed(), format_desc_.fps};\nstate_[\"buffer\"]                 = {frame_buffer_.size(), frame_buffer_.capacity()};\n\ngraph_->set_value(\"output-buffer\",\nstatic_cast<float>(frame_buffer_.size()) /static_cast<float>(frame_buffer_.capacity()));\n};\nBMDTimeValue in_video_pts =0LL;\nBMDTimeValue in_audio_pts =0LL;\n\nautosrc    = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_PIX_FMT_UYVY422;\nsrc->width= video->GetWidth();\nsrc->key_frame=1;\n\nvoid* video_bytes =nullptr;\nvideo->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, video](AVFrame* ptr) { video->Release(); });\n\n}\n}\n\nautosrc             = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_SAMPLE_FMT_S32;\nsrc->channels= format_desc_.audio_channels;\nsrc->sample_rate= format_desc_.audio_sample_rate;\n\nvoid* audio_bytes =nullptr;\naudio->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, audio](AVFrame* ptr) { audio->Release(); });\nsrc->nb_samples= audio->GetSampleFrameCount();\nautoav_video =alloc_frame();\nautoav_audio =alloc_frame();\n\nif(av_buffersink_get_frame_flags(video_filter_.sink, av_video.get(), AV_BUFFERSINK_FLAG_PEEK) <\n0) {\nreturnS_OK;", "before_commit_codebase": "{\nstate_[\"file/name\"]              = model_name_;\nstate_[\"file/path\"]              = device_index_;\nstate_[\"file/video/width\"]       = video->GetWidth();\nstate_[\"file/video/height\"]      = video->GetHeight();\nstate_[\"file/audio/sample-rate\"] = format_desc_.audio_sample_rate;\nstate_[\"file/audio/channels\"]    = format_desc_.audio_channels;\nstate_[\"file/fps\"]               = format_desc_.fps;\nstate_[\"profiler/time\"]          = {frame_timer.elapsed(), format_desc_.fps};\nstate_[\"buffer\"]                 = {frame_buffer_.size(), frame_buffer_.capacity()};\n\ngraph_->set_value(\"frame-time\", frame_timer.elapsed() * format_desc_.fps/ format_desc_.field_count*0.5);\ngraph_->set_value(\"output-buffer\",\nstatic_cast<float>(frame_buffer_.size()) /static_cast<float>(frame_buffer_.capacity()));\n};\nBMDTimeValue in_video_pts =0LL;\nBMDTimeValue in_audio_pts =0LL;\n\n{\nautosrc    = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_PIX_FMT_UYVY422;\nsrc->width= video->GetWidth();\nsrc->key_frame=1;\n\nvoid* video_bytes =nullptr;\nif(video &&SUCCEEDED(video->GetBytes(&video_bytes)) && video_bytes) {\nvideo->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, video](AVFrame* ptr) { video->Release(); });\n\n}\n}\n\n{\nautosrc             = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_SAMPLE_FMT_S32;\nsrc->channels= format_desc_.audio_channels;\nsrc->sample_rate= format_desc_.audio_sample_rate;\n\nvoid* audio_bytes =nullptr;\nif(audio &&SUCCEEDED(audio->GetBytes(&audio_bytes)) && audio_bytes) {\naudio->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, audio](AVFrame* ptr) { audio->Release(); });\nsrc->nb_samples= audio->GetSampleFrameCount();\nautoav_video =alloc_frame();\nautoav_audio =alloc_frame();\n\nif(av_buffersink_get_frame_flags(video_filter_.sink, av_video.get(), AV_BUFFERSINK_FLAG_PEEK) <\n0) {\nreturnS_OK;", "after_commit_codebase": "{\nstate_[\"file/name\"]              = model_name_;\nstate_[\"file/path\"]              = device_index_;\nstate_[\"file/audio/sample-rate\"] = format_desc_.audio_sample_rate;\nstate_[\"file/audio/channels\"]    = format_desc_.audio_channels;\nstate_[\"file/fps\"]               = format_desc_.fps;\nstate_[\"profiler/time\"]          = {frame_timer.elapsed(), format_desc_.fps};\nstate_[\"buffer\"]                 = {frame_buffer_.size(), frame_buffer_.capacity()};\n\nif(video) {\nstate_[\"file/video/width\"]  = video->GetWidth();\nstate_[\"file/video/height\"] = video->GetHeight();\n}\n\ngraph_->set_value(\"frame-time\", frame_timer.elapsed() * format_desc_.fps*0.5);\ngraph_->set_value(\"output-buffer\",\nstatic_cast<float>(frame_buffer_.size()) /static_cast<float>(frame_buffer_.capacity()));\n};\nBMDTimeValue in_video_pts =0LL;\nBMDTimeValue in_audio_pts =0LL;\n\nif(video){\nautosrc    = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_PIX_FMT_UYVY422;\nsrc->width= video->GetWidth();\nsrc->key_frame=1;\n\nvoid* video_bytes =nullptr;\nif(SUCCEEDED(video->GetBytes(&video_bytes)) && video_bytes) {\nvideo->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, video](AVFrame* ptr) { video->Release(); });\n\n}\n}\n\nif(audio){\nautosrc             = std::shared_ptr<AVFrame>(av_frame_alloc(), [](AVFrame* ptr) {av_frame_free(&ptr); });\nsrc->format= AV_SAMPLE_FMT_S32;\nsrc->channels= format_desc_.audio_channels;\nsrc->sample_rate= format_desc_.audio_sample_rate;\n\nvoid* audio_bytes =nullptr;\nif(SUCCEEDED(audio->GetBytes(&audio_bytes)) && audio_bytes) {\naudio->AddRef();\nsrc = std::shared_ptr<AVFrame>(src.get(), [src, audio](AVFrame* ptr) { audio->Release(); });\nsrc->nb_samples= audio->GetSampleFrameCount();\nautoav_video =alloc_frame();\nautoav_audio =alloc_frame();\n\n//TODO (fix) this may get stuck if the decklink sends a frame of video or audio\n\nif(av_buffersink_get_frame_flags(video_filter_.sink, av_video.get(), AV_BUFFERSINK_FLAG_PEEK) <\n0) {\nreturnS_OK;"}
{"Commit title": "Tweak game speed to be roughly on the level of a 486", "only_addition_codes": "//Update game logic at 15 FPS. This is not exactly the speed at which the\n//game runs on period-appropriate hardware, but it's very close, and it nicely\n//fits into 60 FPS, giving us 4 render frames for 1 logic update.\n//\n//On a 486 with a fast graphics card, the game runs at roughly 15.5 FPS, with\n//a slower (non-VLB) graphics card, it's roughly 14 FPS. On a fast 386 (40 MHz),\n//it's roughly 13 FPS. With 15 FPS, the feel should therefore be very close to\n//playing the game on a 486 at the default game speed setting.\nconstexprautoGAME_LOGIC_UPDATE_DELAY =1.0/15.0;\n\n\nmAccumulatedTime>=GAME_LOGIC_UPDATE_DELAY;\nmAccumulatedTime-=GAME_LOGIC_UPDATE_DELAY", "only_deletion_codes": "constexprautotimeForOneFrame =engine::gameFramesToTime(1);\nmAccumulatedTime>=timeForOneFrame;\nmAccumulatedTime-=timeForOneFrame", "codes_without_addition_and_deletion": "\nnamespace{\n\ncharEPISODE_PREFIXES[] = {'L','M','N','O'};\n\nstd::stringlevelFileName(constintepisode,constintlevel) {\n}\n};\n\nif(mSingleStepping) {\nif(mDoNextSingleStep) {\ndoTimeStep();\n}else{\nmAccumulatedTime+= dt;\nfor(;\n) {\ndoTimeStep();\n}", "before_commit_codebase": "\nnamespace{\n\ncharEPISODE_PREFIXES[] = {'L','M','N','O'};\n\nstd::stringlevelFileName(constintepisode,constintlevel) {\n}\n};\n\nconstexprautotimeForOneFrame =engine::gameFramesToTime(1);\nif(mSingleStepping) {\nif(mDoNextSingleStep) {\ndoTimeStep();\n}else{\nmAccumulatedTime+= dt;\nfor(;\nmAccumulatedTime>=timeForOneFrame;\nmAccumulatedTime-=timeForOneFrame\n) {\ndoTimeStep();\n}", "after_commit_codebase": "\nnamespace{\n\n//Update game logic at 15 FPS. This is not exactly the speed at which the\n//game runs on period-appropriate hardware, but it's very close, and it nicely\n//fits into 60 FPS, giving us 4 render frames for 1 logic update.\n//\n//On a 486 with a fast graphics card, the game runs at roughly 15.5 FPS, with\n//a slower (non-VLB) graphics card, it's roughly 14 FPS. On a fast 386 (40 MHz),\n//it's roughly 13 FPS. With 15 FPS, the feel should therefore be very close to\n//playing the game on a 486 at the default game speed setting.\nconstexprautoGAME_LOGIC_UPDATE_DELAY =1.0/15.0;\n\n\ncharEPISODE_PREFIXES[] = {'L','M','N','O'};\n\nstd::stringlevelFileName(constintepisode,constintlevel) {\n}\n};\n\nif(mSingleStepping) {\nif(mDoNextSingleStep) {\ndoTimeStep();\n}else{\nmAccumulatedTime+= dt;\nfor(;\nmAccumulatedTime>=GAME_LOGIC_UPDATE_DELAY;\nmAccumulatedTime-=GAME_LOGIC_UPDATE_DELAY\n) {\ndoTimeStep();\n}"}
{"Commit title": "Remove traces.", "only_addition_codes": "", "only_deletion_codes": "LOG(ERROR)<<vessel->history_->back().time<<\"\"<<\nvessel->psychohistory_->back().time<<\"\"<<\nvessel->prediction_->back().time;", "codes_without_addition_and_deletion": "/*forks=*/{&vessel->psychohistory_, &vessel->prediction_});\n//Necessary after Εὔδοξος because the ephemeris has not been prolonged\n//during deserialization.  Doesn't hurt prior to Εὔδοξος.\nephemeris->Prolong(vessel->prediction_->back().time);\n}\n", "before_commit_codebase": "/*forks=*/{&vessel->psychohistory_, &vessel->prediction_});\n//Necessary after Εὔδοξος because the ephemeris has not been prolonged\n//during deserialization.  Doesn't hurt prior to Εὔδοξος.\nLOG(ERROR)<<vessel->history_->back().time<<\"\"<<\nvessel->psychohistory_->back().time<<\"\"<<\nvessel->prediction_->back().time;\nephemeris->Prolong(vessel->prediction_->back().time);\n}\n", "after_commit_codebase": "/*forks=*/{&vessel->psychohistory_, &vessel->prediction_});\n//Necessary after Εὔδοξος because the ephemeris has not been prolonged\n//during deserialization.  Doesn't hurt prior to Εὔδοξος.\nephemeris->Prolong(vessel->prediction_->back().time);\n}\n"}
{"Commit title": "A more useful trace.", "only_addition_codes": "usingnamespacestd::chrono_literals;\n\nif(after - before > 100ms) {\nLOG(ERROR) <<\"Long method (\"<< (after - before) / 1ms <<\"ms):\\n\"\n<< method_in->DebugString();", "only_deletion_codes": "if(after - before >std::chrono::milliseconds(100)) {\nLOG(ERROR) <<\"Long method:\\n\"<< method_in->DebugString();", "codes_without_addition_and_deletion": "usingbase::UniqueArray;\nusinginterface::principia__ActivatePlayer;\n\nnamespacejournal{\n\nPlayer::Player(std::filesystem::pathconst& path)\n#include\"journal/player.generated.cc\"\n\nautoconstafter =std::chrono::system_clock::now();\n}\n\nlast_method_in_.swap(method_in);", "before_commit_codebase": "usingbase::UniqueArray;\nusinginterface::principia__ActivatePlayer;\n\nnamespacejournal{\n\nPlayer::Player(std::filesystem::pathconst& path)\n#include\"journal/player.generated.cc\"\n\nautoconstafter =std::chrono::system_clock::now();\nif(after - before >std::chrono::milliseconds(100)) {\nLOG(ERROR) <<\"Long method:\\n\"<< method_in->DebugString();\n}\n\nlast_method_in_.swap(method_in);", "after_commit_codebase": "usingbase::UniqueArray;\nusinginterface::principia__ActivatePlayer;\n\nusingnamespacestd::chrono_literals;\n\nnamespacejournal{\n\nPlayer::Player(std::filesystem::pathconst& path)\n#include\"journal/player.generated.cc\"\n\nautoconstafter =std::chrono::system_clock::now();\nif(after - before > 100ms) {\nLOG(ERROR) <<\"Long method (\"<< (after - before) / 1ms <<\"ms):\\n\"\n<< method_in->DebugString();\n}\n\nlast_method_in_.swap(method_in);"}
{"Commit title": "A test.", "only_addition_codes": "deserialized_circle->WriteToMessage(\n&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\n//positions by less than the tolerance.  It also preserve the degrees of\n//freedom at the \"exact\" iterators.\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +1* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +1* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +2* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +2* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +3* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +3* Second)->degrees_of_freedom);\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +4* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +4* Second)->degrees_of_freedom);", "only_deletion_codes": "deserialized_circle->WriteToMessage(&message,/*forks=*/{},/*exact=*/{});\n//positions by less than the tolerance.", "codes_without_addition_and_deletion": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\n\n//Appending may result in different downsampling because the positions differ\n//a bit.", "before_commit_codebase": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle->WriteToMessage(&message,/*forks=*/{},/*exact=*/{});\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\n//positions by less than the tolerance.\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\n\n//Appending may result in different downsampling because the positions differ\n//a bit.", "after_commit_codebase": "deserialized_circle->Append(t.value, dof);\n}\nserialization::DiscreteTrajectory message;\ndeserialized_circle->WriteToMessage(\n&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\ndeserialized_circle =\nDiscreteTrajectory<World>::ReadFromMessage(message,/*forks=*/{});\n\n//Serialization/deserialization preserves the size, the times, and nudges the\n//positions by less than the tolerance.  It also preserve the degrees of\n//freedom at the \"exact\" iterators.\nEXPECT_THAT(circle.Size(),Eq(39));\nEXPECT_THAT(deserialized_circle->Size(), circle.Size());\nfor(autoit1 = circle.begin(), it2 = deserialized_circle->begin();\nAbsoluteErrorFrom(it1->degrees_of_freedom.velocity(),\nLt(1.1*Milli(Metre) / Second)));\n}\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +1* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +1* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +2* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +2* Second)->degrees_of_freedom);\nEXPECT_EQ(\ndeserialized_circle->LowerBound(t0_ +3* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +3* Second)->degrees_of_freedom);\nEXPECT_NE(\ndeserialized_circle->LowerBound(t0_ +4* Second)->degrees_of_freedom,\ncircle.LowerBound(t0_ +4* Second)->degrees_of_freedom);\n\n//Appending may result in different downsampling because the positions differ\n//a bit."}
{"Commit title": "Fix compilation errors.", "only_addition_codes": "CHECK_EQ(0, message.checkpoint(0).non_collapsible_segment().children_size());\nCHECK_EQ(\n1,\nmessage.checkpoint(0).non_collapsible_segment().zfp().timeline_size());\nCHECK_EQ(0, message.checkpoint(1).non_collapsible_segment().children_size());\nCHECK_EQ(\n16,\nmessage.checkpoint(1).non_collapsible_segment().zfp().timeline_size());", "only_deletion_codes": "CHECK_EQ(0, message.checkpoint(0).segment().children_size());\nCHECK_EQ(1, message.checkpoint(0).segment().zfp().timeline_size());\nCHECK_EQ(0, message.checkpoint(1).segment().children_size());\nCHECK_EQ(16, message.checkpoint(1).segment().zfp().timeline_size());", "codes_without_addition_and_deletion": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {", "before_commit_codebase": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(0).segment().children_size());\nCHECK_EQ(1, message.checkpoint(0).segment().zfp().timeline_size());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(1).segment().children_size());\nCHECK_EQ(16, message.checkpoint(1).segment().zfp().timeline_size());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {", "after_commit_codebase": "WriteCheckpointToMessage(&message);\nCHECK_EQ(2, message.checkpoint_size());\nCHECK_EQ(0, message.checkpoint(0).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(0).non_collapsible_segment().children_size());\nCHECK_EQ(\n1,\nmessage.checkpoint(0).non_collapsible_segment().zfp().timeline_size());\nCHECK_EQ(25, message.checkpoint(1).time().scalar().magnitude());\nCHECK_EQ(0, message.checkpoint(1).non_collapsible_segment().children_size());\nCHECK_EQ(\n16,\nmessage.checkpoint(1).non_collapsible_segment().zfp().timeline_size());\n}\n\nTEST_F(VesselTest, SerializationSuccess) {"}
{"Commit title": "Compilation error.", "only_addition_codes": "/*excluded=*/{},\n/*tracked=*/{},", "only_deletion_codes": "/*forks=*/{},", "codes_without_addition_and_deletion": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle =", "before_commit_codebase": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*forks=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle =", "after_commit_codebase": "\nserialization::DiscreteTrajectory message;\ncircle.WriteToMessage(&message,\n/*excluded=*/{},\n/*tracked=*/{},\n/*exact=*/{circle.LowerBound(t0_ +2* Second),\ncircle.LowerBound(t0_ +3* Second)});\nautodeserialized_circle ="}
{"Commit title": "Start the flight plan at the right place.", "only_addition_codes": "autoconstflight_plan_start=backstory_->back();\n/*initial_time=*/flight_plan_start.time,\n/*initial_degrees_of_freedom=*/flight_plan_start.degrees_of_freedom,", "only_deletion_codes": "autoconsthistory_back=history_->back();\n/*initial_time=*/history_back.time,\n/*initial_degrees_of_freedom=*/history_back.degrees_of_freedom,", "codes_without_addition_and_deletion": "Ephemeris<Barycentric>::GeneralizedAdaptiveStepParametersconst&\nflight_plan_generalized_adaptive_step_parameters) {\nabsl::ReaderMutexLockl(&lock_);\nflight_plan_ = std::make_unique<FlightPlan>(\ninitial_mass,\nfinal_time,\nephemeris_,\nflight_plan_adaptive_step_parameters,", "before_commit_codebase": "Ephemeris<Barycentric>::GeneralizedAdaptiveStepParametersconst&\nflight_plan_generalized_adaptive_step_parameters) {\nabsl::ReaderMutexLockl(&lock_);\nautoconsthistory_back=history_->back();\nflight_plan_ = std::make_unique<FlightPlan>(\ninitial_mass,\n/*initial_time=*/history_back.time,\n/*initial_degrees_of_freedom=*/history_back.degrees_of_freedom,\nfinal_time,\nephemeris_,\nflight_plan_adaptive_step_parameters,", "after_commit_codebase": "Ephemeris<Barycentric>::GeneralizedAdaptiveStepParametersconst&\nflight_plan_generalized_adaptive_step_parameters) {\nabsl::ReaderMutexLockl(&lock_);\nautoconstflight_plan_start=backstory_->back();\nflight_plan_ = std::make_unique<FlightPlan>(\ninitial_mass,\n/*initial_time=*/flight_plan_start.time,\n/*initial_degrees_of_freedom=*/flight_plan_start.degrees_of_freedom,\nfinal_time,\nephemeris_,\nflight_plan_adaptive_step_parameters,"}
{"Commit title": "Make progress on segments of length 2.", "only_addition_codes": "if(segment->timeline_size() >2&&", "only_deletion_codes": "if(segment->timeline_size() >=2&&", "codes_without_addition_and_deletion": "CHECK(!is_at_end(it.point_));\nauto& point =iterator(it.point_);\nautoconst& segment = it.segment_;\nstd::prev(segment->timeline_end())->time<= left_time &&\npoint ==std::next(segment->timeline_begin())) {\npoint =std::prev(segment->timeline_end());", "before_commit_codebase": "CHECK(!is_at_end(it.point_));\nauto& point =iterator(it.point_);\nautoconst& segment = it.segment_;\nif(segment->timeline_size() >=2&&\nstd::prev(segment->timeline_end())->time<= left_time &&\npoint ==std::next(segment->timeline_begin())) {\npoint =std::prev(segment->timeline_end());", "after_commit_codebase": "CHECK(!is_at_end(it.point_));\nauto& point =iterator(it.point_);\nautoconst& segment = it.segment_;\nif(segment->timeline_size() >2&&\nstd::prev(segment->timeline_end())->time<= left_time &&\npoint ==std::next(segment->timeline_begin())) {\npoint =std::prev(segment->timeline_end());"}
{"Commit title": "Track the backstory.", "only_addition_codes": "//or prediction (at the last time of the backstory).  To figure things out\n//when reading we must track the |backstory_|.\n/*tracked=*/{backstory_},", "only_deletion_codes": "//or prediction (at the last time of the backstory).\n/*tracked=*/{},", "codes_without_addition_and_deletion": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment.", "before_commit_codebase": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\n//or prediction (at the last time of the backstory).\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*tracked=*/{},\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment.", "after_commit_codebase": "lock_.AssertReaderHeld();\n//The extremities of the |backstory_| are implicitly exact.  Note that\n//|backstory_->end()| might cause serialization of a 1-point psychohistory\n//or prediction (at the last time of the backstory).  To figure things out\n//when reading we must track the |backstory_|.\ntrajectory_.WriteToMessage(message->mutable_non_collapsible_segment(),\nbackstory_->begin(),\nbackstory_->end(),\n/*tracked=*/{backstory_},\n/*exact=*/{});\n\n//Here the containing pile-up is the one for the collapsible segment."}
{"Commit title": "A test of the new function.", "only_addition_codes": "usinggeometry::InfiniteFuture;\nEXPECT_EQ(t1, checkpointer_.checkpoint_at_or_after(t1));\nEXPECT_EQ(t3, checkpointer_.checkpoint_at_or_after(t2 +1* Second));\nEXPECT_EQ(InfiniteFuture,\ncheckpointer_.checkpoint_at_or_after(t3 +1* Second));\n", "only_deletion_codes": "", "codes_without_addition_and_deletion": "namespacephysics{\n\nusingbase::not_null;\nusinggeometry::InfinitePast;\nusinggeometry::Instant;\nusingquantities::si::Second;\nEXPECT_CALL(writer_,Call(_)).WillOnce(SetPayload(3));\ncheckpointer_.WriteToCheckpoint(t3);\n\nEXPECT_EQ(InfinitePast,\ncheckpointer_.checkpoint_at_or_before(Instant() +1* Second));\nEXPECT_EQ(t1, checkpointer_.checkpoint_at_or_before(t1));", "before_commit_codebase": "namespacephysics{\n\nusingbase::not_null;\nusinggeometry::InfinitePast;\nusinggeometry::Instant;\nusingquantities::si::Second;\nEXPECT_CALL(writer_,Call(_)).WillOnce(SetPayload(3));\ncheckpointer_.WriteToCheckpoint(t3);\n\nEXPECT_EQ(InfinitePast,\ncheckpointer_.checkpoint_at_or_before(Instant() +1* Second));\nEXPECT_EQ(t1, checkpointer_.checkpoint_at_or_before(t1));", "after_commit_codebase": "namespacephysics{\n\nusingbase::not_null;\nusinggeometry::InfiniteFuture;\nusinggeometry::InfinitePast;\nusinggeometry::Instant;\nusingquantities::si::Second;\nEXPECT_CALL(writer_,Call(_)).WillOnce(SetPayload(3));\ncheckpointer_.WriteToCheckpoint(t3);\n\nEXPECT_EQ(t1, checkpointer_.checkpoint_at_or_after(t1));\nEXPECT_EQ(t3, checkpointer_.checkpoint_at_or_after(t2 +1* Second));\nEXPECT_EQ(InfiniteFuture,\ncheckpointer_.checkpoint_at_or_after(t3 +1* Second));\n\nEXPECT_EQ(InfinitePast,\ncheckpointer_.checkpoint_at_or_before(Instant() +1* Second));\nEXPECT_EQ(t1, checkpointer_.checkpoint_at_or_before(t1));"}
{"Commit title": "Bypass stock aerodynamics outside the atmosphere", "only_addition_codes": "if(part.atmDensity <=0){\ncontinue;\n}", "only_deletion_codes": "", "codes_without_addition_and_deletion": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){", "before_commit_codebase": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){", "after_commit_codebase": "foreach(Vessel vesselinFlightGlobals.Vessels.Where(\nv=>is_manageable(v)&&!v.packed)){\nforeach(Part partinvessel.parts){\nif(part.atmDensity <=0){\ncontinue;\n}\nPartphysical_parent=closest_physical_parent(part);\nif(part.bodyLiftLocalVector!=UnityEngine.Vector3.zero||\npart.dragVector!=UnityEngine.Vector3.zero){"}
{"Commit title": "Fix a test that was broken by the removal of history().", "only_addition_codes": "EXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(trajectory,SizeIs(435'929));", "only_deletion_codes": "EXPECT_THAT(trajectory,SizeIs(435'927));", "codes_without_addition_and_deletion": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}", "before_commit_codebase": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(trajectory,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}", "after_commit_codebase": "autoconst& trajectory = vessel.trajectory();\nautohistory = trajectory.segments().begin();\nautopsychohistory = vessel.psychohistory();\nEXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n\n//Evaluate a point in each of the two segments.\nParseFromBytes<serialization::DiscreteTrajectory>(serialized_message);\nautoconsttrajectory = DiscreteTrajectory<Barycentric>::ReadFromMessage(\nmessage,/*tracked=*/{&history, &psychohistory});\nEXPECT_THAT(trajectory,SizeIs(435'929));\nEXPECT_THAT(*history,SizeIs(435'927));\nEXPECT_THAT(*psychohistory,SizeIs(3));\n}"}
{"Commit title": "Lint.", "only_addition_codes": "//we cannot use FindPolynomialForInstantLocked because it calls\n//lower_boundand we don't want to change its behaviour.", "only_deletion_codes": "//we cannot use FindPolynomialForInstantLocked because it callslower_bound\n//and we don't want to change its behaviour.", "codes_without_addition_and_deletion": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial.", "before_commit_codebase": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\n//we cannot use FindPolynomialForInstantLocked because it callslower_bound\n//and we don't want to change its behaviour.\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial.", "after_commit_codebase": "first_time_ = std::nullopt;\n}else{\n//Locate the polynomial that ends at the first last_point_.  Note that\n//we cannot use FindPolynomialForInstantLocked because it calls\n//lower_boundand we don't want to change its behaviour.\nInstantconst& oldest_time = last_points_.front().first;\n//If oldest_time is the t_max of some polynomial, then the returned\n//iterator points to the next polynomial."}
{"Commit title": "After egg's review.", "only_addition_codes": "UnityEngine.Physics.autoSyncTransforms=false;\nUnityEngine.Physics.SyncTransforms();\nUnityEngine.Physics.autoSyncTransforms=true;\nUnityEngine.Rigidbodyroot_part_rb=root_part.rb;\nUnityEngine.Rigidbodypart_rb=part.rb;\nUnityEngine.Rigidbodypart_rb=part.rb;\nUnityEngine.Rigidbodypart_rb=part.rb;\nUnityEngine.Physics.autoSyncTransforms=false;\nUnityEngine.Rigidbodypart_rb=part.rb;\nUnityEngine.Rigidbodyphysical_object_rb=physical_object.rb;\nUnityEngine.Physics.SyncTransforms();\nUnityEngine.Physics.autoSyncTransforms=true;", "only_deletion_codes": "usingUnityEngine;\nPhysics.autoSyncTransforms=false;\nPhysics.SyncTransforms();\nPhysics.autoSyncTransforms=true;\nRigidbodyroot_part_rb=root_part.rb;\nRigidbodypart_rb=part.rb;\nRigidbodypart_rb=part.rb;\nRigidbodypart_rb=part.rb;\nPhysics.autoSyncTransforms=false;\nRigidbodypart_rb=part.rb;\nRigidbodyphysical_object_rb=physical_object.rb;\nPhysics.SyncTransforms();\nPhysics.autoSyncTransforms=true;", "codes_without_addition_and_deletion": "usingSystem.Collections.Generic;\nusingSystem.IO;\nusingSystem.Linq;\nusingstaticprincipia.ksp_plugin_adapter.FrameType;\n\nnamespaceprincipia{\n\nprivatevoidApplyToVesselsOnRails(VesselProcessorprocess_vessel){\n// |process_vessels| may touch |Transform|s, so disable syncing.\nforeach(Vessel vesselinFlightGlobals.Vessels.Where(\nis_manageable_on_rails)){\nprocess_vessel(vessel);\n}\n}\n\nprivatevoidUpdateBody(CelestialBodybody,doubleuniversal_time){\nUT:universal_time);\nif(vessel.loaded){\nPartroot_part=vessel.rootPart;\nvarorigin=newOrigin{\nreference_part_is_at_origin=true,\nreference_part_is_unmoving=true,\nforeach(Part partinvessel.parts.Where(part=>part.rb!=null&&\nplugin_.PartIsTruthful(\npart.flightID))){\n// TODO(egg): What if the plugin doesn't have the part? this seems\n// brittle.\n// NOTE(egg): I am not sure what the origin is here, as we are\noutboolinserted);\nif(!vessel.packed){\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nQPdegrees_of_freedom;\nif(part_id_to_degrees_of_freedom_.ContainsKey(part.flightID)){\ndegrees_of_freedom=\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nif(main_body_change_countdown_==0&&\nlast_main_body_==FlightGlobals.ActiveVessel?.mainBody){\nplugin_.PartSetApparentRigidMotion(\npart.flightID,\n// TODO(egg): use the centre of mass.\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\n\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\n}\n\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nQPRWpart_actual_motion=\nplugin_.PartGetActualRigidMotion(part.flightID,origin);\nQPpart_actual_degrees_of_freedom=part_actual_motion.qp;\nforeach(physicalObject physical_objectinFlightGlobals.\nphysicalObjects.Where(o=>o!=null&&o.rb!=null)){\n// TODO(egg): This is no longer sensible.\nphysical_object_rb.position+=q_correction_at_root_part;\nphysical_object_rb.transform.position+=q_correction_at_root_part;\nphysical_object_rb.velocity+=v_correction_at_root_part;\n// them at the previous instant, and will propagate them at the beginning\n// of the next frame...\n}\n\nif(last_main_body_!=FlightGlobals.ActiveVessel?.mainBody){\nmain_body_change_countdown_=1;", "before_commit_codebase": "usingSystem.Collections.Generic;\nusingSystem.IO;\nusingSystem.Linq;\nusingUnityEngine;\nusingstaticprincipia.ksp_plugin_adapter.FrameType;\n\nnamespaceprincipia{\n\nprivatevoidApplyToVesselsOnRails(VesselProcessorprocess_vessel){\n// |process_vessels| may touch |Transform|s, so disable syncing.\nPhysics.autoSyncTransforms=false;\nforeach(Vessel vesselinFlightGlobals.Vessels.Where(\nis_manageable_on_rails)){\nprocess_vessel(vessel);\n}\nPhysics.SyncTransforms();\nPhysics.autoSyncTransforms=true;\n}\n\nprivatevoidUpdateBody(CelestialBodybody,doubleuniversal_time){\nUT:universal_time);\nif(vessel.loaded){\nPartroot_part=vessel.rootPart;\nRigidbodyroot_part_rb=root_part.rb;\nvarorigin=newOrigin{\nreference_part_is_at_origin=true,\nreference_part_is_unmoving=true,\nforeach(Part partinvessel.parts.Where(part=>part.rb!=null&&\nplugin_.PartIsTruthful(\npart.flightID))){\nRigidbodypart_rb=part.rb;\n// TODO(egg): What if the plugin doesn't have the part? this seems\n// brittle.\n// NOTE(egg): I am not sure what the origin is here, as we are\noutboolinserted);\nif(!vessel.packed){\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nRigidbodypart_rb=part.rb;\nQPdegrees_of_freedom;\nif(part_id_to_degrees_of_freedom_.ContainsKey(part.flightID)){\ndegrees_of_freedom=\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nif(main_body_change_countdown_==0&&\nlast_main_body_==FlightGlobals.ActiveVessel?.mainBody){\nRigidbodypart_rb=part.rb;\nplugin_.PartSetApparentRigidMotion(\npart.flightID,\n// TODO(egg): use the centre of mass.\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nPhysics.autoSyncTransforms=false;\n\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\n}\n\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nRigidbodypart_rb=part.rb;\nQPRWpart_actual_motion=\nplugin_.PartGetActualRigidMotion(part.flightID,origin);\nQPpart_actual_degrees_of_freedom=part_actual_motion.qp;\nforeach(physicalObject physical_objectinFlightGlobals.\nphysicalObjects.Where(o=>o!=null&&o.rb!=null)){\n// TODO(egg): This is no longer sensible.\nRigidbodyphysical_object_rb=physical_object.rb;\nphysical_object_rb.position+=q_correction_at_root_part;\nphysical_object_rb.transform.position+=q_correction_at_root_part;\nphysical_object_rb.velocity+=v_correction_at_root_part;\n// them at the previous instant, and will propagate them at the beginning\n// of the next frame...\n}\nPhysics.SyncTransforms();\nPhysics.autoSyncTransforms=true;\n\nif(last_main_body_!=FlightGlobals.ActiveVessel?.mainBody){\nmain_body_change_countdown_=1;", "after_commit_codebase": "usingSystem.Collections.Generic;\nusingSystem.IO;\nusingSystem.Linq;\nusingstaticprincipia.ksp_plugin_adapter.FrameType;\n\nnamespaceprincipia{\n\nprivatevoidApplyToVesselsOnRails(VesselProcessorprocess_vessel){\n// |process_vessels| may touch |Transform|s, so disable syncing.\nUnityEngine.Physics.autoSyncTransforms=false;\nforeach(Vessel vesselinFlightGlobals.Vessels.Where(\nis_manageable_on_rails)){\nprocess_vessel(vessel);\n}\nUnityEngine.Physics.SyncTransforms();\nUnityEngine.Physics.autoSyncTransforms=true;\n}\n\nprivatevoidUpdateBody(CelestialBodybody,doubleuniversal_time){\nUT:universal_time);\nif(vessel.loaded){\nPartroot_part=vessel.rootPart;\nUnityEngine.Rigidbodyroot_part_rb=root_part.rb;\nvarorigin=newOrigin{\nreference_part_is_at_origin=true,\nreference_part_is_unmoving=true,\nforeach(Part partinvessel.parts.Where(part=>part.rb!=null&&\nplugin_.PartIsTruthful(\npart.flightID))){\nUnityEngine.Rigidbodypart_rb=part.rb;\n// TODO(egg): What if the plugin doesn't have the part? this seems\n// brittle.\n// NOTE(egg): I am not sure what the origin is here, as we are\noutboolinserted);\nif(!vessel.packed){\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nUnityEngine.Rigidbodypart_rb=part.rb;\nQPdegrees_of_freedom;\nif(part_id_to_degrees_of_freedom_.ContainsKey(part.flightID)){\ndegrees_of_freedom=\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nif(main_body_change_countdown_==0&&\nlast_main_body_==FlightGlobals.ActiveVessel?.mainBody){\nUnityEngine.Rigidbodypart_rb=part.rb;\nplugin_.PartSetApparentRigidMotion(\npart.flightID,\n// TODO(egg): use the centre of mass.\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\n}\n\nforeach(Part partinvessel.parts.Where(PartIsFaithful)){\nUnityEngine.Rigidbodypart_rb=part.rb;\nQPRWpart_actual_motion=\nplugin_.PartGetActualRigidMotion(part.flightID,origin);\nQPpart_actual_degrees_of_freedom=part_actual_motion.qp;\nforeach(physicalObject physical_objectinFlightGlobals.\nphysicalObjects.Where(o=>o!=null&&o.rb!=null)){\n// TODO(egg): This is no longer sensible.\nUnityEngine.Rigidbodyphysical_object_rb=physical_object.rb;\nphysical_object_rb.position+=q_correction_at_root_part;\nphysical_object_rb.transform.position+=q_correction_at_root_part;\nphysical_object_rb.velocity+=v_correction_at_root_part;\n// them at the previous instant, and will propagate them at the beginning\n// of the next frame...\n}\nUnityEngine.Physics.SyncTransforms();\nUnityEngine.Physics.autoSyncTransforms=true;\n\nif(last_main_body_!=FlightGlobals.ActiveVessel?.mainBody){\nmain_body_change_countdown_=1;"}
{"Commit title": "No auto sync.", "only_addition_codes": "// We aregoing to touch plenty of|Transform|s,sowewill prevent\n//Unity from syncing withthephysics system all the time.", "only_deletion_codes": "// We arenot changing the|Transform|s,but ifwedon't disable auto-\n//synctheprofiles show |SyncColliderTransform|.\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n", "codes_without_addition_and_deletion": "yieldbreak;\n}\n\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;", "before_commit_codebase": "yieldbreak;\n}\n\n// We arenot changing the|Transform|s,but ifwedon't disable auto-\n//synctheprofiles show |SyncColliderTransform|.\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\n// We are going to touch plenty of |Transform|s, so we will prevent\n// Unity from syncing with the physics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;", "after_commit_codebase": "yieldbreak;\n}\n\n// We aregoing to touch plenty of|Transform|s,sowewill prevent\n//Unity from syncing withthephysics system all the time.\nUnityEngine.Physics.autoSyncTransforms=false;\n\ndoubleΔt=Planetarium.TimeScale*Planetarium.fetch.fixedDeltaTime;\nif(has_active_manageable_vessel()&&\n!FlightGlobals.ActiveVessel.packed&&\nplugin_.HasVessel(FlightGlobals.ActiveVessel.id.ToString())){\nVector3dq_correction_at_root_part=Vector3d.zero;\nVector3dv_correction_at_root_part=Vector3d.zero;\nCelestialBodymain_body=FlightGlobals.ActiveVessel.mainBody;"}
{"Commit title": "Improve performance of poisson_log_lpmf in some cases", "only_addition_codes": "for(size_ti =0, size_alpha =size(alpha); i < size_alpha; i++) {\nVectorBuilder<include_summand<propto>::value, T_partials_return, T_n>\nlgamma_n_plus_one(size(n));\nif(include_summand<propto>::value) {\nfor(size_ti =0, size_n =size(n); i < size_n; i++) {\nlgamma_n_plus_one[i] =lgamma(n_vec[i] +1.0);\n}\n}\n\nfor(size_ti =0, size_alpha =size(alpha); i < size_alpha; i++) {\nconstauto& alpha_val =value_of(alpha_vec[i]);\nif(!(alpha_val == NEGATIVE_INFTY && n_vec[i] ==0)) {\nlogp -=lgamma_n_plus_one[i];\nlogp += n_vec[i] *alpha_val- exp_alpha[i];", "only_deletion_codes": "//FIXME: first loop size of alpha_vec, second loop if-ed for\n//max_size_seq_view==1\nfor(size_ti =0; i < max_size_seq_view; i++) {\n//FIXME: cache value_of for alpha_vec?  faster if only one?\nfor(size_ti =0; i <size(alpha); i++) {\nif(!(alpha_vec[i] == NEGATIVE_INFTY && n_vec[i] ==0)) {\nlogp -=lgamma(n_vec[i]+1.0);\nlogp += n_vec[i] *value_of(alpha_vec[i])- exp_alpha[i];", "codes_without_addition_and_deletion": "scalar_seq_view<T_log_rate>alpha_vec(alpha);\nsize_tmax_size_seq_view =max_size(n, alpha);\n\nif(INFTY == alpha_vec[i]) {\nreturnLOG_ZERO;\n}\n\noperands_and_partials<T_log_rate>ops_partials(alpha);\n\nVectorBuilder<include_summand<propto, T_log_rate>::value, T_partials_return,\nT_log_rate>\nexp_alpha(size(alpha));\nexp_alpha[i] =exp(value_of(alpha_vec[i]));\n}\n\nfor(size_ti =0; i < max_size_seq_view; i++) {\nif(include_summand<propto>::value) {\n}\n}\n\nif(!is_constant_all<T_log_rate>::value) {", "before_commit_codebase": "scalar_seq_view<T_log_rate>alpha_vec(alpha);\nsize_tmax_size_seq_view =max_size(n, alpha);\n\n//FIXME: first loop size of alpha_vec, second loop if-ed for\n//max_size_seq_view==1\nfor(size_ti =0; i < max_size_seq_view; i++) {\nif(INFTY == alpha_vec[i]) {\nreturnLOG_ZERO;\n}\n\noperands_and_partials<T_log_rate>ops_partials(alpha);\n\n//FIXME: cache value_of for alpha_vec?  faster if only one?\nVectorBuilder<include_summand<propto, T_log_rate>::value, T_partials_return,\nT_log_rate>\nexp_alpha(size(alpha));\nfor(size_ti =0; i <size(alpha); i++) {\nexp_alpha[i] =exp(value_of(alpha_vec[i]));\n}\n\nfor(size_ti =0; i < max_size_seq_view; i++) {\nif(!(alpha_vec[i] == NEGATIVE_INFTY && n_vec[i] ==0)) {\nif(include_summand<propto>::value) {\nlogp -=lgamma(n_vec[i]+1.0);\n}\nlogp += n_vec[i] *value_of(alpha_vec[i])- exp_alpha[i];\n}\n\nif(!is_constant_all<T_log_rate>::value) {", "after_commit_codebase": "scalar_seq_view<T_log_rate>alpha_vec(alpha);\nsize_tmax_size_seq_view =max_size(n, alpha);\n\nfor(size_ti =0, size_alpha =size(alpha); i < size_alpha; i++) {\nif(INFTY == alpha_vec[i]) {\nreturnLOG_ZERO;\n}\n\noperands_and_partials<T_log_rate>ops_partials(alpha);\n\nVectorBuilder<include_summand<propto>::value, T_partials_return, T_n>\nlgamma_n_plus_one(size(n));\nif(include_summand<propto>::value) {\nfor(size_ti =0, size_n =size(n); i < size_n; i++) {\nlgamma_n_plus_one[i] =lgamma(n_vec[i] +1.0);\n}\n}\n\nVectorBuilder<include_summand<propto, T_log_rate>::value, T_partials_return,\nT_log_rate>\nexp_alpha(size(alpha));\nfor(size_ti =0, size_alpha =size(alpha); i < size_alpha; i++) {\nexp_alpha[i] =exp(value_of(alpha_vec[i]));\n}\n\nfor(size_ti =0; i < max_size_seq_view; i++) {\nconstauto& alpha_val =value_of(alpha_vec[i]);\nif(!(alpha_val == NEGATIVE_INFTY && n_vec[i] ==0)) {\nif(include_summand<propto>::value) {\nlogp -=lgamma_n_plus_one[i];\n}\nlogp += n_vec[i] *alpha_val- exp_alpha[i];\n}\n\nif(!is_constant_all<T_log_rate>::value) {"}
{"Commit title": "avoid putting un-needed vars on chain stack and place them on nochain…", "only_addition_codes": "Eigen::Matrix<var, Eigen::Dynamic,1>x_var(x.size());\nfor(inti =0; i < x.size(); ++i)\nx_var(i) =var(newvari(x(i),false));", "only_deletion_codes": "Eigen::Matrix<var, Eigen::Dynamic,1>x_var(x);", "codes_without_addition_and_deletion": "double& fx, Eigen::Matrix<double, Eigen::Dynamic,1>& grad_fx) {\nstart_nested();\ntry{\nvar fx_var =f(x_var);\nfx = fx_var.val();\ngrad_fx.resize(x.size());", "before_commit_codebase": "double& fx, Eigen::Matrix<double, Eigen::Dynamic,1>& grad_fx) {\nstart_nested();\ntry{\nEigen::Matrix<var, Eigen::Dynamic,1>x_var(x);\nvar fx_var =f(x_var);\nfx = fx_var.val();\ngrad_fx.resize(x.size());", "after_commit_codebase": "double& fx, Eigen::Matrix<double, Eigen::Dynamic,1>& grad_fx) {\nstart_nested();\ntry{\nEigen::Matrix<var, Eigen::Dynamic,1>x_var(x.size());\nfor(inti =0; i < x.size(); ++i)\nx_var(i) =var(newvari(x(i),false));\nvar fx_var =f(x_var);\nfx = fx_var.val();\ngrad_fx.resize(x.size());"}
{"Commit title": "Fix no instance of overloaded functionstan::math::Holder::coeffRef", "only_addition_codes": "inlineautooperator[](size_ti)const{returnc_.coeff(i); }", "only_deletion_codes": "inlineautooperator[](size_ti)const{returnc_.coeffRef(i); }", "codes_without_addition_and_deletion": "* @param i index\n* @return the element at the specified position in the container\n*/\n\ninlineautosize()constnoexcept{returnc_.size(); }\n", "before_commit_codebase": "* @param i index\n* @return the element at the specified position in the container\n*/\ninlineautooperator[](size_ti)const{returnc_.coeffRef(i); }\n\ninlineautosize()constnoexcept{returnc_.size(); }\n", "after_commit_codebase": "* @param i index\n* @return the element at the specified position in the container\n*/\ninlineautooperator[](size_ti)const{returnc_.coeff(i); }\n\ninlineautosize()constnoexcept{returnc_.size(); }\n"}
{"Commit title": "Fallback to GLX_MESA_swap_control if GLX_EXT_swap_control isn't suppo…", "only_addition_codes": "#ifGLX_MESA_swap_control\nelseif(glXSwapIntervalMESA !=nullptr)\n{\nglXSwapIntervalMESA(SwapInterval);\n}\n#endif", "only_deletion_codes": "", "codes_without_addition_and_deletion": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#endif\nglXSwapBuffers(display, wnd);\n}", "before_commit_codebase": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#endif\nglXSwapBuffers(display, wnd);\n}", "after_commit_codebase": "{\nglXSwapIntervalEXT(display, wnd, SwapInterval);\n}\n#ifGLX_MESA_swap_control\nelseif(glXSwapIntervalMESA !=nullptr)\n{\nglXSwapIntervalMESA(SwapInterval);\n}\n#endif\n#endif\nglXSwapBuffers(display, wnd);\n}"}
{"Commit title": "Remove obsolete TODO comment", "only_addition_codes": "//dead reckoning", "only_deletion_codes": "//dead reckoning//TODO: I feel like this could be improved. Right now, it's effectively an O(N^2) loop when it concerns monsters and players, since for every monster and player, it loops through the entire entity list to find the limbs. Why? Just access them directly from this entity!", "codes_without_addition_and_deletion": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;", "before_commit_codebase": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\n//dead reckoning//TODO: I feel like this could be improved. Right now, it's effectively an O(N^2) loop when it concerns monsters and players, since for every monster and player, it loops through the entire entity list to find the limbs. Why? Just access them directly from this entity!\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;", "after_commit_codebase": "entity->z+= (entity->new_z- entity->z) /4;\n}\n}\n//dead reckoning\nif(fabs(entity->vel_x) >0||fabs(entity->vel_y) >0)\n{\ndoubleox =0, oy =0, onewx =0, onewy =0;"}
{"Commit title": "Adding percentile statistics to pmemkv_bench output", "only_addition_codes": "snprintf(buf,sizeof(buf),\n\"Percentiles: P50: %.2f P75: %.2f P99: %.2f P99.9: %.2f P99.99: %.2f\\n\",\nPercentile(50),Percentile(75),Percentile(99),\nPercentile(99.9),Percentile(99.99)\n);\nr.append(buf);", "only_deletion_codes": "", "codes_without_addition_and_deletion": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;", "before_commit_codebase": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;", "after_commit_codebase": "\"Min: %.4f  Median: %.4f  Max: %.4f\\n\",\n(num_ ==0.0?0.0: min_),Median(), max_);\nr.append(buf);\nsnprintf(buf,sizeof(buf),\n\"Percentiles: P50: %.2f P75: %.2f P99: %.2f P99.9: %.2f P99.99: %.2f\\n\",\nPercentile(50),Percentile(75),Percentile(99),\nPercentile(99.9),Percentile(99.99)\n);\nr.append(buf);\nr.append(\"------------------------------------------------------\\n\");\nconstdoublemult =100.0/ num_;\ndoublesum =0;"}
{"Commit title": "cmap: assert that polymorphic_string is 40 bytes.", "only_addition_codes": "* Copyright 2017-2020, Intel Corporation\nstatic_assert(\nsizeof(internal::cmap::string_t) ==40,\n\"Wrong size of cmap value and key. This probably means that std::string has size > 32\");\n", "only_deletion_codes": "* Copyright 2017-2019, Intel Corporation", "codes_without_addition_and_deletion": "/*\n*\n* Redistribution and use in source and binary forms, with or without\n* modification, are permitted provided that the following conditions\n\ncmap::cmap(std::unique_ptr<internal::config> cfg) : pmemobj_engine_base(cfg)\n{\nLOG(\"Started ok\");\nRecover();\n}", "before_commit_codebase": "/*\n* Copyright 2017-2019, Intel Corporation\n*\n* Redistribution and use in source and binary forms, with or without\n* modification, are permitted provided that the following conditions\n\ncmap::cmap(std::unique_ptr<internal::config> cfg) : pmemobj_engine_base(cfg)\n{\nLOG(\"Started ok\");\nRecover();\n}", "after_commit_codebase": "/*\n* Copyright 2017-2020, Intel Corporation\n*\n* Redistribution and use in source and binary forms, with or without\n* modification, are permitted provided that the following conditions\n\ncmap::cmap(std::unique_ptr<internal::config> cfg) : pmemobj_engine_base(cfg)\n{\nstatic_assert(\nsizeof(internal::cmap::string_t) ==40,\n\"Wrong size of cmap value and key. This probably means that std::string has size > 32\");\n\nLOG(\"Started ok\");\nRecover();\n}"}
{"Commit title": "Fixed a bug in shapeWidget", "only_addition_codes": "this->xSpinBox->setValue(x);\nthis->ySpinBox->setValue(y);\nthis->zSpinBox->setValue(z);", "only_deletion_codes": "this->xSpinBox->setValue(128);\nthis->ySpinBox->setValue(128);\nthis->zSpinBox->setValue(128);", "codes_without_addition_and_deletion": "//----------------------------------------------------------------------------\nvoidsetSpinBoxValue(intx,inty,intz)\n{\n}\n//----------------------------------------------------------------------------\n", "before_commit_codebase": "//----------------------------------------------------------------------------\nvoidsetSpinBoxValue(intx,inty,intz)\n{\nthis->xSpinBox->setValue(128);\nthis->ySpinBox->setValue(128);\nthis->zSpinBox->setValue(128);\n}\n//----------------------------------------------------------------------------\n", "after_commit_codebase": "//----------------------------------------------------------------------------\nvoidsetSpinBoxValue(intx,inty,intz)\n{\nthis->xSpinBox->setValue(x);\nthis->ySpinBox->setValue(y);\nthis->zSpinBox->setValue(z);\n}\n//----------------------------------------------------------------------------\n"}
{"Commit title": "Changed default color preset to Plasma_17", "only_addition_codes": "this->setDefaultColorMapFromPreset(\"Plasma_17\");", "only_deletion_codes": "this->setDefaultColorMapFromPreset(\"Grayscale\");", "codes_without_addition_and_deletion": "}\n\n//Set the default color map from a preset.\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");", "before_commit_codebase": "}\n\n//Set the default color map from a preset.\nthis->setDefaultColorMapFromPreset(\"Grayscale\");\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");", "after_commit_codebase": "}\n\n//Set the default color map from a preset.\nthis->setDefaultColorMapFromPreset(\"Plasma_17\");\n\n//this will trigger the logic to setup reader/writer factories, etc.\npqApplicationCore::instance()->loadConfigurationXML(\"<xml/>\");"}
{"Commit title": "Always use component 0 when getting voxel values", "only_addition_codes": "indices[0], indices[1], indices[2],0);", "only_deletion_codes": "autoactiveScalars = data->GetPointData()->GetScalars()->GetName();\nintactiveScalarsIdx =0;\nfor(inti =0; i < data->GetPointData()->GetNumberOfComponents(); ++i) {\nif(data->GetPointData()->GetArrayName(i) == activeScalars) {\nactiveScalarsIdx = i;\nbreak;\n}\n}\n\nindices[0], indices[1], indices[2],activeScalarsIdx);", "codes_without_addition_and_deletion": "indices[i] =round((position[i] - origin[i]) / spacing[i]);\n}\n\ndoublescalar = data->GetScalarComponentAsDouble(\nok =true;\nreturnscalar;\n}", "before_commit_codebase": "indices[i] =round((position[i] - origin[i]) / spacing[i]);\n}\n\nautoactiveScalars = data->GetPointData()->GetScalars()->GetName();\nintactiveScalarsIdx =0;\nfor(inti =0; i < data->GetPointData()->GetNumberOfComponents(); ++i) {\nif(data->GetPointData()->GetArrayName(i) == activeScalars) {\nactiveScalarsIdx = i;\nbreak;\n}\n}\n\ndoublescalar = data->GetScalarComponentAsDouble(\nindices[0], indices[1], indices[2],activeScalarsIdx);\nok =true;\nreturnscalar;\n}", "after_commit_codebase": "indices[i] =round((position[i] - origin[i]) / spacing[i]);\n}\n\ndoublescalar = data->GetScalarComponentAsDouble(\nindices[0], indices[1], indices[2],0);\nok =true;\nreturnscalar;\n}"}
{"Commit title": "Async matrix release for MKL >= 2023.2", "only_addition_codes": "//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\noneapi::mkl::sparse::release_matrix_handle(exec.sycl_queue(), &handle,\n{ev_gemv});\n#else\n#endif\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\noneapi::mkl::sparse::release_matrix_handle(exec.sycl_queue(), &handle,\n{ev_gemv});\n#else\n#endif", "only_deletion_codes": "", "codes_without_addition_and_deletion": "autoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\nx.data(), beta, y.data(), {ev_opt});\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n}\n};\n\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_opt});\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n}\n};\n", "before_commit_codebase": "autoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\nx.data(), beta, y.data(), {ev_opt});\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n}\n};\n\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_opt});\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n}\n};\n", "after_commit_codebase": "autoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\nx.data(), beta, y.data(), {ev_opt});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\noneapi::mkl::sparse::release_matrix_handle(exec.sycl_queue(), &handle,\n{ev_gemv});\n#else\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n#endif\n}\n};\n\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_opt});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\noneapi::mkl::sparse::release_matrix_handle(exec.sycl_queue(), &handle,\n{ev_gemv});\n#else\nautoev_release =oneapi::mkl::sparse::release_matrix_handle(\nexec.sycl_queue(), &handle, {ev_gemv});\nev_release.wait();\n#endif\n}\n};\n"}
{"Commit title": "Don't call optimize_gemv for one-shot spmv", "only_addition_codes": "x.data(), beta, y.data(), {ev_set});\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_set});", "only_deletion_codes": "autoev_opt =oneapi::mkl::sparse::optimize_gemv(\nexec.sycl_queue(), mkl_mode, handle, {ev_set});\nx.data(), beta, y.data(), {ev_opt});\nautoev_opt =oneapi::mkl::sparse::optimize_gemv(\nexec.sycl_queue(), mkl_mode, handle, {ev_set});\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_opt});", "codes_without_addition_and_deletion": "const_cast<ordinal_type*>(A.graph.row_map.data()),\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nconst_cast<scalar_type*>(A.values.data()));\nautoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(A.values.data())));\nautoev_gemv =oneapi::mkl::sparse::gemv(\nexec.sycl_queue(), mkl_mode, alpha, handle,\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200", "before_commit_codebase": "const_cast<ordinal_type*>(A.graph.row_map.data()),\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nconst_cast<scalar_type*>(A.values.data()));\nautoev_opt =oneapi::mkl::sparse::optimize_gemv(\nexec.sycl_queue(), mkl_mode, handle, {ev_set});\nautoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\nx.data(), beta, y.data(), {ev_opt});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(A.values.data())));\nautoev_opt =oneapi::mkl::sparse::optimize_gemv(\nexec.sycl_queue(), mkl_mode, handle, {ev_set});\nautoev_gemv =oneapi::mkl::sparse::gemv(\nexec.sycl_queue(), mkl_mode, alpha, handle,\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_opt});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200", "after_commit_codebase": "const_cast<ordinal_type*>(A.graph.row_map.data()),\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nconst_cast<scalar_type*>(A.values.data()));\nautoev_gemv =\noneapi::mkl::sparse::gemv(exec.sycl_queue(), mkl_mode, alpha, handle,\nx.data(), beta, y.data(), {ev_set});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200\nconst_cast<ordinal_type*>(A.graph.entries.data()),\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(A.values.data())));\nautoev_gemv =oneapi::mkl::sparse::gemv(\nexec.sycl_queue(), mkl_mode, alpha, handle,\nreinterpret_cast<std::complex<mag_type>*>(\nconst_cast<scalar_type*>(x.data())),\nbeta,reinterpret_cast<std::complex<mag_type>*>(y.data()), {ev_set});\n//MKL 2023.2 and up make this release okay async even though it takes a\n//pointer to a stack variable\n#ifINTEL_MKL_VERSION >= 20230200"}
{"Commit title": "Allow scalar_diff pgen to not include scalars", "only_addition_codes": "if(NSCALARS >0) {\nif(f3) {\nfor(intk=pmb->ks-1; k<=pmb->ke+1; k++) {\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i)))\n+SQR(0.5*(r(0,k+1,j,i) -r(0,k-1,j,i))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}\n}elseif(f2) {\nintk = pmb->ks;\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i))));\n}else{\nintk = pmb->ks;\nintj = pmb->js;\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1))));\nreturn0;", "only_deletion_codes": "#if!(NSCALARS == 1)\n#error\"This problem generator requires one scalar\"\n#endif\n\nif(f3) {\nfor(intk=pmb->ks-1; k<=pmb->ke+1; k++) {\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i)))\n+SQR(0.5*(r(0,k+1,j,i) -r(0,k-1,j,i))));\n}\n}elseif(f2) {\nintk = pmb->ks;\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i))));\nintk = pmb->ks;\nintj = pmb->js;\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1))));\nmaxeps =std::max(maxeps, eps);\n}", "codes_without_addition_and_deletion": "#include\"../parameter_input.hpp\"\n#include\"../scalars/scalars.hpp\"\n\nReal threshold;\n\nintRefinementCondition(MeshBlock *pmb);\nintf2 = pmb->pmy_mesh->f2, f3 = pmb->pmy_mesh->f3;\nAthenaArray<Real> &r = pmb->pscalars->r;\nReal maxeps =0.;\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\nmaxeps =std::max(maxeps, eps);\n}\n}\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nmaxeps =std::max(maxeps, eps);\n}\n}\n}else{\n}\n\nif(maxeps > threshold)return1;", "before_commit_codebase": "#include\"../parameter_input.hpp\"\n#include\"../scalars/scalars.hpp\"\n\n#if!(NSCALARS == 1)\n#error\"This problem generator requires one scalar\"\n#endif\n\nReal threshold;\n\nintRefinementCondition(MeshBlock *pmb);\nintf2 = pmb->pmy_mesh->f2, f3 = pmb->pmy_mesh->f3;\nAthenaArray<Real> &r = pmb->pscalars->r;\nReal maxeps =0.;\nif(f3) {\nfor(intk=pmb->ks-1; k<=pmb->ke+1; k++) {\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i)))\n+SQR(0.5*(r(0,k+1,j,i) -r(0,k-1,j,i))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}\n}elseif(f2) {\nintk = pmb->ks;\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}else{\nintk = pmb->ks;\nintj = pmb->js;\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n\nif(maxeps > threshold)return1;", "after_commit_codebase": "#include\"../parameter_input.hpp\"\n#include\"../scalars/scalars.hpp\"\n\nReal threshold;\n\nintRefinementCondition(MeshBlock *pmb);\nintf2 = pmb->pmy_mesh->f2, f3 = pmb->pmy_mesh->f3;\nAthenaArray<Real> &r = pmb->pscalars->r;\nReal maxeps =0.;\nif(NSCALARS >0) {\nif(f3) {\nfor(intk=pmb->ks-1; k<=pmb->ke+1; k++) {\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i)))\n+SQR(0.5*(r(0,k+1,j,i) -r(0,k-1,j,i))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}\n}elseif(f2) {\nintk = pmb->ks;\nfor(intj=pmb->js-1; j<=pmb->je+1; j++) {\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1)))\n+SQR(0.5*(r(0,k,j+1,i) -r(0,k,j-1,i))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}else{\nintk = pmb->ks;\nintj = pmb->js;\nfor(inti=pmb->is-1; i<=pmb->ie+1; i++) {\nReal eps =std::sqrt(SQR(0.5*(r(0,k,j,i+1) -r(0,k,j,i-1))));\nmaxeps =std::max(maxeps, eps);\n}\n}\n}else{\nreturn0;\n}\n\nif(maxeps > threshold)return1;"}
{"Commit title": "fix a bug in disk.cpp related to#430", "only_addition_codes": "phi=pco->x3v(k);", "only_deletion_codes": "phi=pco->x3v(i);", "codes_without_addition_and_deletion": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;", "before_commit_codebase": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nphi=pco->x3v(i);\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;", "after_commit_codebase": "z=pco->x3v(k);\n}elseif(std::strcmp(COORDINATE_SYSTEM,\"spherical_polar\") ==0) {\nrad=std::abs(pco->x1v(i)*std::sin(pco->x2v(j)));\nphi=pco->x3v(k);\nz=pco->x1v(i)*std::cos(pco->x2v(j));\n}\nreturn;"}
{"Commit title": "Fix a bug in the hierarchy construction when using 63 bits for Morton…", "only_addition_codes": "if(x !=0)\n{\n//When using 63 bits for Morton codes, the LLONG_MAX is actually a valid\n//code. As we want the return statement above to return a value always\n//greater than anything here, we downshift by 1.\nreturnx -1;\n}\n\nreturnLLONG_MIN + (i ^ (i +1));", "only_deletion_codes": "returnx + (!x) * (LLONG_MIN + (i ^ (i +1)));", "codes_without_addition_and_deletion": "//Morton comparison. Thus, we add INT_MIN to it.\n//We also avoid if/else statement by doing a \"x + !x*<blah>\" trick.\nautox =_sorted_morton_codes(i) ^_sorted_morton_codes(i +1);\n}\n\nKOKKOS_FUNCTION Node *getNodePtr(inti)const", "before_commit_codebase": "//Morton comparison. Thus, we add INT_MIN to it.\n//We also avoid if/else statement by doing a \"x + !x*<blah>\" trick.\nautox =_sorted_morton_codes(i) ^_sorted_morton_codes(i +1);\nreturnx + (!x) * (LLONG_MIN + (i ^ (i +1)));\n}\n\nKOKKOS_FUNCTION Node *getNodePtr(inti)const", "after_commit_codebase": "//Morton comparison. Thus, we add INT_MIN to it.\n//We also avoid if/else statement by doing a \"x + !x*<blah>\" trick.\nautox =_sorted_morton_codes(i) ^_sorted_morton_codes(i +1);\nif(x !=0)\n{\n//When using 63 bits for Morton codes, the LLONG_MAX is actually a valid\n//code. As we want the return statement above to return a value always\n//greater than anything here, we downshift by 1.\nreturnx -1;\n}\n\nreturnLLONG_MIN + (i ^ (i +1));\n}\n\nKOKKOS_FUNCTION Node *getNodePtr(inti)const"}
{"Commit title": "faster rotation transformation", "only_addition_codes": "//int nv = resolution;\nSinCosTabletab2(resolution,0, M_PI);\nfor(intv =0; v<resolution-1; v++)\nVector v_p1 =Vector(eig_vec1[0] * x1 + eig_vec2[0] *y1+ eig_vec3[0] * z1,\neig_vec1[1] * x1 + eig_vec2[1] *y1+ eig_vec3[1] * z1,\neig_vec1[2] * x1 + eig_vec2[2] *y1+ eig_vec3[2] * z1);\nVector v_p2 =Vector(eig_vec1[0] * x2 + eig_vec2[0] * y2 + eig_vec3[0] * z2,\neig_vec1[1] * x2 + eig_vec2[1] * y2 + eig_vec3[1] * z2,\neig_vec1[2] * x2 + eig_vec2[2] * y2 + eig_vec3[2] * z2);\nnormals_.push_back(v_p1);\nnormals_.push_back(v_p2);", "only_deletion_codes": "//Get rotation matrix from eigenvectors\nDenseMatrixrot_and_scale(3,3);\nrot_and_scale << eig_vec1[0], eig_vec2[0], eig_vec3[0],\neig_vec1[1], eig_vec2[1], eig_vec3[1],\neig_vec1[2], eig_vec2[2], eig_vec3[2];\n\nintnv = resolution;\ndoublestart =0, stop =  M_PI;\nSinCosTabletab2(nv, start, stop);\nfor(intv =0; v<nv-1; v++)\nEigen::Vector3d p1 = rot_and_scale *Eigen::Vector3d(x1,y1, z1);\nEigen::Vector3d p2 = rot_and_scale *Eigen::Vector3d(x2, y2, z2);\n\nVector v_p1 =Vector(p1[0], p1[1], p1[2]);\nVector v_p2 =Vector(p2[0], p2[1], p2[2]);\nnormals_.push_back(v_p1.normal());\nnormals_.push_back(v_p2.normal());", "codes_without_addition_and_deletion": "eig_vec2 *= r2;\neig_vec3 *= r3;\n\nintnu = resolution +1;\n\n//Half ellipsoid criteria.\n//if (half == -1) start = M_PI / 2.0;\n//Should only happen when doing half ellipsoids.\n//if (nv < 2) nv = 2;\n\nSinCosTabletab1(nu,0,2* M_PI);\n\n//Draw the ellipsoid\n{\ndoublenr1 = tab2.sin(v +1);\ndoublenr2 = tab2.sin(v);\ndoublez2 = nz2;\n\n//Rotate points\n\n\n//Transorm points and add to points list\npoints_.push_back(v_p1 +Vector(center));\npoints_.push_back(v_p2 +Vector(center));\n\n//Add normals\n\n//Add color vectors from parameters\ncolors_.push_back(color);", "before_commit_codebase": "eig_vec2 *= r2;\neig_vec3 *= r3;\n\n//Get rotation matrix from eigenvectors\nDenseMatrixrot_and_scale(3,3);\nrot_and_scale << eig_vec1[0], eig_vec2[0], eig_vec3[0],\neig_vec1[1], eig_vec2[1], eig_vec3[1],\neig_vec1[2], eig_vec2[2], eig_vec3[2];\n\nintnu = resolution +1;\nintnv = resolution;\n\n//Half ellipsoid criteria.\n//if (half == -1) start = M_PI / 2.0;\n//Should only happen when doing half ellipsoids.\n//if (nv < 2) nv = 2;\n\ndoublestart =0, stop =  M_PI;\nSinCosTabletab1(nu,0,2* M_PI);\nSinCosTabletab2(nv, start, stop);\n\n//Draw the ellipsoid\nfor(intv =0; v<nv-1; v++)\n{\ndoublenr1 = tab2.sin(v +1);\ndoublenr2 = tab2.sin(v);\ndoublez2 = nz2;\n\n//Rotate points\nEigen::Vector3d p1 = rot_and_scale *Eigen::Vector3d(x1,y1, z1);\nEigen::Vector3d p2 = rot_and_scale *Eigen::Vector3d(x2, y2, z2);\n\nVector v_p1 =Vector(p1[0], p1[1], p1[2]);\nVector v_p2 =Vector(p2[0], p2[1], p2[2]);\n\n\n//Transorm points and add to points list\npoints_.push_back(v_p1 +Vector(center));\npoints_.push_back(v_p2 +Vector(center));\n\n//Add normals\nnormals_.push_back(v_p1.normal());\nnormals_.push_back(v_p2.normal());\n\n//Add color vectors from parameters\ncolors_.push_back(color);", "after_commit_codebase": "eig_vec2 *= r2;\neig_vec3 *= r3;\n\nintnu = resolution +1;\n//int nv = resolution;\n\n//Half ellipsoid criteria.\n//if (half == -1) start = M_PI / 2.0;\n//Should only happen when doing half ellipsoids.\n//if (nv < 2) nv = 2;\n\nSinCosTabletab1(nu,0,2* M_PI);\nSinCosTabletab2(resolution,0, M_PI);\n\n//Draw the ellipsoid\nfor(intv =0; v<resolution-1; v++)\n{\ndoublenr1 = tab2.sin(v +1);\ndoublenr2 = tab2.sin(v);\ndoublez2 = nz2;\n\n//Rotate points\nVector v_p1 =Vector(eig_vec1[0] * x1 + eig_vec2[0] *y1+ eig_vec3[0] * z1,\neig_vec1[1] * x1 + eig_vec2[1] *y1+ eig_vec3[1] * z1,\neig_vec1[2] * x1 + eig_vec2[2] *y1+ eig_vec3[2] * z1);\n\nVector v_p2 =Vector(eig_vec1[0] * x2 + eig_vec2[0] * y2 + eig_vec3[0] * z2,\neig_vec1[1] * x2 + eig_vec2[1] * y2 + eig_vec3[1] * z2,\neig_vec1[2] * x2 + eig_vec2[2] * y2 + eig_vec3[2] * z2);\n\n//Transorm points and add to points list\npoints_.push_back(v_p1 +Vector(center));\npoints_.push_back(v_p2 +Vector(center));\n\n//Add normals\nnormals_.push_back(v_p1);\nnormals_.push_back(v_p2);\n\n//Add color vectors from parameters\ncolors_.push_back(color);"}
{"Commit title": "Remove the unused test code: generate_pow_code is used to assist in g…", "only_addition_codes": "", "only_deletion_codes": "BOOST_AUTO_TEST_CASE(generate_pow_code)\n{\nstd::cout <<\"{\"<< std::endl;\nfor(inti =1; i <=51; i++)\n{\nstd::cout <<\"//\"<< i <<\"^1 ...\"<< i <<\"^26\"<< std::endl;\nstd::cout <<\"{\"<< std::endl;\nCSC25519base(1);\nuint256 ret;\nfor(intj =1; j <=26; j++)\n{\nbase *= i;\nbase.Pack(ret.begin());\nconstuint64* p = (constuint64*)ret.begin();\nstd::cout <<\"CSC25519({\";\nfor(intk =0; k <4; k++)\n{\nstd::cout <<\"0x\"<< std::hex << *p++ <<std::resetiosflags(std::ios_base::basefield);\nif(k <3)\n{\nstd::cout <<\",\";\n}\n}\nstd::cout <<\"}),\"<< std::endl;\n}\nstd::cout <<\"},\"<< std::endl;\n}\nstd::cout <<\"};\"<< std::endl;\n}\n", "codes_without_addition_and_deletion": "}\n}\n\nBOOST_AUTO_TEST_SUITE_END()", "before_commit_codebase": "}\n}\n\nBOOST_AUTO_TEST_CASE(generate_pow_code)\n{\nstd::cout <<\"{\"<< std::endl;\nfor(inti =1; i <=51; i++)\n{\nstd::cout <<\"//\"<< i <<\"^1 ...\"<< i <<\"^26\"<< std::endl;\nstd::cout <<\"{\"<< std::endl;\nCSC25519base(1);\nuint256 ret;\nfor(intj =1; j <=26; j++)\n{\nbase *= i;\nbase.Pack(ret.begin());\nconstuint64* p = (constuint64*)ret.begin();\nstd::cout <<\"CSC25519({\";\nfor(intk =0; k <4; k++)\n{\nstd::cout <<\"0x\"<< std::hex << *p++ <<std::resetiosflags(std::ios_base::basefield);\nif(k <3)\n{\nstd::cout <<\",\";\n}\n}\nstd::cout <<\"}),\"<< std::endl;\n}\nstd::cout <<\"},\"<< std::endl;\n}\nstd::cout <<\"};\"<< std::endl;\n}\n\nBOOST_AUTO_TEST_SUITE_END()", "after_commit_codebase": "}\n}\n\nBOOST_AUTO_TEST_SUITE_END()"}
{"Commit title": "Return early from fwdpy11.infinite_sites when possible.", "only_addition_codes": "constdoublemu) ->unsigned{\nif(mu <=0.0)\n{\nreturn0u;\n}\nif(nmuts ==0)\n{\nreturnnmuts;\n}", "only_deletion_codes": "constdoublemu) {\nstd::sort(pop.tables.mutation_table.begin(),\npop.tables.mutation_table.end(),\n[&pop](constfwdpp::ts::mutation_record& a,\nconstfwdpp::ts::mutation_record& b) {\nreturnpop.mutations[a.key].pos\n< pop.mutations[b.key].pos;\n});", "codes_without_addition_and_deletion": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);", "before_commit_codebase": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nconstdoublemu) {\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nstd::sort(pop.tables.mutation_table.begin(),\npop.tables.mutation_table.end(),\n[&pop](constfwdpp::ts::mutation_record& a,\nconstfwdpp::ts::mutation_record& b) {\nreturnpop.mutations[a.key].pos\n< pop.mutations[b.key].pos;\n});\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);", "after_commit_codebase": "m.def(\n\"infinite_sites\",\n[](constfwdpy11::GSLrng_t& rng, fwdpy11::Population& pop,\nconstdoublemu) ->unsigned{\nif(mu <=0.0)\n{\nreturn0u;\n}\nfwdpp::flagged_mutation_queue recycling_bin\n=fwdpp::ts::make_mut_queue(pop.mcounts,\npop.mcounts_from_preserved_nodes);\n};\nautonmuts =fwdpp::ts::mutate_tables(rng, apply_mutations,\npop.tables, samples, mu);\nif(nmuts ==0)\n{\nreturnnmuts;\n}\nfwdpp::ts::count_mutations(pop.tables, pop.mutations, samples,\npop.mcounts,\npop.mcounts_from_preserved_nodes);"}
{"Commit title": "Don't assume that a is positive in rational_power_parts", "only_addition_codes": "if(a.abs()< maxnum) {\nad =std::abs(ad);", "only_deletion_codes": "if(a < maxnum) {", "codes_without_addition_and_deletion": "std::vector<std::pair<numeric,int>> factors;\nlongmax_prime_idx;\nstaticnumeric maxnum =numeric(10).power(200);\ndoublead;\nif(a.t== MPZ)\nad =mpz_get_d(a.v._bigint);\nelse\nad = a.v._long;\ndoubleadrootlog =std::log(ad) / denoml;\ndoubleadroot =std::exp(adrootlog);\ndoublempid = adroot*1.25506/adrootlog;", "before_commit_codebase": "std::vector<std::pair<numeric,int>> factors;\nlongmax_prime_idx;\nstaticnumeric maxnum =numeric(10).power(200);\nif(a < maxnum) {\ndoublead;\nif(a.t== MPZ)\nad =mpz_get_d(a.v._bigint);\nelse\nad = a.v._long;\ndoubleadrootlog =std::log(ad) / denoml;\ndoubleadroot =std::exp(adrootlog);\ndoublempid = adroot*1.25506/adrootlog;", "after_commit_codebase": "std::vector<std::pair<numeric,int>> factors;\nlongmax_prime_idx;\nstaticnumeric maxnum =numeric(10).power(200);\nif(a.abs()< maxnum) {\ndoublead;\nif(a.t== MPZ)\nad =mpz_get_d(a.v._bigint);\nelse\nad = a.v._long;\nad =std::abs(ad);\ndoubleadrootlog =std::log(ad) / denoml;\ndoubleadroot =std::exp(adrootlog);\ndoublempid = adroot*1.25506/adrootlog;"}
{"Commit title": "Update to use new namespaces", "only_addition_codes": "\n", "only_deletion_codes": "", "codes_without_addition_and_deletion": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold =", "before_commit_codebase": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold =", "after_commit_codebase": "system.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nrelaxed_comparison(gold,system.batch_output);\n}\n\nsystem.reduction_space.size() /system.batch_input.size());\n\nfm::gemv(reduction_matrix,system.get_unit_vector(),system.batch_output);\n\nstd::stringconstfile_path =\n\"../testing/generated-inputs/batch/continuity3_sg_l3_d4_t1.dat\";\nfk::vector<TestType>constgold ="}
{"Commit title": "update tim's tests to use the new op two scale interface", "only_addition_codes": "fk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);", "only_deletion_codes": "fk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);", "codes_without_addition_and_deletion": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));", "before_commit_codebase": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(dim);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));", "after_commit_codebase": "dimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));\ndimensionconstdim = make_PDE<TestType>(PDE_opts::continuity_1, lev, kdeg)\n->get_dimensions()[0];\n\nfk::matrix<TestType>constfmwt = operator_two_scale<TestType>(kdeg, lev);\n\nfk::matrix<TestType> mat1 =\nfk::matrix<TestType>(read_matrix_from_txt_file(mat1_string));"}
{"Commit title": "improve perf of combine dims using views", "only_addition_codes": "intconststart_index = (i - start_element) *std::pow(degree, num_dims);\nintconststop_index  = start_index +std::pow(degree, num_dims) -1;\nfk::vector<P, mem_type::view>combined_view(combined, start_index,\nstop_index);\ncombined_view =kron_d(kron_list, kron_list.size()) * time_scale;", "only_deletion_codes": "fk::vector<P>constpartial_result =\nkron_d(kron_list, kron_list.size()) * time_scale;\ncombined.set_subvector((i - start_element) *std::pow(degree, num_dims),\npartial_result);", "codes_without_addition_and_deletion": "degree >1? (((id +1) * degree) -1) : index_start;\nkron_list.push_back(vectors[j].extract(index_start, index_end));\n}\n}\nreturncombined;\n}", "before_commit_codebase": "degree >1? (((id +1) * degree) -1) : index_start;\nkron_list.push_back(vectors[j].extract(index_start, index_end));\n}\nfk::vector<P>constpartial_result =\nkron_d(kron_list, kron_list.size()) * time_scale;\ncombined.set_subvector((i - start_element) *std::pow(degree, num_dims),\npartial_result);\n}\nreturncombined;\n}", "after_commit_codebase": "degree >1? (((id +1) * degree) -1) : index_start;\nkron_list.push_back(vectors[j].extract(index_start, index_end));\n}\nintconststart_index = (i - start_element) *std::pow(degree, num_dims);\nintconststop_index  = start_index +std::pow(degree, num_dims) -1;\nfk::vector<P, mem_type::view>combined_view(combined, start_index,\nstop_index);\ncombined_view =kron_d(kron_list, kron_list.size()) * time_scale;\n}\nreturncombined;\n}"}
{"Commit title": "clang-format", "only_addition_codes": "(*std::min_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n})).second.start;\n\nintconstmax_col =\n(*std::max_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n})).second.stop;", "only_deletion_codes": "(*std::min_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n}))\n.second.start;\n\nintconstmax_col = (*std::max_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n}))\n.second.stop;", "codes_without_addition_and_deletion": "{\nassert(g.size() >0);\nintconstmin_col =\nreturngrid_limits(min_col, max_col);\n}\n", "before_commit_codebase": "{\nassert(g.size() >0);\nintconstmin_col =\n(*std::min_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n}))\n.second.start;\n\nintconstmax_col = (*std::max_element(g.begin(), g.end(),\n[](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n}))\n.second.stop;\nreturngrid_limits(min_col, max_col);\n}\n", "after_commit_codebase": "{\nassert(g.size() >0);\nintconstmin_col =\n(*std::min_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.start< b.second.start;\n})).second.start;\n\nintconstmax_col =\n(*std::max_element(g.begin(), g.end(), [](autoconst&a,autoconst&b) {\nreturna.second.stop< b.second.stop;\n})).second.stop;\nreturngrid_limits(min_col, max_col);\n}\n"}
{"Commit title": "default token -> string output for symbols", "only_addition_codes": "}else{\nout <<symbol_map::to_string(token.symbol);\nreturnout;", "only_deletion_codes": "if(token.is_punctuator()) {\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}", "codes_without_addition_and_deletion": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}\nreturnout;\n}", "before_commit_codebase": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_punctuator()) {\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}\nreturnout;\n}", "after_commit_codebase": "out <<\"keyword[\"<<symbol_map::to_string(token.symbol) <<\"]\";\nreturnout;\n}\nif(token.is_literal()){\n//TODO(jaypipes): Add typing of literal...\nsize_tlen = (token.end- token.start);\nsize_tlen = (token.end- token.start);\nout <<\"comment[length:\"<< len <<\"]\";\nreturnout;\n}else{\nout <<symbol_map::to_string(token.symbol);\nreturnout;\n}\nreturnout;\n}"}
